\chapter[Preliminares]{Preliminares}
\label{cap:preliminares.BE}
\section{Generacion exhaustiva acotada  de entradas}
\label{sec:BE}
La generación automatizada de entradas de prueba para las APIs de los programas es una tarea crítica en la prueba de software, ya que puede ayudar a identificar errores y garantizar que los programas se comporten correctamente bajo una amplia gama de entradas. Sin embargo, la generación de entradas para las APIs puede ser desafiante, ya que el número de posibles valores de entrada a menudo es muy grande. La prueba exhaustiva de todas las posibles entradas es típicamente inviable debido a la explosión combinatoria de los valores de entrada, mientras que la prueba aleatoria puede pasar por alto casos importantes. En este artículo, se propone un nuevo enfoque para generar valores de entrada exhaustivos y acotados para las APIs de los programas. Nuestro enfoque combina la ejecución simbólica con la resolución de restricciones para generar un conjunto representativo de valores de entrada que se pueden utilizar para probar APIs con una alta cobertura, sin la necesidad de probar cada posible valor de entrada. Evaluamos nuestro enfoque en un conjunto de APIs del mundo real y mostramos que es más efectivo que los enfoques existentes en términos de cobertura y eficiencia.

Los enfoques de generación de pruebas automatizadas tienen como objetivo ayudar a los desarrolladores en tareas cruciales de prueba de software [TODO ???], como la generación automática o facilitar la creación de conjuntos de pruebas [TODO: ????] y la detección y reporte automáticos de fallas [TODO: ????] . Muchos de estos enfoques implican componentes aleatorios que evitan una exploración sistemática del espacio de comportamientos, pero mejoran la eficiencia de la generación de pruebas [TODO: ????] . Si bien estos enfoques han sido muy útiles para encontrar una gran cantidad de errores en el software, podrían perder la exploración de ciertos comportamientos defectuosos del software debido a su naturaleza aleatoria. Los enfoques alternativos tienen como objetivo explorar sistemáticamente un número muy grande de ejecuciones del software bajo prueba (SUT), con el objetivo de proporcionar garantías más sólidas sobre la ausencia de errores[TODO: ????] . Uno de estos enfoques es la generación exhaustiva acotada (BE) [TODO: ????] , que consiste en generar todas las estructuras factibles que se pueden construir utilizando dominios de datos acotados. Los objetivos comunes de los enfoques BE han sido implementaciones de estructuras de datos complejas y dinámicas con ricos y estructurados enlaces (por ejemplo, listas enlazadas, árboles, etc.). Los enfoques BE de caja negra [TODO: ????]  son los más utilizados y eficientes para probar software. Requieren que el usuario proporcione una especificación formal de las restricciones que las estructuras deben satisfacer, con mayor frecuencia una invariante de representación de la estructura (repOK), y los límites de los dominios de datos [TODO: ????] , a menudo llamados \emph{scope}. De este modo, los enfoques BE de caja negra generan todas las estructuras dentro de los ámbitos proporcionados que satisfacen repOK.
Varios estudios muestran que los enfoques BE son efectivos para revelar fallas en el software [TODO ???]. Además, la llamada hipótesis del cota pequeña [TODO ?], que establece que la mayoría de las fallas de software se pueden revelar ejecutando el SUT en "entradas pequeñas", sugiere que, si se utilizan ámbitos lo suficientemente grandes, los enfoques BE deberían ser capaces de revelar la mayoría (si no todas) las fallas en el SUT. El desafío que enfrentan los enfoques BE es cómo explorar eficientemente un gran espacio de búsqueda, que en el peor de los casos crece exponencialmente con respecto a los ámbitos. El espacio de búsqueda a menudo incluye un gran número de estructuras no válidas (que no satisfacen repOK) y estructuras isomórficas [TODO ??]. Por lo tanto, podar partes del espacio de búsqueda que involucran estructuras inválidas y redundantes es clave para hacer que los enfoques BE se escalen en la práctica [TODO ??]. Escribir especificaciones formales apropiadas para la generación de BE es una tarea desafiante y que consume mucho tiempo. Las especificaciones deben capturar precisamente el conjunto de restricciones previstas en las estructuras. Las especificaciones sobrerestringidas hacen que falte la generación de una parte de las estructuras válidas, lo que puede hacer que la etapa de prueba subsiguiente pierda la exploración de los comportamientos defectuosos del SUT. Las especificaciones subrestringidas pueden llevar a la generación de estructuras inválidas (es decir, estructuras que no cumplen con las restricciones previstas), lo que puede producir falsos negativos durante la prueba del SUT. Además, a veces el usuario tiene que tener en cuenta la forma en que opera el enfoque de generación y escribir las especificaciones de una manera muy específica, de manera que el enfoque pueda lograr un buen rendimiento [TODO ???]. Finalmente, tales especificaciones formales precisas rara vez están disponibles en el software, lo que dificulta la usabilidad de los enfoques BE de caja negra.

\section{Feedback-directed test generation}\label{sec:feedback-directed-test-gen}

La generación de pruebas dirigida por retroalimentación se introdujo por primera vez en el enfoque \textsf{Randoop}, basado en la generación aleatoria de pruebas \cite{Pacheco07}. \textsf{Randoop} requiere un conjunto de rutinas de una API y un budget para la generación de pruebas (tiempo o número de pruebas a generar). \textsf{Randoop} representa las pruebas como secuencias de invocaciones a las rutinas de la API. Por lo tanto, a menudo se llaman \emph{secuencias de prueba}. Comienza con unos pocos valores semilla predeterminados para los tipos primitivos que se utilizarán para instanciar los parámetros de las rutinas de tipos primitivos durante la generación (el usuario también puede proporcionar valores semilla adicionales). \textsf{Randoop} realiza un proceso iterativo. Cada paso consiste en seleccionar aleatoriamente una única rutina \texttt{r(p$_1$,..,p$_k$)} para generar una nueva secuencia de prueba. Para esta rutina, \textsf{Randoop} selecciona aleatoriamente las secuencias \texttt{s$_1$,..,s$_k$} de un conjunto de secuencias de prueba previamente generadas, que se pueden usar para crear valores de los tipos apropiados para instanciar los parámetros \texttt{p$_1$,..,p$_k$} de \texttt{r}, respectivamente. Una nueva prueba \texttt{T} se crea componiendo secuencialmente \texttt{s$_1$,..,s$_k$} y \texttt{r} (y reemplazando los parámetros formales de \texttt{r} por las variables correspondientes en \texttt{s$_1$,..,s$_k$}). \texttt{T} podría ser una prueba ilegal debido al uso no válido de la API y/o fallas en el código en prueba. También podría ser redundante en el sentido de que no produce ninguna estructura para ejercitar el código de manera diferente que las pruebas generadas anteriormente.
La idea principal de la generación de pruebas dirigida por retroalimentación es ejecutar \texttt{T} y observar su comportamiento en tiempo de ejecución. Si \texttt{T} es una prueba legal, es decir, su ejecución termina con éxito,
y \texttt{T} no es redundante, entonces, \texttt{T} se agrega al conjunto de pruebas generadas previamente. Esto hace que \texttt{T} sea un candidato para su posible extensión para generar nuevas pruebas cuando se seleccione un nuevo método en una iteración futura del algoritmo. De lo contrario, si \texttt{T} es una prueba ilegal, por ejemplo, porque genera una excepción o viola un contrato, o si es redundante (consulte la sección~\ref{sec:state-matching})), entonces \texttt{T} no se considera para su posible extensión. \textsf{Randoop} continúa este proceso iterativo hasta que agota su presupuesto. Las evaluaciones experimentales han encontrado que la generación de pruebas dirigida por retroalimentación funciona significativamente mejor que la generación aleatoria simple de pruebas \cite{Pacheco07,Pacheco08}.

% \textsf{BEAPI} se basa en \textsf{Randoop}, pero en lugar de la generación aleatoria, tiene como objetivo generar \emph{todas} las secuencias de pruebas factibles (acotadas), dentro de un alcance dado. La retroalimentación de la ejecución permite a \textsf{BEAPI} descartar pruebas ilegales durante el proceso de generación. Además, al estar basado en una generación de pruebas dirigida por retroalimentación, \textsf{BEAPI} genera una secuencia de prueba para cada estructura en el conjunto exhaustivo acotado que construye. Como se argumenta en la Sección [TODO], esta representación favorece la comprensibilidad y la reutilización de las pruebas generadas con respecto a los enfoques basados en especificaciones relacionados.

\section{Objects? algo sobre serializacion y obejtcos}
\section{Coverage?}

