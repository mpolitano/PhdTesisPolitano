\chapter{Generacion Exhaustiva acotada desde API de los programas}
\label{cap:beapi}

En adelante, se presenta la técnica desarrollada llamada BEAPI, que tiene como objetivo mejorar la generación exhaustiva acotada (BEG, por sus siglas en inglés, \emph{Bounded Exhaustive Generation}). \ref{sec:BE}. \cacho{Agregar en preliminar? ampliar?}
La generación exhaustiva acotada se refiere a un enfoque en pruebas de software y análisis de sistemas en el cual se generan y evalúan todas las posibles combinaciones o instancias de entrada dentro de un conjunto acotado. Esto significa que se examinan todas las combinaciones posibles de entrada dentro de un límite especificado. Es un enfoque efectivo para revelar fallas en el sofware. Este enfoque se utiliza a menudo en sistemas donde el espacio de entrada es manejable y finito. 
Existen varios enfoques de BEG que requieren una especificación precisa de que entradas son válidas en el contexto del sistema. Esta especificación comúnmente se llaman \emph{RepOK} y debe ser brindada por el usuario.
En este capítulo, introduciremos BEAPI, un enfoque eficiente que genera un conjunto exhaustivo acotado de objetos realizando únicamente llamadas a la API de un módulo. Discutiremos las principales ideas de nuestros enfoques para generar de manera eficiente. Este capítulo está organizado de la siguiente manera: en la Sección \ref{sec:motivating-example}, se presenta un ejemplo que ilustra el problema que se aborda con la técnica propuesta, la cual se explica en la Sección \ref{sec:beapiIntro}. Luego, en las Secciones \ref{sec:scope}, \ref{sec:stateMatching} y \ref{sec:builders}, se describen las optimizaciones implementadas en BEAPI. Estas optimizaciones son de vital importancia a la hora de trabajar con BE, ya que necesitamos acortar el espacio de búsqueda para poder generar suites exhaustivas acotadas con un rendimiento comparable al de las técnicas basada en especificaciones, una de ellas es \emph{Korat}\cite{Boyapati02} 


\section[Motivación]{Motivación}
\label{sec:motivating-example}


\begin{figure}[!thb]
\begin{lstlisting}
public boolean repOK() {
    if (this.header == null) return false;
    // Missing constraint: the value of the sentinel node must be null  
    // if (this.header.value != null) return false;
    if (this.header.next == null) return false;
    if (this.header.previous == null) return false;
    if (this.cacheSize > this.maximumCacheSize) return false;
    if (this.size < 0) return false;
    int cyclicSize = 0;
    LinkedListNode n = this.header;
    do {
        cyclicSize++;
        if (n.previous == null) return false;
        if (n.previous.next != n) return false;
        if (n.next == null) return false;
        if (n.next.previous != n) return false;
        if (n != null) n = n.next;
    } while (n != this.header && n != null);
    if (n == null) return false;
    if (this.size != cyclicSize - 1) return false;
    int acyclicSize = 0;
    LinkedListNode m = this.firstCachedNode;
    Set visited = new HashSet();
    visited.add(this.firstCachedNode);
    while (m != null) {
        acyclicSize++;
        if (m.previous != null) return false;
        // Missing constraint: the value of cache nodes must be null
        // if (m.value != null) return false;
        m = m.next;
        if (!visited.add(m)) return false;
    }
    if (this.cacheSize != acyclicSize) return false;
    return true;
}
\end{lstlisting}
\caption{\texttt{repOK} de \texttt{NodeCachingLinkedList} tomado del benchmark de \textsf{ROOPS}}
\label{fig:NCL-repOK}
\end{figure}

Para ilustrar las dificultades de escribir especificaciones formales para la generación exhaustiva acotada de estructuras, consideremos el invariante de representación (comúnmente llamado \emph{repOK}) de la clase \emph{NodeCachingLinkedList} (NCL) de Apache, que se muestra en la Figura \ref{fig:NCL-repOK}. Este es un \emph{repOK} del benchmark \emph{ROOPS}. Los NCL se componen de una lista principal circular doblemente enlazada con un nodo ficticio al comienzo de la estructura. Esta estructura se utiliza para el almacenamiento de datos y una caché de nodos previamente utilizados, implementada como una lista enlazada simple. Los nodos eliminados de la lista principal se mueven a la caché, cambiando su valor a \emph{null}, donde se guardan para su uso futuro. De esta manera, cuando se requiere un nodo para una operación de inserción, se reutiliza un nodo de la caché (si existe) en lugar de asignar un nuevo nodo. El objetivo es evitar la sobrecarga de recolección de basura para las aplicaciones que realizan una gran cantidad de inserciones y eliminaciones en la lista. El \emph{repOK} devuelve \texttt{true} si y solo si la estructura de entrada satisface las propiedades estructurales de NCL \cite{Liskov00}. En la Figura \ref{fig:nclInstanceRepOK} se pueden observar instancias válidas de la estructura.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{NCL.jpg}
    \caption{Instancia de NodeCachingLinkedList}
    \label{fig:nclInstanceRepOK}
\end{figure}

Las restricciones impuestas en el método Java que abarcan las líneas 2 a 11 se refieren a la verificación de la estructura general de \emph{NodeCachingLinkedList}, como por ejemplo la existencia de un nodo ficticio en la lista principal. Este nodo ficticio es generalmente un nodo especial que no contiene datos reales (debería contener \emph{null} como valor del nodo), pero se utiliza como una especie de marcador de inicio que simplifica la manipulación de la lista. La idea es que este nodo ficticio tiene un enlace que apunta al primer elemento real de la lista. Por ejemplo, la Figura \ref{fig:repOK1} nos muestra dos instancias de NCL. La lista de la parte superior es la lista principal y la lista de la parte inferior es la representación de la lista caché. En la figura, la instancia del lado derecho es válida, la del izquierdo es inválida debido a que no cumple la especificación de poseer un nodo ficticio. El \emph{repOK} en la línea 6 controla esta situación y el método retorna \texttt{false}.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{images/repok1.jpg}
  \caption{Ejemplo de una instancia válida y otra no válida de acuerdo al \emph{repOK} en las configuraciones generales de la estructura.}
  \label{fig:repOK1}
\end{figure}

Siguiendo con el análisis del \emph{repOK} de la Figura \ref{fig:NCL-repOK}, las líneas 12 a 21 del método verifican que la lista principal sea una lista circular doblemente enlazada. Veamos en detalle lo que esto significa:
\begin{itemize}
    \item \textbf{Lista Circular:} Una lista circular es aquella en la que el último elemento de la lista está enlazado al primer elemento, formando un ciclo. En otras palabras, si avanzamos a través de la lista desde el primer elemento, llegaremos eventualmente al último elemento y luego volveremos al primer elemento.
    \item \textbf{Doblemente Enlazada:} En una lista doblemente enlazada, cada nodo tiene dos enlaces, uno que apunta al nodo anterior y otro que apunta al nodo siguiente. Esto permite recorrer la lista en ambas direcciones: desde el primer nodo hasta el último y viceversa.
\end{itemize}
El método Java, que especifica la estructura entre las líneas 12 a 21, realiza un recorrido sobre la lista principal. En la Figura \ref{fig:repok2} se pueden observar ejemplos de instancias que pasan o no esta sección de restricciones del método. La instancia de la izquierda muestra una lista principal correctamente construida, mientras que la instancia de la derecha tiene el error de que la lista principal no es cíclica, característica que poseen las listas principales (donde se guardan los datos) de NCL. El campo \emph{next} del nodo \textbf{NO} apunta a \emph{null}, lo que rompe la propiedad de ciclicidad. Esta restricción se contempla en la línea 16 del \emph{repOK}.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{images/repok2.jpg}
  \caption{Ejemplo de una instancia válida y otra no válida de acuerdo al \emph{repOK} en la lista principal.}
  \label{fig:repok2}
\end{figure}

Por último, el método \emph{repOK} de la Figura \ref{fig:NCL-repOK}, en las líneas 22 a 37 verifica propiedades sobre la lista caché. Esta debe ser una lista simplemente enlazada terminada en un valor nulo (y se verifica la consistencia de los campos de tamaño en el proceso). Como ejemplo de esta situación, mostramos dos nuevas instancias en la Figura \ref{fig:repok3}. La primera es una instancia válida de la lista caché y el \emph{repOK} nos devuelve \texttt{true}. La segunda instancia en la figura nos muestra una instancia inválida de acuerdo a la especificación. Esto se debe a que la lista caché (la lista de la parte inferior de la estructura) es cíclica. La insatisfacción de la propiedad se da cuando el método vuelve a insertar el mismo nodo al conjunto \emph{visited}. Este conjunto recorre la lista y chequea en la línea 33 si vuelve a pasar por un nodo ya visitado. En caso de que esto suceda, retorna \texttt{false}. Esto es lo que sucede en la instancia de la Figura \ref{fig:repok3}.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.3]{images/repok3.jpg}
  \caption{Ejemplo de una instancia válida y otra no válida de acuerdo al \emph{repOK} en la lista caché.}
  \label{fig:repok3}
\end{figure}

Este método \emph{repOK} está implementado siguiendo las recomendaciones de los autores del enfoque de generación exhaustiva acotada de BEAPI, utilizando la herramienta \textsf{Korat} \cite{Boyapati02}. La función devuelve \emph{falso} tan pronto como detecta una violación en alguna propiedad esperada de la estructura actual. En caso contrario, devuelve \emph{verdadero} al finalizar el método. Este enfoque permite a \textsf{Korat} podar eficientemente grandes porciones del espacio de búsqueda al encontrar restricciones incumplidas, mejorando así significativamente su eficiencia.

Sin embargo, en el \emph{repOK} que se presenta en la figura \ref{fig
}, se puede observar que algunas restricciones están comentadas, lo que indica la ausencia de validaciones cruciales. Estas restricciones no estaban presentes en la versión original del \emph{repOK} que tomamos de Roops; las incorporamos después de analizar las estructuras generadas para las pruebas que resultaron incorrectas.

La omisión de restricciones en el \emph{repOK} tiene un impacto directo y considerable en la cantidad de estructuras que \textsf{Korat} genera. Esta falta de precisión no solo aumenta exponencialmente el número de estructuras generadas, sino que también complica la tarea de identificar cuáles son válidas y cuáles no. Por ejemplo, cuando se ejecuta \textsf{Korat} con el \emph{repOK} sin las restricciones comentadas, se generan 54.5 millones de estructuras para un \emph{scope} de 8. Al incluir las restricciones faltantes, la cantidad de estructuras generadas se reduce drásticamente a solo 2.8 millones para el mismo \emph{scope}.

Este incremento masivo en la generación de estructuras debido a la omisión de restricciones tiene implicaciones graves para el proceso de testing. Aumenta la probabilidad de que se generen falsos positivos, es decir, estructuras que cumplen con las propiedades básicas pero que no son representativas de casos válidos. Estos falsos positivos pueden llevar a realizar pruebas innecesarias o a interpretar incorrectamente los resultados del testing, comprometiendo la calidad del software.

Motivados por estos desafíos y la complejidad inherente a la escritura de métodos \emph{repOK} precisos para la generación exhaustiva acotada, hemos desarrollado una técnica que hemos denominado BEAPI. Esta técnica será detallada en las siguientes secciones, y busca ofrecer una solución más robusta y precisa para la generación y validación de estructuras en el contexto de pruebas exhaustivas.


\section[BEAPI]{BEAPI}
\label{sec:beapiIntro}

En esta sección discutimos las ideas principales de nuestros enfoques para generar de manera eficiente un conjunto exhaustivo acotado de objetos, haciendo solo llamadas a la API de un módulo. Nuestro enfoque se basan en la generación de pruebas dirigida por retroalimentación, explicado en la sección \ref{sec:feedback-directed-test-gen}.
El enfoque propuesto, denominado \textsf{BEAPI} (Bounded Exhaustive from an API), introduce una técnica innovadora para la generación exhaustiva acotada. Este enfoque se basa en la realización de llamadas a los métodos de la API del software bajo prueba (SUT). Al igual que otros enfoques de generación de pruebas basados en API, \textsf{BEAPI} crea secuencias de llamadas a métodos de la API, conocidas como secuencias de test \cite{Ammann16}, y las ejecuta para generar estructuras. 

A diferencia de los enfoques de generación basados en caja negra, \textsf{BEAPI} no requiere una especificación formal de las propiedades de las estructuras. Al igual que otras técnicas de generación exhaustiva acotada (BEG), el usuario solo debe proporcionar los alcances para la generación, que se abordan en detalle en la sección correspondiente.  Esto permite generar estructuras válidas sin requerir una especificación detallada de las propiedades de las estructuras, reduciendo así la carga de trabajo para el programador.

La principal ventaja de \textsf{BEAPI} es que requiere un esfuerzo menor de especificación para realizar la generación exhaustiva acotada. Si los métodos de la API utilizados en la generación son correctos, todas las estructuras generadas serán válidas para su construcción. El programador solo necesita asegurarse de que los métodos de la API lancen excepciones cuando se violen las reglas de uso, siguiendo un estilo de programación defensivo \cite{Liskov00}. En la mayoría de los casos, esto implica verificar condiciones muy simples en las entradas. Por ejemplo, el método para eliminar (\emph{remove(int)}) un elemento de una \texttt{NCL} en un índice pasado como parámetro lanza una \texttt{IllegalArgumentException} cuando se llama con un índice menor a 0 o mayor al \emph{size} de la lista. El \emph{listing} de la figura \ref{fig:algoProgDefensiva}  se puede observar que la implementación del método se encarga de cumplir con la especificación indicada \texttt{NCL}.
Para hacer esto


\begin{figure}[!thb]
\begin{lstlisting}
public Object removeIndex(int index) {
  // Check precondicion
  if(index < 0 || index >= size)
      throws new IllegalArgumentException();  
  . . .
}

\end{lstlisting}
\caption{Programación defensiva aplicada en métodos de la API}
\label{fig:algoProgDefensiva}
\end{figure}


Es importante destacar que el enfoque \textsf{BEAPI} aborda las dificultades de escribir especificaciones formales para la generación de estructuras exhaustiva acotadas al aprovechar la ejecución de las rutinas de la API y aplicar técnicas de poda para mejorar la eficiencia de la generación.

% La generación exhaustiva de todas las secuencias de prueba factibles a partir de rutinas hasta una longitud máxima, también conocida como generación por fuerza bruta, es un enfoque intrínsecamente combinatorio que consume una gran cantidad de recursos computacionales, incluso para alcances pequeños. Por lo tanto, \textsf{BEAPI} utiliza varias técnicas de poda que son fundamentales para mejorar su eficiencia y permitir la escalabilidad a alcances más grandes.

% En primer lugar, \textsf{BEAPI} ejecuta las secuencias de prueba y descarta aquellas que producen excepciones que violan las reglas de uso de la API, como \emph{IllegalArgumentException} e \emph{IllegalStateException} en Java.

% En segundo lugar, \textsf{BEAPI} implementa la técnica de coincidencia de estados, la cual descarta secuencias de métodos que generan estructuras que ya han sido creadas por secuencias de métodos exploradas previamente. Esta técnica se describe en detalle en la sección \ref{sec:state-matching}.

% En tercer lugar, \textsf{BEAPI} utiliza un subconjunto de las rutinas de la API para crear las secuencias de prueba.
% Este subconjunto se identifica mediante un algoritmo de búsqueda greedy y una función de valoración que tiene en cuenta qué subconjunto permite crear la mayor cantidad de objetos utilizando \textsf{BEAPI} en el menor tiempo posible. Este proceso se detalla en el capítulo \ref{cap:builders}.

A continuación, explicaremos en detalle cada una de estas optimizaciones.

% \cacho{TODO: no se si agregar arbolitos de exploracion para explicarlos}
% \begin{tikzpicture}
%     [level 1/.style={sibling distance=27mm},
%    level 2/.style={sibling distance=25mm},
%    every node/.style={rectangle,draw,fill=white,minimum size=10mm,align=center,font=\tiny},
%    edge from parent/.style={draw}]
   
%   % Raíz
%   \node {n = new NCL()}
%     % Hijos
%     child {node {n = new NCL() \\
%                 n.add(int)}
%       child {node {n = new NCL() \\
%                     n.method()}}
%       child {node {n = new NCL() \\
%                     n.anotherMethod()}}
%     }
%    child {node {n = new NCL() \\
%                 n.addFirst()}}
%    child {node {n = new NCL() \\
%                 n.remove()}}
%     child {node {...}}
%     % child {node {Método N}};
% \end{tikzpicture}



\section{Scope}
\label{sec:scope}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{images/NCL-instances.png}
    \caption{Tres instancias de NodeCachingLinkedList con exactamente dos nodos}
    \label{fig:ncl-instances}
\end{figure}

\begin{figure}[H]
\begin{lstlisting}[keywordstyle=\scriptsize\ttfamily]
max.objects=k
int.range=0:k
strings=str1,str2,str3
omit.fields=NCL.DEFAULT_MAXIMUM_CACHE_SIZE
\end{lstlisting}
\caption{\textsf{BEAPI}'s scope definition for \texttt{NCL} (max. nodes 3)}
\label{fig:NCL-fin-BEAPI}
\end{figure}

En el contexto de la generación exhaustiva acotada, el término \emph{scope} se refiere al límite o alcance que se establece para la generación de estructuras. Es una restricción que define cuántos objetos de un tipo particular pueden aparecer en las estructuras generadas. Esta restricción es esencial para controlar el tamaño y la complejidad del espacio de búsqueda de estructuras durante la generación exhaustiva. Sin un límite en el número de objetos que pueden aparecer en las estructuras generadas, el espacio de búsqueda podría ser infinito o extremadamente grande. Esto hace que la generación sea impracticable en la mayoría de los casos debido al tiempo y los recursos requeridos.  En muchos casos, el conjunto de estructuras relevantes o interesantes es finito y puede definirse mediante un \emph{scope} adecuado. Al generar solo un conjunto finito de estructuras, se pueden abordar de manera exhaustiva todos los casos posibles.

Para limitar el número de estructuras generadas, BEAPI necesita definirlo en un archivo de descripción simple en formato \texttt{java.properties}, en el cual, además, se establecen algunos otros parámetros. En la figura \ref{fig:NCL-fin-BEAPI}, en la línea 1, se puede observar como establecer el \emph{scope} para un caso específico con la sentencia \emph{max.objects}. Este valor (\emph{k}) debe ser un valor entero. Supongamos el caso de la figura \ref{fig:ncl-instances} de instancias de \texttt{NCL}.  El límite $k$ representa el número máximo de objetos que se pueden crear para cada clase (en la Figura \ref{fig:ncl-instances}, el número de nodos en los objetos NCL está acotado por $k=2$). Esto especifica el número máximo de objetos diferentes (alcanzables desde la raíz) permitidos en una estructura. Las secuencias de prueba generadas por \emph{BEAPI} que crean estructuras que exceden este número (para cualquier clase) se descartan y no se siguen extendiendo

Nuestra técnica, basada en generación de test por feedback, necesita, también, un conjunto de valores primitivos especificado por el usuario (enteros, strings, etc) que son utilizados para alimentar a los métodos (que requieran valores primitivos) de la API que se combinan para generar las estructuras del SUT que estamos buscando.
Por ejemplo, en la figura \ref{fig:scope} el método \emph{add(int)}, que agrega un elemento a la lista principal, necesita un entero para el campo \emph{value} de cada nodo. Este valor entero, como es un valor primitivo, se toma de algunos de los valores primitivos que definió el usuario en el archivo de configuración de BEAPI (\ref{fig:NCL-fin-BEAPI}). En la línea 2 y 3 se puede observar que define valores de tipo enteros y valores de tipo string que serán utilizados por los métodos cuando necesiten valores de este tipo. 
\cacho{Explicar sobre objects que son int para nosotros? o esconderlo?}

Cómo último, nuestro archivo de configuración, permite que el usuario especifique que valores desea que no sean tenidos en cuenta a la hora de comparar estructuras. 
Esto toma especial importancia el contexto de estructuras de datos, especialmente en colecciones y contenedores en Java. En estos casos suelen aparecer campos en la clase que representa un contador de modificaciones o cambios realizados en la estructura de datos. Comúnmente son llamados \emph{modCount}. Este es un campo que se utiliza para realizar un seguimiento de las modificaciones que se han realizado en la colección desde su creación o desde la última vez que se realizó un seguimiento. El \emph{modCount} es un campo de tipo entero que se incrementa cada vez que se realiza una modificación en la estructura de datos. Las modificaciones pueden incluir inserciones, eliminaciones, actualizaciones u otras operaciones que afecten la colección. El propósito principal de llevar un contador de modificaciones es facilitar la detección de modificaciones concurrentes o cambios inesperados en la colección por parte de múltiples hilos de ejecución. En la línea 4 del archivo de configuración \ref{fig:NCL-fin-BEAPI}, se puede observar como se especifica aquellos campos que deseamos omitir a la hora de tener una representación canónica de la estructura. Canonicalizar un objeto se refiere a la acción de garantizar que un objeto se encuentre en su forma más básica y representativa, lo que facilita las comparaciones y operaciones con otros objetos similares.
Para lograr todo lo explicado en esta sección, nosotros canonizamos los objetos generados por la ejecución de cada secuencia de métodos y analizamos y trabajamos con su representación canónica.
Para finalizar esta sección, se puede observar en la figura \ref{sec:scope} un ejemplo del espacio de búsqueda de una secuencia generada con la combinación del método constructor de la clase más el método \emph{add} de NCL. En esta figura, se especificó un scope de 3. Esto quiere decir que cuando genera alguna estructura con más de 3 nodos como es en el caso de la última secuencia de la figura, esta es descartada por exceder el límite de nodos en la estructura (el nodo ficticio de la estructura se tiene en cuenta en la definición de \emph{scope})

Imaginemos un conjunto de números representado en diferentes órdenes:
\begin{itemize}
    \item Conjunto 1: \{3, 1, 2\}
    \item Conjunto 2: \{1, 2, 3\}
    \item Conjunto 3: \{2, 3, 1\}
\end{itemize}

Aunque los elementos de cada conjunto son los mismos, el orden de los números varía. Si quisiéramos comparar estos conjuntos para determinar si son equivalentes, el proceso de canonización podría consistir en ordenar los números en cada conjunto de manera ascendente:

\begin{itemize}
    \item Conjunto 1 canonizado: {1, 2, 3}
    \item Conjunto 2 canonizado: {1, 2, 3}
    \item Conjunto 3 canonizado: {1, 2, 3}
\end{itemize}

Tras la canonización, todas las versiones del conjunto resultan idénticas, lo que nos permite determinar fácilmente que los tres conjuntos son equivalentes, independientemente del orden en el que aparecían originalmente los números.

En el contexto de estructuras de datos, este proceso podría implicar reorganizar los nodos, normalizar los valores de ciertos campos, o eliminar detalles que no son relevantes para la comparación, como el \emph{modCount} mencionado anteriormente. Al canonizar, se asegura que dos estructuras de datos se comparen en términos de su contenido esencial, ignorando diferencias superficiales o de implementación.

% (Normalmente, las técnicas basada en generación por retroalimentación guardaría los valores primitivos que son devueltos por la ejecución de las pruebas y reutilizaría estos valores en pruebas futuras). También nuestra técnica descartar secuencias de métodos que crean objetos con más de $k$ objetos (de cualquier tipo), para evitar que se construyan objetos más grandes de lo necesario. 


% \cacho{VER BIEN ESTO DE NO EXTENDERSE, porq para crear estrucutras de 3 nodos a veces necesito crear previamente una de 4 nodos}
% Esto asegura que se generen solo \texttt{NCL} con no más de k nodos. Por ejemplo, la figura \ref{fig:scope}, se puede observar que cuando genera una estructura con mas nodos que el especificado en el archivo de configuración, este no sigue extiendo el arbol de búsqueda. En la figura el scope especificado es 3 (vale aclarar, que el nodo ficticio cuanta como nodo de la estructura.)

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{images/scope.jpg}
    \caption{Representación con scope 3 para NCL}
    \label{fig:scope}
\end{figure}


% Siguiendo el análisis del archivo de configuración de la figura \ref{fig:NCL-fin-BEAPI},
% y el número de valores primitivos disponibles, en nuestro ejemplo de la figura, se especifica enteros del 0 a $k-1$ y cadenas de caracteres: str1, str2, str3. Ademas, se pueden especificar otros valores primitivos como floats, doubles, etc. Esto serán los dominios de datos para los tipos primitivos que necesiten los métodos que serán utilizados. Podemos indicarle a \emph{BEAPI} que ignore algunos campos en el proceso de canonización de objetos, que se lleva a cabo en la ejecución de las secuencias de métodos de la API. Esto permite al usuario controlar qué partes de la estructura del objeto son relevantes para la coincidencia de estados (ver más adelante en la sección \ref{sec:stateMatching}). Por ejemplo,  la línea 4 haría que \emph{BEAPI} omita el tamaño máximo predeterminado de la caché en la coincidencia de estados, que en la API de \emph{NCL} es una constante inicializada en 20 en el constructor de la clase. Es importante que aqui se omitan campos que puede afectar la coincidencia de estados, como el caso del campo \emph{modCount}. Esta variable se utiliza a menudo en estructuras de datos para realizar un seguimiento de las modificaciones o cambios realizados en los datos almacenados, pero claramente no afecta la estructura generada. 
% La configuración mostrada en la Figura~\ref{fig:NCL-fin-BEAPI} es suficiente para que \emph{BEAPI} genere NCL con un máximo de 3 nodos, que contienen enteros del 0 al 2 como valores. 


\section{State Matching}
\label{sec:stateMatching}

Para introducirno en el tema veamos algunos ejemplos de secuencias de test en estructuras de datos:

Estos sos algunos ejemplos de secuencia de test: 
\begin{itemize}
    \item \textbf{Ejemplo 1: Operaciones en una Lista}

    \begin{itemize}
        \item \textbf{Secuencia 1}:

        
\begin{lstlisting}[numbers=none,label=fig:NCLadds, caption= Crear una lista vacía y agregar un elemento, captionpos=b, frame=tb , basicstyle=\scriptsize]
        List<Integer> lista = new ArrayList<>();
        lista.add(5);
\end{lstlisting}


        \item \textbf{Secuencia 2}:
        \begin{verbatim}
        // Crear una lista vacía, agregar y eliminar un elemento, luego agregarlo nuevamente
        List<Integer> lista = new ArrayList<>();
        lista.add(5);
        lista.remove(0);
        lista.add(5);
        \end{verbatim}

        \textbf{Estado resultante}:
        \begin{verbatim}
        Lista: [5]
        \end{verbatim}
    \end{itemize}

    \item \textbf{Ejemplo 2: Eliminación de Elementos en una Lista Vacía}

    \begin{itemize}
        \item \textbf{Secuencia 1}:
        \begin{verbatim}
        // Crear una lista vacía
        List<Integer> lista = new ArrayList<>();
        \end{verbatim}

        \textbf{Estado resultante}:
        \begin{verbatim}
        Lista: []
        \end{verbatim}

        \item \textbf{Secuencia 2}:
        \begin{verbatim}
        // Crear una lista vacía e intentar eliminar un elemento (sin efecto)
        List<Integer> lista = new ArrayList<>();
        lista.remove(new Integer(5)); // No tiene efecto ya que la lista está vacía
        \end{verbatim}

        \textbf{Estado resultante}:
        \begin{verbatim}
        Lista: []
        \end{verbatim}
    \end{itemize}

    \item \textbf{Ejemplo 3: Agregar y Remover en una Pila (Stack)}

    \begin{itemize}
        \item \textbf{Secuencia 1}:
        \begin{verbatim}
        // Crear una pila y apilar un elemento
        Stack<Integer> pila = new Stack<>();
        pila.push(10);
        \end{verbatim}

        \textbf{Estado resultante}:
        \begin{verbatim}
        Pila: [10]
        \end{verbatim}

        \item \textbf{Secuencia 2}:
        \begin{verbatim}
        // Crear una pila, apilar un elemento, desapilarlo y volver a apilar el mismo elemento
        Stack<Integer> pila = new Stack<>();
        pila.push(10);
        pila.pop();
        pila.push(10);
        \end{verbatim}

        \textbf{Estado resultante}:
        \begin{verbatim}
        Pila: [10]
        \end{verbatim}
    \end{itemize}
\end{itemize}

En la generación de objetos con \textsf{BEAPI}, a menudo muchas secuencias de prueba producen la misma estructura. Por ejemplo, en la figura \ref{fig:stateMatching}, insertar un elemento en una lista, luego eliminar y volver a agregarlo a la lista principal, produce un estado que ya fue analizado con solo la secuencia que crea la lista y agrega el elemento. Lo mismo sucede en el caso que se quiera eliminar un objecto de la lista cuando la misma es vacia. Esto va a provocar un nuevo estado que es igual al estado utilizando solo el metodo constructor de la clase. \textsf{BEAPI} asume que las ejecuciones de métodos son deterministas, es decir, cualquier ejecución de una rutina con las mismas entradas produce los mismos resultados. Observamos que para cada estructura distinta $s$, solo necesitamos guardar la primera secuencia de prueba que genera $s$ (y la estructura en sí). Todas las secuencias de prueba generadas posteriormente que también crean $s$ pueden ser descartadas. Si almacenamos muchas secuencias de prueba para la misma estructura, todas estas secuencias tendrían que ser extendidas con nuevas rutinas en iteraciones posteriores de \textsf{BEAPI}, lo que resultaría tener que realizar un cómputo de las secuencias que sería innecesario ya que producen un estado que ya hemos computado y que hemos extendido.  


Por lo tanto, implementamos la coincidencia de estados en \textsf{BEAPI} de la siguiente manera.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/stateMatching1.jpg}
    \caption{Representación con scope 3 para NCL}
    \label{fig:stateMatching}
\end{figure}

Almacenamos todas las estructuras producidas hasta ahora por \textsf{BEAPI} en una forma canónica (ver más abajo). Después de ejecutar la última rutina \texttt{r(p$_1$, ..., p$_k$)} de una nueva secuencia de prueba generada \texttt{T}, comprobamos si alguno de los parámetros de \texttt{r} tiene una estructura no vista antes (no almacenada). Si \texttt{T} no crea ninguna estructura nueva, se descarta. De lo contrario, \texttt{T} y las nuevas estructuras que genera son almacenadas por \textsf{BEAPI}.

Representamos las estructuras asignadas en el heap como grafos etiquetados. Después de la ejecución de un método, un parámetro $p$ (de tipo no primitivo) contiene una referencia al objeto raíz $r$ de un \emph{heap} con raíz (es decir, $p=r$), definido a continuación.

\begin{definition}
Sea $O$ un conjunto de objetos y $P$ un conjunto de valores primitivos (incluido $null$). Sea $F$ el conjunto de campos de todos los objetos en $O$.
\begin{itemize}
\item Un \emph{heap} es un grafo etiquetado $H = \langle O, E\rangle$ con $E = {(o, f, v) | o \in O, f \in F, v \in O \cup P}$.
\item Un \emph{heap con raíz} es un par $RH = \langle r, H \rangle$ donde $r \in O$, $H = \langle O, E\rangle$ es un heap, y para cada $v' \in O \cup P$, $v'$ es alcanzable desde $r$ a través de campos en $F$.
\end{itemize}
\end{definition}

El caso especial $p = null$ se puede representar con un \emph{heap} con raíz que tiene un nodo ficticio y un campo ficticio que apunta a null. En lenguajes como Java, cada objeto se identifica por la dirección de memoria donde se encuentra. Cambiar las direcciones de memoria donde se asignan los objetos no tiene efecto desde el punto de vista del programa, ya que el programador no tiene control sobre la representación de bajo nivel de la memoria (a diferencia de otros lenguajes como C). Los \emph{heaps} obtenidos mediante permutaciones de las direcciones de memoria de sus objetos componentes se llaman \emph{heaps isomorfos}. Evitamos la generación de \emph{heaps isomorfos} empleando una representación canónica para los heaps \cite{Iosif02,Boyapati02}. Los heaps con raíz se pueden canonizar eficientemente mediante un enfoque llamado \emph{linearización} \cite{Iosif02,Xie04}, que transforma un heap con raíz en una secuencia única de valores.

\bigbreak

\begin{figure}[!th]
\begin{lstlisting}
int[] linearizar(O raiz, Heap<O, E> heap, int alcance, Regex omitirCampos) {
    Map ids = new Map(); // mapea nodos a sus identificadores unicos
    return lin(raiz, heap, alcance, ids, omitirCampos);
}
int[] lin(O raiz, Heap<O, E> heap, int alcance, Map ids, Regex omitirCampos) {
    if (ids.containsKey(raiz))
        return secuenciaUnica(ids.get(raiz));
    if (ids.size() == alcance)
        throw new ExcepcionAlcanceSuperado();
    int id = ids.size() + 1;
    ids.put(raiz, id);
    int[] seq = secuenciaUnica(id);
    Edge[] campos =
    ordenarPorCampo({ <raiz, f, o> en E }, omitirCampos);
    foreach (<raiz, f, o> en campos) {
        if (esPrimitivo(o))
            seq.add(representacionUnica(o));
        else
            seq.append(lin(o, heap, alcance, ids, omitirCampos));
    }
    return seq;
}
\end{lstlisting}
\caption{Algoritmo de linearización}
\label{alg:linearization}
\end{figure}


% java.util.LinkedList.MAX_ARRAY_SIZE&java.util.LinkedList:0&2147483639
% java.util.LinkedList.first&java.util.LinkedList:0&java.util.LinkedList$Node:0
% java.util.LinkedList.last&java.util.LinkedList:0&java.util.LinkedList$Node:1
% java.util.LinkedList.modCount&java.util.LinkedList:0&2
% java.util.LinkedList.serialVersionUID&java.util.LinkedList:0&876323262645176354
% java.util.LinkedList.size&java.util.LinkedList:0&2
% traversal.DummyHeapRoot.theroot&traversal.DummyHeapRoot:0&java.util.LinkedList:0



El algoritmo mostrado en la Figura~\ref{alg:linearization} es una versión personalizada para \textsf{BEAPI} del algoritmo de linearización presentado en \cite{Xie04}. Esta versión ha sido modificada para informar cuando los objetos exceden los alcances y para permitir la omisión de campos de la estructura de dato en análisis.

El algoritmo \texttt{linearize} invoca a la función \texttt{lin} y realiza un recorrido en profundidad del heap comenzando desde la raíz (línea 3). Durante este recorrido, se asignan identificadores diferentes a cada objeto visitado. Cuando se visita un objeto por primera vez, se le asigna un nuevo identificador único (líneas 10-11) y se crea una secuencia de un solo elemento llamada \texttt{seq}, que contiene el identificador de objeto y representa el objeto (línea 12). El mapa \texttt{ids} se utiliza para almacenar el mapeo entre los objetos y los identificadores de objeto únicos.

A continuación, se recorren los campos del objeto en un orden predefinido (por ejemplo, por nombre) y se construye la linearización de cada valor de campo, que se agrega a la secuencia \texttt{seq} (líneas 13-19). Si un campo almacena un valor primitivo (línea 15), se agrega una secuencia de un solo elemento que representa ese valor a \texttt{seq} (línea 16). Si el campo hace referencia a otro objeto, se realiza una llamada recursiva a la función \texttt{lin} para transformarlo en una secuencia, que luego se agrega a \texttt{seq} (línea 18).

Al final del ciclo, la secuencia \texttt{seq} contiene la representación canónica de todo el heap que comienza en la raíz, y se devuelve por la función \texttt{lin} (línea 20). Sin embargo, si se encuentra un objeto que ya ha sido visitado en llamadas recursivas anteriores, es decir, que ya tiene un identificador asignado en \texttt{ids}, el algoritmo devuelve una secuencia de un solo elemento que contiene el identificador único del objeto (líneas 6-7).

Si hay más de \texttt{scope} objetos alcanzables desde la raiz del \emph{heap}, lo cual significa que se ha superado el límite establecido en los alcances, el algoritmo \texttt{linearize} devuelve una excepción para informar esta situación (líneas 9-10). Además, el parámetro \texttt{linearize} también acepta una expresión regular llamada \texttt{omitFields}, que se utiliza para coincidir con los nombres de los campos que deben ser omitidos durante la canonización del \emph{heap}.

Para omitir dichos campos, se implementa la función \texttt{sortByField} (línea 13) de manera que no se devuelven las aristas correspondientes a los campos cuyos nombres coinciden con \texttt{omitFields}. Es importante destacar que este comportamiento es específico de nuestro enfoque, ya que la excepción será utilizada por \textsf{BEAPI} para descartar secuencias de prueba que generen objetos que excedan los alcances permitidos.

Cabe destacar que la linearización proporciona una forma eficiente de comparar objetos: dos objetos se consideran iguales si y solo si las secuencias correspondientes generadas por la función \texttt{linearize} son iguales.


\section{Uso de Builders en BEAPI}
\label{sec:builders}
En esta sección, utilizaremos una optimización que hemos desarrollado y que es una parte importante de esta tesis \ref{cap:builders}. Estos métodos builders nos permiten generar cualquier configuración posible que se puede construir con la API (pudiendo generar de manera exhaustiva, es decir, generando todos los objetos posibles hasta un alcance dado).
Dado que la cantidad de combinaciones factibles de métodos crece de manera exponencial con el número de métodos, es crucial reducir la cantidad de métodos que \textsf{BEAPI} utiliza para producir secuencias de prueba. Para abordar este problema, utilizamos el enfoque de identificación automática de métodos builders que se describe en el capítulo (Capítulo \ref{cap:builders}). Este enfoque nos ayuda a encontrar un subconjunto de métodos de la API que son suficientes para generar conjuntos de estructuras acotadas y exhaustivas. 
El uso de métodos \textit{builders} permite generar estados complejos sin necesidad de ejecutar múltiples pasos individuales. Esto reduce significativamente la cantidad de secuencias que BEAPI necesita explorar, optimizando el análisis. 

Por ejemplo, consideremos una clase \texttt{NodeCachingLinkedList (NCL)}. Sin \textit{builders}, para generar una lista con un solo elemento, se necesitarían las siguientes operaciones:


Esto implica ejecutar al menos dos pasos para construir el estado deseado. Sin embargo, con un método \textit{builder} predefinido, se puede simplificar a:

\begin{lstlisting}
ncl.NodeCachingLinkedList.<init>(42) // Crear lista con un elemento directamente
\end{lstlisting}

De esta manera, los metodos \textit{builders} permite construir un estado equivalente sin necesidad de explorar todas las combinaciones posibles de pasos intermedios.

En el contexto de \textsf{BEAPI}, utilizamos el algoritmo de búsqueda de tipo Greedy para identificar este subconjunto de métodos generadores.El enfoque está basado en el algoritmo de optimización \emph{Hill Climbing} que logra un mejor rendimiento. Aunque \emph{Hill Climbing} puede ser menos preciso, ya que puede incluir algunos métodos que no son necesarios para producir un conjunto acotado y exhaustivo de estructuras, en nuestros experimentos, \emph{Hill Climbing}  funcionó muy bien y calculó consistentemente conjuntos sufientes de métodos generadores (verificamos que coincidieran con los métodos que identificados manualmente y que son generadores en cada caso de estudio). 
% Nuestro objetivo aquí es evaluar el impacto de utilizar builders para la generación exhaustiva acotada (BEG) a partir de una API.

Para la identificación de métodos generadores, utilizamos como función de evaluación un generador exhaustivo para crear objetos de la API (ver sección \ref{sec:fitness}). Este generador es precisamente BEAPI que estamos desarrollando en esta sección. 
La idea clave que hace factible la identificación de los métodos generadores es que a menudo los generadores identificados para un \emph{scope} relativamente pequeño utilizan el mismo conjunto de métodos que se necesitan para crear estructuras de cualquier tamaño. En otras palabras, una vez que el alcance para el cálculo de los métodos generadores es lo suficientemente grande, aumentar el alcance producirá como resultado el mismo conjunto de constructores. Este resultado se asemeja a la hipótesis de la cota pequeña para la detección de errores[\cite{Andoni02} (a la técnica de \emph{transcoping} \cite{Rosner13}).
En todos nuestros casos de estudio, un \emph{scope} de 5 fue suficiente para calcular los métodos generadores de objetos. 
Después de identificar eficientemente los métodos generadores con un alcance pequeño, podemos ejecutar \textsf{BEAPI}, utilizando los métodos generadores identificados y, con un alcance mayor. Esto nos permite generar objetos más grandes y utilizarlos para probar el software bajo prueba.

En la mayoría de nuestros casos de estudio, los métodos generadores de objetos consisten en un constructor y un solo método para agregar elementos a la estructura. Como por ejemplo en el caso de listas simplemente enlazadas. 
Sin embargo, nuestro enfoque automatizado de identificación de métodos generadores mostró que, en el caso de los árboles Rojo-Negro (ver figura \ref{fig:redBlack}), también se requería un método de eliminación (para alcances mayores que 3). 

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{images/redBlackTree.jpg}
  \caption{Ejemplo de un árbol red-black}
  \label{fig:redBlack}
\end{figure}

Esto se debe a que estos tipos de árboles necesitan una configuración específica de equilibrio (coloreando los nodos en rojo y negro) que no se pueden construir solo agregando elementos al árbol. En contraste, los árboles AVL (figura \ref{fig:avl}), que también son estructuras balanceadas, no requieren el método de eliminación como parte de su subconjunto de métodos generadores.
Los árboles AVL están siempre equilibrados, de tal modo que para todos los nodos, la altura de la rama izquierda no debe diferir en más de una unidad de la altura de la rama derecha o viceversa. Gracias a esta forma de equilibrio (o balanceo), la complejidad de una búsqueda en uno de estos árboles se mantiene siempre en orden de complejidad O(log n). 
Para este caso de árboles, solo el constructor de la clase y una rutina de adición son suficientes. Esto demuestra que la identificación de métodos generadores no es trivial de realizar manualmente.



\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{images/avl.jpg}
  \caption{Ejemplo de un árbol AVL}
  \label{fig:redBlack}
\end{figure}


Para obtener más información sobre esta sección, invitamos al lector a leer el siguiente capítulo donde se explica en detalle el desarrollo de esta técnica (Capítulo \ref{cap:builders}).

\section{Algoritmo de BEAPI}
\label{sec:beapiTechnique}

A continuación se muestra un pseudocódigo de \emph{BEAPI} en la Figura \ref{alg:beapi}. \emph{BEAPI} toma como entradas una lista de métodos de una API,  \texttt{methods}. Estos métodos pueden ser la API completa o un subconjuntos de métodos de la misma. En nuestro caso, como hemos aplicado anteriormente, vamos a utilizar los métodos \emph{builders} previamente identificados. Ademas, el algoritmo recibe de parámetro, el alcance (\emph{scope}) de objetos para la generación; una lista para crear valores de cada tipo primitivo proporcionado en la descripción del alcance, \texttt{primitives} (creados automáticamente a partir de las opciones de configuración como \texttt{int.range}, \texttt{string}, etc., ver Figura~\ref{fig:NCL-fin-BEAPI}); y una expresión regular que coincide con los campos que se deben omitir en la canonización de las estructuras, \texttt{omitFields}. Notar que se pueden pasar métodos de más de una clase en \texttt{methods} si se desean generar objetos para varias clases en la misma ejecución de \textsf{BEAPI}, por ejemplo, cuando los métodos de una clase toman objetos de otra clase como parámetros. La estructura de datos de tipo Map, \texttt{currSeqs} de \emph{BEAPI}  almacena, para cada tipo, la lista de secuencias de test que se sabe que generan estructuras del tipo correspondiente. El \cacho{check}\texttt{currSeqs} se inicia con todas las secuencias de tipos primitivos en \texttt{primitives} (líneas 3-4). En cada iteración del bucle principal (líneas 6-39), \textsf{BEAPI}  crea nuevas secuencias para cada método disponible \texttt{m} (línea 9), explorando exhaustivamente todas las posibilidades para crear secuencias de prueba utilizando \texttt{m} e inputs generados en iteraciones anteriores y almacenados en \texttt{currSeqs} (líneas 10-35). Las secuencias de prueba recién creadas que generan nuevas estructuras en la iteración actual se guardan en el mapa \texttt{newSeqs} (inicializado vacío en la línea 7). Se puede observar que todas las secuencias generadas se agregan a \texttt{currSeqs} al final de la iteración principal (línea 40). Si no se producen nuevas estructuras en la iteración actual (\texttt{newStrs} es falso en la línea 36), el bucle principal del algoritmo de  \textsf{BEAPI}  termina su ejecución y se devuelve la lista de todas las secuencias en \texttt{currSeqs} (línea 40).


\begin{figure}[t!]

\begin{lstlisting}[language=Java]
public BEAPI(List methods, int scope, Map<Type, List<Seq>> primitives, 
Regex omitFields) {
    Map<Type, List<Seq>> currSeqs = new Map();
    currSeqs.addAll({ T->L | T->L in primitives });
    Set canonicalStrs = new Set();
    for (int it=0; true; it++) {
      Map<Type, List<Seq>> newSeqs = new Map();
      boolean newStrs = false;
      for (m(T1,...,Tn):Tr: methods) {
        Map<Type, List<Seq>> seqsT1 = currSeqs.getSequencesForType(T1);
        ...
        Map<Type, List<Seq>> seqsTn = currSeqs.getSequencesForType(Tn);
        for ((s1,...,sn): seqsT1 x ... x seqsTn) {
          Seq newSeq = createNewSeq(s1,...,sn,m);
          o1,...,on,or,failure,exception = execute(newSeq);
          if (failure) 
            throw new ExecutionFailedException(newSeq);
          if (exception) 
            continue;
          c1,...,cn,cr,outOfScope = makeCanonical(o1,...,on,scope,omitFields);
          if (outOfScope) 
            continue;
          if (isReferenceType(T1) and !canonicalStrs.contains(c1)) {
                canonicalStrs.add(c1);
                newSeqs.addSeqForType(T1, newSeq);
                newStrs = true;
          }
          ...
          if (isReferenceType(Tr) and !canonicalStrs.contains(cr)) {
                canonicalStrs.add(cr);
                newSeqs.addSeqForType(Tr, newSeq);
                newStrs = true;
          }
        }
      }
      if (!newStrs) 
        break;
      currSeqs.addAll(newSeqs);
    }
    return currSeqs.getAllSeqsAsList();
}
\end{lstlisting}
\caption{\textsf{BEAPI} algorithm}
\label{alg:beapi}
\end{figure}

A continuación, comentaré los detalles del bucle for en las líneas 9-35. En primer lugar, se obtienen todas las secuencias que se pueden utilizar para construir entradas para \texttt{m} en \texttt{seqsT$_1$}, ..., \texttt{seqsT$_n$}. \textsf{BEAPI} explora cada tupla \texttt{(s$_1$}, ..., \texttt{s$_n$)} de entradas factibles para \texttt{m}. A continuación, se ejecuta \texttt{createNewSeq} (línea 14), que construye una nueva secuencia de prueba \texttt{newSeq} realizando la composición secuencial de las secuencias de prueba \texttt{s$_1$}, ..., \texttt{s$_n$} y la rutina \texttt{m}, y reemplazando los parámetros formales de \texttt{m} por las variables que crean los objetos requeridos en \texttt{s$_1$}, ..., \texttt{s$_n$}. Luego, se ejecuta \texttt{newSeq} (línea 15) y como resultado podemos tener que, produzca un fallo (\texttt{failure} se establece en verdadero), genera una excepción que representa un uso no válido de la API (\texttt{exception} se establece en verdadero) o su ejecución tiene éxito y crea nuevos objetos \texttt{o$_1$,$\ldots$,o$_n$}. En caso de fallo, se lanza una excepción y \texttt{newSeq} se presenta al usuario como evidencia del fallo (línea 17). Si se lanza un tipo diferente de excepción, \textsf{BEAPI} asume que corresponde a un mal uso de la API (ver más abajo), descarta la secuencia de prueba (línea 19) y continúa con la siguiente secuencia candidata. De lo contrario, la ejecución de \texttt{newSeq} genera nuevos objetos \texttt{o$_1$,$\ldots$,o$_n$} (o valores de tipos primitivos) que se canonizan mediante \texttt{makeCanonical} (línea 20) --ejecutando \texttt{linearize} de la Figura~\ref{alg:linearization} en cada estructura. Si alguna de las estructuras producidas por \texttt{newSeq} excede el scope, \texttt{makeCanonical} establece \texttt{outOfScope} en verdadero, \textsf{BEAPI} descarta \texttt{newSeq} y continúa con la siguiente (línea 22).
Esto garantiza que \textsf{BEAPI} nunca crea objetos más grandes que lo permitidio por el alcance.
Si ninguna de las situaciones anteriores ocurre, quiere decir que ha pasado todos los chequeos la secuencia corriente y, \texttt{makeCanonical} devuelve versiones canónicas de \texttt{o$_1$,$\ldots$,o$_n$} en las variables \texttt{c$_1$,$\ldots$,c$_n$}, respectivamente. A continuación, \textsf{BEAPI} realiza una coincidencia de estado comprobando que la estructura canónica \texttt{c$_1$} sea de tipo de referencia y que no haya sido creada por ninguna secuencia de prueba anterior (línea 23). Observa que \texttt{canonicalStrs} almacena todas las estructuras ya visitadas. Si \texttt{c$_1$} es una nueva estructura, se agrega a \texttt{canonicalStrs} (línea 24) y se agrega la secuencia que crea \texttt{c$_1$}, \texttt{newSeq}, al conjunto de secuencias de prueba que producen estructuras de tipo \texttt{T$_1$} (\texttt{newSeqs} en la línea 27). Además, se establece \texttt{newStrs} en verdadero para indicar que al menos se ha creado un nuevo objeto en la iteración actual (línea 26). Este proceso se repite para los objetos canónicos \texttt{c$_2$,$\ldots$,c$_n$,c$_r$} (líneas 29-32).
\cacho{Un for aqui}

\textsf{BEAPI} distingue los fallos del mal uso de la API en función del tipo de excepción (similarmente a las técnicas anteriores de generación de pruebas basadas en API \cite{Pacheco07}). Por ejemplo,\\
\texttt{IllegalArgumentException} y \texttt{IllegalStateException} corresponden a usos incorrectos de la API, y el resto de las excepciones se consideran fallos de manera predeterminada. La implementación de \textsf{BEAPI} permite al usuario seleccionar las excepciones que corresponden a fallos y aquellas que no, configurando los parámetros correspondientes. Como se mencionó en la Sección~\ref{sec:motivating-example}, \textsf{BEAPI} asume que los métodos de la API lanzan excepciones cuando no se pueden ejecutar con entradas inválidas. Sostenemos que esta es una práctica común, llamada programación defensiva \cite{Liskov00}, que todos los programadores deberían seguir, ya que resulta en un código más robusto y mejora las pruebas de software en general \cite{Ammann16} (además de ayudar a las herramientas de generación de pruebas automatizadas). También argumentamos en la Sección~\ref{sec:motivating-example} que el esfuerzo de especificación requerido para la programación defensiva es mucho menor que escribir \texttt{repOK}s precisos (y eficientes) para BEG, y esto era cierto después de inspeccionar manualmente el código fuente de nuestros casos de estudio. Por otro lado, ten en cuenta que \textsf{BEAPI} puede utilizar especificaciones formales para revelar errores en la API, por ejemplo, ejecutando \texttt{repOK} y comprobando que devuelve verdadero en cada objeto generado del tipo correspondiente (como en Randoop \cite{Pacheco07}). Sin embargo, las especificaciones utilizadas para encontrar errores no necesitan ser muy precisas (por ejemplo, el \texttt{repOK} subespecificado de \texttt{NCL} de la Sección~\ref{sec:motivating-example} es válido para encontrar errores), ni estar escritas de una manera particular (como lo requiere \textsf{Korat}). \textsf{BEAPI} también puede utilizar otros tipos de especificaciones más débiles y más simples de escribir para revelar errores, como violaciones de contratos específicos del lenguaje (por ejemplo, \texttt{equals} es una relación de equivalencia en Java), propiedades metamórficas \cite{Chen19}, afirmaciones proporcionadas por el usuario (\texttt{assert}), etc.

Otra ventaja de \textsf{BEAPI} es que, para cada objeto generado, proporciona una secuencia de prueba que se puede ejecutar para crear el objeto. Esto contrasta con los enfoques basados en especificaciones (que generan un conjunto de objetos a partir de \texttt{repOK}). Encontrar una secuencia de invocaciones a métodos de la API que creen una estructura específica es un problema difícil en sí mismo, que puede ser bastante costoso computacionalmente \cite{Braione17} o requerir un esfuerzo significativo para realizarlo manualmente. Por lo tanto, a menudo los objetos generados por enfoques basados en especificaciones están "incrustados" cuando se utilizan para probar un SUT (por ejemplo, mediante el uso de reflexión en Java), lo que hace que las pruebas sean muy difíciles de entender y mantener, ya que dependen de los detalles de implementación de bajo nivel de las estructuras \cite{Braione17}.

