\chapter[Introducción]{Introducción}
\label{cap:introduccion}

% Esqueleto de la intro general de la tesis
% Contexto: Explayarse sobre por qué los análisis de software son importantes. Meter énfasis en el testing y la verificación
% El análisis de software es una tarea crucial en el campo de la Ingeniería de
% Software \cite{}. Por ejemplo, la generación automática de tests \cite{} y la verificación \cite{} son muy efectivos para encontrar defectos en el software.


% Contribuciones:
% 1- Definición y cómputo automático de builders

% Cuales son los análisis que se podrían beneficiar de los builders y por qué

% Definición intuitiva de builders
% Introducción de cómputo automático de builders

% 2- BEAPI
% Importancia de técnicas exhaustivas acotadas

% Por que me conviene generar a partir de la API

% Descripción breve de la técnica


% Breve resumen de los resultados




\pp{1- Traducir la intro del paper de builders y ponerla acá.}
A medida que el software se vuelve más ubicuo gracias a los rápidos avances tecnológicos, garantizar la corrección funcional del software es más crucial que nunca. Por lo tanto, un área de investigación de creciente importancia es la del análisis automatizado de software, cuyo objetivo es asistir a los ingenieros, a través de herramientas de análisis automatizado, en la identificación de deficiencias tanto en el software como en los modelos relacionados con el software. La generación automatizada de pruebas \cite{Ponzio:2016, Rosner15, Abad13, Galeotti:2010, Khalek:2011, Pasareanu:2010, Gligoric10, Tillmann:2008, Pacheco07}, los \emph{model checkers} para software \cite{Visser06, Visser05, Clarke:2004}, y los análisis estáticos \cite{Calcagno:2011, Itzhaky:2014}, entre otros, son enfoques destacados en esta línea de investigación.

Aunque estas técnicas implican en muchos casos análisis completamente automatizados, su aplicación suele requerir cierto esfuerzo por parte de los ingenieros de software. Los \emph{model checkers} para software dependen de la definición de \emph{drivers}, programas que permiten construir entradas para el código bajo análisis. De manera similar, en los enfoques de pruebas unitarias parametrizadas \cite{Tillmann:2010} es obligatorio un mecanismo para construir entradas. Algunas herramientas basadas en la ejecución simbólica requieren las llamadas "fábricas de objetos" para construir casos de prueba que incluyan entradas con tipos no primitivos \cite{Tillmann:2008}. Las técnicas automatizadas de generación de pruebas basadas en la API de un módulo pueden usarse para construir entradas de tipos no primitivos \cite{Pacheco07, Fraser11}, automatizando así los problemas de generación de entradas antes mencionados. Sin embargo, suelen presentar dificultades para generar un buen conjunto de entradas diversas para módulos con estados complejos. Esto es aún más difícil para módulos con APIs ricas \cite{Ponzio:2018}. Muchos autores han abordado este problema definiendo diferentes enfoques para guiar la generación de pruebas y crear conjuntos más diversos de entradas \cite{Ponzio:2018, Ciupa:2008}.

En este trabajo, adoptamos un enfoque diferente para abordar el problema de generar mejores entradas para módulos con estados complejos. Observamos que la selección de rutinas de una API de módulo, para alimentar una herramienta de generación de entradas y construir estructuras de entrada para el análisis de programas (drivers para la verificación de modelos, estructuras de entrada para pruebas unitarias parametrizadas, etc.), tiene un impacto crucial en el análisis. Llamamos \emph{métodos generadores de objectos} a un conjunto de métodos \(B\), extraídos de la API de un módulo \(M\), que pueden emplearse para crear estructuras de entrada en un análisis automatizado de programas para \(M\) (por ejemplo, un driver para la verificación de modelos). Claramente, cuanto mayor sea el número de estructuras diferentes que se puedan crear con \(B\), mayores serán las posibilidades de encontrar errores en \(M\).

Dado que el número de instancias de un módulo de software es potencialmente infinito, y los análisis de programas que abordamos también están limitados en cuanto al número de estructuras que pueden emplear, nos limitamos a un conjunto exhaustivo acotado de estructuras para \(M\) \cite{Boyapati02} (por ejemplo, todas las instancias de una lista enlazada con hasta \(k\) nodos). Denotamos este conjunto como \(BE(M, k)\). Decimos que un conjunto de constructores es suficiente si se pueden combinar para construir todas las instancias en \(BE(M, k)\). Por lo tanto, los constructores suficientes son la mejor opción posible para encontrar errores (en un contexto acotado). Cabe notar que \(B\) puede contener rutinas superfluas. Una rutina superflua \(s\) es aquella tal que \(BE(M, k)\) puede construirse usando las rutinas en $B - \{s\}$ (el ejemplo más simple son las rutinas que nunca cambian el estado de los objetos). Estas rutinas no aportan beneficios en términos de las capacidades de detección de errores del análisis. Llamamos \emph{mínimo} a un conjunto de constructores que no contiene rutinas superfluas. La minimalidad es importante porque proporcionar a una herramienta de análisis rutinas superfluas suele impactar negativamente en su eficiencia (el número de formas en que se pueden combinar \(k\) rutinas usualmente aumenta exponencialmente con \(k\)).

Identificar un conjunto suficiente y mínimo de métodos generadores de objetos requiere un análisis exhaustivo de las rutinas disponibles y una comprensión profunda de la semántica del módulo. Esto es especialmente difícil para módulos con APIs ricas, donde hay muchas rutinas y mucha redundancia en la API. Proponemos un enfoque automatizado para identificar dicho conjunto suficiente y mínimo de métodos, basado en un algoritmo evolutivo que busca un conjunto mínimo de rutinas capaz de generar el máximo número de objetos (acotados) diferentes (es decir, \(BE(M, k)\)). Además, nuestro enfoque evolutivo también tiene en cuenta otras características de los métodos generadores, como la cantidad y la complejidad de sus parámetros, de modo que se favorecen las rutinas “más simples” en la búsqueda. El objetivo es elegir métodos generadores que puedan ser utilizados de manera más fácil y eficiente en los análisis de programas.

El valor de aptitud (\emph{fitness}) para un conjunto de rutinas \(R\) se basa en el número de estructuras acotadas que se pueden generar utilizando combinaciones de estas rutinas. Para calcular la aptitud, usamos una versión modificada de una herramienta de generación de casos de prueba aleatorios (Randoop \cite{ref24}) para generar la mayor cantidad posible de estructuras acotadas a partir de \(R\), permitiendo como máximo \(k\) objetos de cada tipo en las estructuras (un parámetro de nuestro algoritmo). 
%Dado que los conjuntos de objetos son muy costosos de mantener y manipular, tanto en términos de espacio como de tiempo de ejecución, empleamos una abstracción eficiente de un conjunto de objetos, llamada extensiones de campos (\emph{field extensions}), definida como el conjunto de valores de los campos que aparecen en cualquiera de los objetos del conjunto \cite{ref25}. Por lo tanto, en lugar de contar el número de objetos diferentes generados por un candidato, la función de aptitud calculará las extensiones de campos a medida que se generan los objetos y devolverá el número de valores de campo en las extensiones. Intuitivamente, un mayor número de valores de campo en las extensiones de campo significa que los constructores se pueden usar para construir un conjunto más diverso de objetos, y por lo tanto, deberían ser preferidos sobre otros conjuntos de constructores.

Evaluamos nuestro enfoque experimentalmente en un conjunto de clases Java con estados complejos, extraídas de la literatura. Los resultados muestran que, en nuestros casos de estudio, nuestro enfoque identifica conjuntos de rutinas que son suficientes y mínimos, en un tiempo aceptable \pp{Cuánto en promedio?}. También evaluamos el impacto de nuestro enfoque en un análisis automatizado, concretamente, en la generación de casos de prueba para pruebas parametrizadas \pp{No hicimos esto según entiendo}. Comparamos cómo se comporta la herramienta de generación de casos de prueba aleatorios Randoop cuando se le proporciona la API completa del módulo, frente a proporcionarle únicamente los constructores identificados por nuestro enfoque. Los resultados indican que, en este último caso, Randoop generó más objetos (y más grandes), dentro de un tiempo límite fijo.

\pp{2- También habría que traducir la intro del paper de bounded exhuastive y ponerla acá.}

Los enfoques de generación automática de pruebas tienen como objetivo asistir a los desarrolladores en tareas cruciales de testing de software \cite{Ammann16,Myers11}, como la generación automática de casos de test \cite{Cadar08,Christakis15,Iosif02,Luckow14,Fraser11}, y la detección y reporte automáticos de fallas \cite{Pacheco07, Ma15 , Godefroid05, Marinov01, Boyapati02, Godefroid12}. Muchos de estos enfoques incluyen componentes aleatorios, los cuales evitan realizar una exploración sistemática del espacio de comportamientos, pero mejoran la eficiencia de la generación de pruebas \cite{Pacheco07, Ma15, Fraser11}. Aunque estos enfoques han sido útiles para encontrar un gran número de errores en software, podrían no explorar ciertos comportamientos defectuosos debido a su naturaleza aleatoria. 

Enfoques alternativos buscan explorar sistemáticamente un gran número de ejecuciones del software bajo prueba (\emph{SUT}, por sus siglas en inglés), con el objetivo de proporcionar garantías más sólidas sobre la ausencia de errores \cite{Marinov01, Boyapati02, Godefroid05, Godefroid18, Cadar08, Luckow14}. Algunos de estos enfoques se basan en la generación exhaustiva acotada \cite{Marinov01, Boyapati02}, que consiste en generar todas las entradas que pueden construirse utilizando dominios de datos acotados. Los objetivos comunes de los enfoques de generación exhaustiva acotada han sido implementaciones de estructuras de datos dinámicas complejas con restricciones estructurales significativas (por ejemplo, listas enlazadas, árboles, etc.). Los enfoques más utilizados y eficientes de generación exhaustiva acotada para testear el software \cite{Marinov01, Boyapati02} requieren que el usuario proporcione una especificación formal de las restricciones que las entradas deben satisfacer (típicamente, el invariante de representación que deben satisfacer las entradas (denominado \textit{repOK})), y límites en el tamaño de los dominios de datos \cite{Marinov01, Boyapati02} (a menudo denominados \textit{scopes}). Así, los enfoques de generación exhaustiva acotada basados en especificaciones generan todas las entradas acotadas que satisfacen \textit{repOK}.

Escribir especificaciones formales adecuadas para la generación exhaustiva acotada es una tarea desafiante y que consume mucho tiempo. Las especificaciones deben capturar con precisión las restricciones sobre las  entradas. Las especificaciones demasiado restrictivas pueden llevar a no generar algunas entradas válidas, lo cual podría hacer que la etapa de prueba posterior no explore comportamientos defectuosos del SUT. Por otro lado, las especificaciones poco restrictivas pueden llevar a la generación de entradas inválidas, lo que podría producir falsas alarmas durante la prueba del SUT. Además, a veces el usuario necesita tener en cuenta la forma en que opera el enfoque de generación y escribir las especificaciones de manera muy específica para lograr un buen rendimiento \cite{Boyapati02}. Por último, dichas especificaciones formales precisas raramente están disponibles en el software, lo que dificulta la usabilidad de los enfoques de generación exhaustiva acotada basados en especificaciones.

Varios estudios demuestran que los enfoques de generación exhaustiva acotada son efectivos para revelar fallas en el software \cite{Marinov01, Khurshid01, Boyapati02, Sullivan04}. Además, la hipótesis de la cota pequeña (\textit{small scope hypothesis}) \cite{Andoni02}, que establece que la mayoría de las fallas en el software pueden revelarse ejecutando el SUT con “datos de entrada pequeños”, sugiere que los enfoques de generación exhaustiva acotada deberían descubrir la mayoría de las fallas en el SUT (si no todas), si se utilizan \textit{scopes} lo suficientemente grandes. El desafío que enfrentan los enfoques de generación exhaustiva acotada es cómo explorar eficientemente un espacio de búsqueda enorme, que a menudo crece exponencialmente con respecto a los \textit{scopes}. El espacio de búsqueda típicamente incluye una gran cantidad de entradas inválidas (que no satisfacen \textit{repOK}), y entradas isomorfas \cite{15, 28} \pp{citas}. Por lo tanto, podar partes del espacio de búsqueda que involucren datos de entrada inválidos e isomorfos (redundantes) es clave para que estos enfoques sean eficientes y escalables en la práctica \cite{Boyapati02}.

En este trabajo, proponemos un nuevo enfoque para la generación exhaustiva acotada, denominado BEAPI, que funciona realizando llamadas a métodos de la API del SUT. De manera similar a los enfoques de generación de pruebas basados en API \cite{Pacheco07, Ma15,Fraser11}, BEAPI genera secuencias de invocaciones a métodos de la API, denominadas secuencias de test. La ejecución de cada secuencia de test generada por BEAPI produce una entrada en el conjunto resultante de objetos (exhaustivo acotado). 
%Como es habitual en la generación exhaustiva acotada, BEAPI requiere que el usuario proporcione los scopes para la generación, que en BEAPI incluyen cotas en el tamaño de las estructuras a generar, y valores primitivos para invocar a los métodos de la API (ver más adelante). 
Un enfoque de fuerza bruta intentaría generar todas las secuencias de test con hasta $m$ métodos, donde $m$ es la longitud máxima permitida para la secuencias de test, dado por el usuario. Este enfoque es intrínsecamente combinatorio, que agota los recursos computacionales antes de su finalización incluso para valores de $m$ muy pequeños. Proponemos varias técnicas de poda que son cruciales para la eficiencia de BEAPI, y que permiten que escale a scopes significativamente mayores. Primero, BEAPI ejecuta las secuencias de prueba y descarta aquellas que corresponden a violaciones de las reglas de uso de la API (por ejemplo, lanzar excepciones que indican un uso incorrecto de la API, como IllegalArgumentException en Java \cite{Liskov00, Pacheco07}). 

Segundo, BEAPI implementa la coincidencia de estados (\emph{state matching}) \cite{Iosif02, Politano20, Xie04} para descartar secuencias de prueba que produzcan estructuras ya creadas por secuencias previamente exploradas. Tercero, BEAPI emplea solo un subconjunto de los métodos de la API para crear secuencias de prueba: un conjunto de métodos identificados automáticamente como métodos generadores \cite{Ponzio19}. Previo a la generación de tests, BEAPI ejecuta un enfoque automatizado de identificación de métodos generadores \cite{Ponzio19}, en busca de un subconjunto más pequeño de métodos de la API que sea suficiente para generar el conjunto de entradas exhaustivas acotadas. 

Una ventaja de BEAPI respecto de los enfoques basados en especificaciones es que no requiere una especificación que describa con precisión las propiedades de las entradas válidas (repOK). En cambio, en BEAPI 
%requiere un esfuerzo mínimo de especificación en la mayoría de los casos (incluidos la mayoría de nuestros estudios de estudios), que consiste en 
es suficiente con
hacer que los métodos de la API lancen excepciones en presencia de entradas inválidas. Este estilo de programación se denomina "programación defensiva", popularizado por Liskov \cite{Liskov00}, y es ampliamente recomendado para el desarrollo de APIs robustas. 
Otra ventaja de BEAPI respecto a los enfoques basados en especificaciones es que produce secuencias de test para crear las entradas correspondientes utilizando métodos de la API, lo que facilita la creación de tests, y mejora la legibilidad y mantenibilidad de los mismos \cite{Braione17}. Esto es en contraste con las técnicas existentes, en las que las estructuras son codificadas directamente en los tests (como grafos) usando mecanismos de bajo nivel del lenguaje de programación (como reflexión en Java \cite{} \pp{algo de reflection}).

Evaluamos experimentalmente BEAPI y mostramos que su eficiencia y escalabilidad son comparables a las del mejor enfoque exhaustivo acotado actual (Korat), sin necesidad de proveer especificaciones formales para la estructuras (repOKs). También mostramos que BEAPI puede ser útil para encontrar fallos en los repOKs, comparando los conjuntos de entradas generados por BEAPI utilizando la API con los conjuntos de entradas generados por Korat a partir de un repOK. Usando este procedimiento, encontramos varios errores en los repOKs empleados en la evaluación experimental de herramientas relacionadas, proporcionando así evidencia sobre la dificultad de escribir repOKs (en particular, los repOKs precisos requeridos por las herramientas de generación acotada).


\pp{3- Habría que intentar mergear ambas, pero me gustaría también tenerlas por separado para no omitir detalles importantes.}

 % En este artículo, se propone un nuevo enfoque para generar valores de entrada exhaustivos y acotados para las APIs de los programas. Nuestro enfoque combina la ejecución simbólica con la resolución de restricciones para generar un conjunto representativo de valores de entrada que se pueden utilizar para probar APIs con una alta cobertura, sin la necesidad de probar cada posible valor de entrada. Evaluamos nuestro enfoque en un conjunto de APIs del mundo real y mostramos que es más efectivo que los enfoques existentes en términos de cobertura y eficiencia.


En la actualidad, el software está presente en casi todos los aspectos de la vida diaria, desde sistemas críticos en la industria aeronáutica y en salud, hasta aplicaciones móviles de uso cotidiano. La evolución de la tecnología y su integración en nuestra sociedad han hecho que la calidad del software sea un factor clave en el desarrollo tecnológico.  La ingeniería de software es una disciplina fundamental en el desarrollo y construcción de sistemas de software complejos y de alta calidad. A medida que la tecnología ha avanzado, el software se ha vuelto omnipresente en nuestra vida cotidiana. A medida que el software se vuelve más ubicuo gracias a los rápidos avances en tecnología, garantizar la corrección funcional del software es más crucial que nunca. Sin embargo, a menudo sucede que se lanza software defectuoso al mercado, lo que causa inconvenientes a los usuarios finales. Además, la creciente demanda de sistemas de software críticos ha llevado a la aparición de diversos desafíos y problemas en su desarrollo y mantenimiento.
Para abordar este problema, un área de investigación de creciente importancia es la del análisis automático de software, cuyo objetivo es ayudar a los programadores, a través de la provisión de herramientas para el análisis automatizado, a encontrar deficiencias tanto en el software
como en los modelos relacionados con el software, Garantizar la corrección funcional del software sigue siendo un desafío importante, y es por ello que el análisis automatizado del software ha cobrado relevancia en los últimos años. Este campo de investigación busca asistir a los ingenieros a través de herramientas automatizadas para identificar deficiencias en el software.

%\cacho{Tengo que enganchar la verificación de modelos de software \cite{Visser06, Visser05, Clarke:2004}, y los análisis estáticos \cite{Calcagno:2011, Itzhaky:2014}}

Entre las técnicas de análisis automatizado destacan la generación automatizada de casos de test \cite{Ponzio:2016, Rosner15, Abad13, Galeotti:2010, Khalek:2011, Pasareanu:2010, Gligoric10, Tillmann:2008, Pacheco07}, y la detección y reporte automáticos de fallas \cite{Pacheco07, Ma15 , Godefroid05, Marinov01, Boyapati02, Godefroid12}
Muchos de estos enfoques incluyen componentes aleatorios, los cuales evitan realizar una exploración sistemática del espacio de comportamientos, pero mejoran la eficiencia de la generación de casos de test \cite{Pacheco07, Ma15, Fraser11}. Aunque estos enfoques han sido útiles para encontrar un gran número de errores en software, podrían no explorar ciertos comportamientos defectuosos debido a su naturaleza aleatoria.

Enfoques alternativos buscan explorar sistemáticamente un gran número de ejecuciones del software bajo prueba (\emph{SUT}, por sus siglas en inglés), con el objetivo de proporcionar garantías más sólidas sobre la ausencia de errores \cite{Marinov01, Boyapati02, Godefroid05, Godefroid18, Cadar08, Luckow14}. Algunos de estos enfoques se basan en la generación exhaustiva acotada (\emph{BEG}, por sus siglas en inglés) \cite{Marinov01, Boyapati02}, que consiste en generar todos los datos de entrada factibles que pueden construirse utilizando dominios de datos acotados. Los objetivos comunes de los enfoques BEG han sido implementaciones de estructuras de datos dinámicas complejas con restricciones estructurales significativas (por ejemplo, listas enlazadas, árboles, etc.). Los enfoques más utilizados y eficientes de BEG para probar software \cite{Marinov01, Boyapati02} requieren que el usuario proporcione una especificación formal de las restricciones que los datos de entrada deben satisfacer (a menudo un invariante de representación del dato de entrada (\textit{repOK})), y límites en los dominios de datos \cite{Marinov01, Boyapati02} (a menudo denominados \textit{scopes}). Por lo tanto, los enfoques BEG basados en especificaciones generan todos los datos de entrada dentro de los \textit{scopes} proporcionados que satisfacen \textit{repOK}.


%Tengo que engancharlo
%Estas herramientas han demostrado ser útiles, aunque su aplicación en entornos reales a menudo requiere esfuerzos significativos por parte de los ingenieros de software. Por ejemplo, los verificadores de modelos necesitan \emph{drivers} para construir entradas al código bajo análisis, y en las pruebas unitarias parametrizadas \cite{Tillmann:2010} se requiere un mecanismo para generar dichas entradas.
%Además, las herramientas basadas en la ejecución simbólica dependen de "fábricas de objetos" para construir casos de prueba que incluyan entradas con tipos no primitivos \cite{Tillmann:2008}. Aunque algunos enfoques basados en la API de un módulo permiten automatizar la generación de entradas \cite{Pacheco07, Fraser11}, estos enfrentan dificultades al generar conjuntos diversos de entradas para estructuras complejas con estado, especialmente en el caso de APIs ricas en métodos \cite{Ponzio:2018}. 

Escribir especificaciones formales adecuadas para BEG es una tarea desafiante y que consume mucho tiempo. Las especificaciones deben capturar con precisión las restricciones previstas de los datos de entrada. Las especificaciones demasiado restrictivas pueden llevar a no generar entradas válidas, lo cual podría hacer que la etapa de prueba posterior no explore comportamientos defectuosos del SUT. Por otro lado, las especificaciones poco restrictivas pueden llevar a la generación de entradas no válidas, lo que podría producir falsas alarmas durante la prueba del SUT. Además, a veces el usuario necesita tener en cuenta la forma en que opera el enfoque de generación y escribir las especificaciones de manera muy específica para lograr un buen rendimiento \cite{Boyapati02}. Por último, dichas especificaciones formales precisas raramente están disponibles en el software, lo que dificulta la usabilidad de los enfoques BEG basados en especificaciones.

Varios estudios demuestran que los enfoques BEG son efectivos para revelar fallas en el software \cite{Marinov01, Khurshid01, Boyapati02, Sullivan04}. Además, la hipótesis de la cota pequeña (\textit{small scope hypothesis}) \cite{Andoni02}, que establece que la mayoría de los fallos de software pueden revelarse ejecutando el SUT con “datos de entrada pequeños”, sugiere que los enfoques BEG deberían descubrir la mayoría (si no todos) de los fallos en el SUT, si se utilizan \textit{scopes} lo suficientemente grandes. El desafío que enfrentan los enfoques BEG es cómo explorar eficientemente un enorme espacio de búsqueda, que a menudo crece exponencialmente con respecto al \textit{scope}. El espacio de búsqueda a menudo incluye una gran cantidad de datos de entrada inválidos (que no satisfacen \textit{repOK}) y datos de entrada isomorfos. Por lo tanto, podar partes del espacio de búsqueda que involucren datos de entrada inválidos y redundantes es clave para que los enfoques BEG sean escalables en la práctica \cite{Boyapati02}.


En esta tesis, se aporta un enfoque diferente para BEG.
En primer caso, abordamos el problema de generar mejores entradas para testear el software. Observamos que la selección de rutinas de una API, para alimentar una herramienta de generación de entradas y construir estructuras de entrada para el análisis de programas (drivers para la verificación de modelos, estructuras de entrada para pruebas unitarias parametrizadas, etc.), tiene un impacto crucial en el análisis. Llamamos \emph{métodos generadores de objetos} a un conjunto de métodos $B$, extraídos de la API de un módulo $M$, que pueden emplearse para crear estructuras de entrada en un análisis automatizado de programas para \( M \)  (por ejemplo, un driver para la verificación de modelos). Claramente, cuanto mayor sea el número de estructuras diferentes que se puedan crear con \( B \) , mayores serán las posibilidades de encontrar errores en \( M \).

Dado que el número de instancias de un módulo de software es potencialmente infinito, y los análisis de programas que abordamos también están limitados en cuanto al número de estructuras que pueden emplear, nos limitamos a un conjunto exhaustivo acotado de estructuras para \( M \) \cite{Boyapati02} (por ejemplo, todas las instancias de una lista enlazada con hasta \( k \) nodos). Denotamos este conjunto como \( BE(M, k) \). Decimos que un conjunto de constructores es suficiente si se pueden combinar para construir todas las instancias en \( BE(M, k) \). Por lo tanto, los métodos generadores de objetos suficientes son la mejor opción posible para encontrar errores (en un contexto acotado). Cabe notar que \( B \) puede contener rutinas superfluas. Una rutina superflua \( s \) es aquella tal que \( BE(M, k) \) puede construirse usando las rutinas en \( B - \{s\} \) (el ejemplo más simple son las rutinas que nunca cambian el estado de sus parámetros). Estas rutinas no aportan beneficios en términos de las capacidades de detección de errores del análisis. Llamamos \emph{mínimo} a un conjunto de metodos que no contiene rutinas superfluas. La minimalidad es importante porque proporcionar a una herramienta de análisis rutinas superfluas suele impactar negativamente en su eficiencia (el número de formas en que se pueden combinar \( k \) rutinas usualmente aumenta exponencialmente con \( k \)).

Identificar un conjunto suficiente y mínimo de métodos generadores de objetos requiere un análisis exhaustivo de las rutinas disponibles y una comprensión profunda de la semántica del programa. Esto es especialmente difícil para programas con APIs ricas, donde hay muchas rutinas y mucha redundancia en la API. Proponemos un enfoque automatizado para identificar dicho conjunto suficiente y mínimo de métodos, basado en algoritmos evolutivos que busca un conjunto mínimo de rutinas capaz de generar el máximo número de objetos (acotados) diferentes (es decir, \( BE(M, k) \)). Además, nuestro enfoque evolutivo también tiene en cuenta otras características de los metodos generadores, como el número y la complejidad de sus parámetros, de modo que se favorecen las rutinas “más simples” en la búsqueda. El objetivo es elegir métodos que puedan ser utilizados de manera más fácil y eficiente en los análisis de programas subsiguientes.

\cacho{Aca no se se si hace falta la fitness, sino hay que explicar las dos. Lo puse aca, lo saque del paper. Ver si lo dejamos y si es asi, lo explico mejor para las dos fitness}
El valor de aptitud (\emph{fitness}) para un conjunto de rutinas \( R \) se basa en el número de estructuras acotadas que se pueden generar utilizando combinaciones de estas rutinas. Para calcular la aptitud, usamos una versión modificada de una herramienta de generación de casos de prueba aleatorios (Randoop \cite{ref24}) para generar la mayor cantidad posible de estructuras acotadas a partir de \( R \), permitiendo como máximo \( k \) objetos de cada tipo en las estructuras (un parámetro de nuestro algoritmo). Dado que los conjuntos de objetos son muy costosos de mantener y manipular, tanto en términos de espacio como de tiempo de ejecución, empleamos una abstracción eficiente de un conjunto de objetos, llamada extensiones de campos (\emph{field extensions}), definida como el conjunto de valores de los campos que aparecen en cualquiera de los objetos del conjunto \cite{ref25}. Por lo tanto, en lugar de contar el número de objetos diferentes generados por un candidato, la función de aptitud calculará las extensiones de campos a medida que se generan los objetos y devolverá el número de valores de campo en las extensiones. Intuitivamente, un mayor número de valores de campo en las extensiones de campo significa que los constructores se pueden usar para construir un conjunto más diverso de objetos, y por lo tanto, deberían ser preferidos sobre otros conjuntos de constructores.


Luego, el otro aporte, y el más importante de esta tesis,  es el nuevo enfoque para BEG, denominado BEAPI, que funciona realizando llamadas a métodos de la API del SUT. De manera similar a los enfoques de generación de pruebas basados en API \cite{Pacheco07, Ma15,Fraser11}, BEAPI genera secuencias de llamadas a métodos de la API (es decir, secuencias de test). La ejecución de cada secuencia de test generada por BEAPI produce una entrada en el conjunto resultante de objetos BEG. Como es habitual en BEG, BEAPI requiere que el usuario proporcione los alcances para la generación, que en BEAPI incluyen una longitud máxima de secuencia de prueba. BEG a fuerza bruta, con un alcance proporcionado por el usuario, intentaría generar todas las secuencias de prueba factibles de métodos de la API con una longitud de secuencia máxima. Este es un proceso intrínsecamente combinatorio, que agota los recursos computacionales antes de su finalización, incluso para alcances muy pequeños. Proponemos varias técnicas de poda que son cruciales para la eficiencia de BEAPI y permiten que escale a alcances significativamente mayores. Primero, BEAPI ejecuta secuencias de prueba y descarta aquellas que corresponden a violaciones de las reglas de uso de la API (por ejemplo, lanzar excepciones que indican un uso incorrecto de la API, como IllegalArgumentException en Java \cite{Liskov00, Pacheco07}). Así, a diferencia de los enfoques BEG basados en especificaciones, BEAPI no requiere un repOK que describa con precisión las entradas válidas. En cambio, BEAPI requiere un esfuerzo mínimo de especificación en la mayoría de los casos (incluidos la mayoría de nuestros estudios de estudios), que consiste en hacer que los métodos de la API lancen excepciones ante entradas inválidas (en el estilo de "programación defensiva" popularizado por Liskov \cite{Liskov00}). Segundo, BEAPI implementa el emparejamiento de estados \cite{Iosif02, Politano20, Xie04} para descartar secuencias de prueba que produzcan entradas ya creadas por secuencias previamente exploradas. Tercero, BEAPI emplea solo un subconjunto de los métodos de la API para crear secuencias de prueba: un conjunto de métodos identificados automáticamente como constructores \cite{Ponzio19}. Este es el primer aporte que brinda esta tesis. Antes de la generación de pruebas, BEAPI ejecuta el enfoque, previamente comentado, de identificación de constructores \cite{Ponzio19} para encontrar un subconjunto más pequeño de la API que sea suficiente para generar el conjunto resultante de entradas BEG. Otra ventaja de BEAPI respecto a los enfoques basados en especificaciones es que produce secuencias de prueba para crear las entradas correspondientes utilizando métodos de la API, lo que facilita la creación de pruebas a partir de la salida de BEAPI 


Evaluamos nuestro enfoque experimentalmente en un conjunto de clases Java con estado extraídas de la literatura. Los resultados muestran que, en nuestros casos de estudio, nuestro enfoque identifica conjuntos de rutinas que son suficientes y mínimos, en un tiempo razonable. También evaluamos el impacto de nuestro enfoque en un análisis automatizado, concretamente, en la generación de casos de prueba para pruebas parametrizadas. Comparamos cómo se comporta la herramienta de generación de casos de prueba aleatorios Randoop cuando se le proporciona la API completa del módulo, frente a proporcionarle únicamente los constructores identificados por nuestro enfoque. Los resultados indican que, en este último caso, Randoop generó más objetos (y más grandes) dentro de un tiempo límite fijo, lo que evidencia el valor práctico de los conjuntos mínimos identificados.

Luego, mostramos que la eficiencia y escalabilidad de nuestro enfoque son comparables a las del enfoque BEG más rápido (Korat), sin requerir la definición de repOKs. Además, evidenciamos que BEAPI puede ser útil para detectar fallos en los repOKs, al comparar los conjuntos de entradas generados por BEAPI utilizando la API, con los conjuntos de entradas generados por Korat a partir de un repOK. Este procedimiento permitió identificar varios fallos en los repOKs utilizados en la evaluación experimental de herramientas relacionadas, subrayando así la dificultad inherente a la escritura correcta de repOKs para enfoques BEG




/////
\cacho{vieja intro}



A medida que el software se vuelve más ubicuo gracias a los rápidos avances tecnológicos, garantizar la corrección funcional del software es más crucial que nunca. Por lo tanto, un área de investigación de creciente importancia es la del análisis automatizado de software, cuyo objetivo es asistir a los ingenieros, a través de herramientas de análisis automatizado, en la identificación de deficiencias tanto en el software como en los modelos relacionados con él. La generación automatizada de pruebas \cite{Ponzio:2016, Rosner15, Abad13, Galeotti:2010, Khalek:2011, Pasareanu:2010, Gligoric10, Tillmann:2008, Pacheco07}, la verificación de modelos de software \cite{Visser06, Visser05, Clarke:2004}, y los análisis estáticos \cite{Calcagno:2011, Itzhaky:2014}, entre otros, son enfoques destacados en esta línea de investigación.

Aunque estas técnicas implican en muchos casos análisis completamente automatizados, su aplicación suele requerir cierto esfuerzo por parte de los ingenieros de software. Los verificadores de modelos de software dependen de la definición de \emph{drivers}, programas que permiten construir entradas para el código bajo análisis. De manera similar, en los enfoques de pruebas unitarias parametrizadas \cite{Tillmann:2010} es obligatorio un mecanismo para construir entradas. Algunas herramientas basadas en la ejecución simbólica requieren las llamadas "fábricas de objetos" para construir casos de prueba que incluyan entradas con tipos no primitivos \cite{Tillmann:2008}. Las técnicas automatizadas de generación de pruebas basadas en la API de un módulo pueden usarse para construir entradas de tipos no primitivos \cite{Pacheco07, Fraser11}, automatizando así los problemas de generación de entradas antes mencionados. Sin embargo, suelen presentar dificultades para generar un buen conjunto de entradas diversas para estructuras complejas con estado. Esto es aún más difícil para estructuras con APIs ricas \cite{Ponzio:2018}. Muchos autores han abordado este problema definiendo diferentes enfoques para guiar la generación de pruebas y crear conjuntos más diversos de entradas \cite{Ponzio:2018, Ciupa:2008}.











A medida que el software se está volviendo más ubicuo gracias a los rápidos avances en tecnología, garantizar la corrección funcional del software es más crucial que nunca. Sin embargo, a menudo sucede que se lanza software defectuoso al mercado, lo que causa al menos inconvenientes a los usuarios finales. Para abordar este problema, un área de investigación de creciente importancia es la del análisis de software automatizado, cuyo objetivo es ayudar a los programadores, a través de la provisión de herramientas para el análisis automatizado, a encontrar deficiencias tanto en el software como en los modelos relacionados con el software. La generación automatizada de pruebas [TODO], la verificación de modelos de software [TODO] y los análisis estáticos [TODO], entre muchos otros, son enfoques destacados en esta línea de investigación.

Entre estos desafíos, uno de los más cruciales es la generación de entradas adecuadas para las herramientas de análisis automatizado, como \emph{model checkers} y pruebas unitarias parametrizadas.

En este contexto, existen diversas técnicas automatizadas para la generación de pruebas y análisis de software. Sin embargo, muchas de estas técnicas requieren cierto esfuerzo por parte de los programadores de software para definir rutinas o métodos, \cacho{Aca estoy yo definiendo el concepto, me suena que deberia poner algo como que definimos este concepto}
conocidos como métodos generadores de objetos, que permiten construir estructuras de entrada para el análisis de código. La selección adecuada de estos métodos es crucial, ya que afecta directamente la efectividad del análisis y la detección de errores en el software.

En las prácticas actuales de desarrollo de software, las pruebas de software son el enfoque más utilizado para encontrar fallos en el software. Las pruebas permiten a los desarrolladores encontrar y corregir fallos antes de los lanzamientos, mejorando la fiabilidad del producto de software \cite{Ammann16,Myers11}. Sin embargo, las pruebas manuales son muy costosas: se deben asignar un número significativo de horas de trabajo de los desarrolladores para llevar a cabo pruebas de manera efectiva, y su alcance a menudo está muy limitado por el presupuesto del proyecto \cite{Ammann16,Myers11}. Por lo tanto, no es raro que se lance software con fallos desconocidos para los desarrolladores.

Uno de los objetivos de esta tesis es abordar el desafío de identificar un conjunto óptimo de metodos generadores de objetos para la generación de entradas de un sofware. En lugar de depender de selecciones manuales, proponemos tres enfoques automatizados para encontrar estos conjuntos de metodos. Estos enfoques se basan en algoritmos de busqueda informada.  El primer enfoque es un algoritmo evolutivo, el segundo es un algoritmo perezoso, mas precisiamente un algoritmo del estilo \emph{Hill Climbing}, y el tercer algortimo nos basamos en la idea de un desarollo de algoritmo de busqueda basado en la idea de agrupar los conjuntos de métodos en clases de equivalencias. Estos algoritmos consideran tanto la cantidad como la complejidad de los parámetros de los métodos, para favorecer la selección de rutinas más simples.

Para evaluar la efectividad de nuestros enfoques, realizamos experimentos en un conjunto de clases Java con estado, extraídas de la literatura. Los resultados demuestran que nuestros enfoques identifican conjuntos de builders suficientes y mínimos en un tiempo razonable. Además, evaluamos el impacto de estos conjuntos en análisis automatizados, como la generación de casos de prueba para pruebas unitarias parametrizadas. Comparando nuestro enfoque con herramientas de generación de casos de prueba aleatorios, observamos que al proporcionar a la herramienta solo los builders identificados por nuestro método, se logra generar más y más diversos objetos de entrada en el mismo período de tiempo.

Los enfoques automatizados de generación de pruebas tienen como objetivo ayudar a los desarrolladores en las tareas de pruebas, por ejemplo, mediante la generación automática o la facilitación de la creación de conjuntos de pruebas \cite{Cadar08,Luckow14,Fraser11}, o mediante la búsqueda y el informe automático de fallos \cite{Pacheco07,Ma15,Godefroid05,Marinov01,Boyapati02,Godefroid12}. Muchos enfoques para encontrar fallos implican algún componente aleatorio, que evita la exploración sistemática del espacio de comportamientos y mejora la eficiencia de la generación de pruebas \cite{Pacheco07,Ma15,Fraser11}. Si bien estos enfoques han sido muy útiles para encontrar una gran cantidad de errores en el software, generalmente no pueden proporcionar garantías, incluso parciales, de que se exploran ciertas familias de comportamientos de software. Por lo tanto, algunos enfoques alternativos tienen como objetivo explorar sistemáticamente un número muy grande de ejecuciones de un software en prueba (SUT), con el objetivo de proporcionar garantías más sólidas sobre la ausencia de errores en el SUT \cite{Marinov01,Boyapati02,Godefroid05,Godefroid18}. Uno de estos enfoques es la generación de entradas exhaustivas acotadas \cite{Marinov01,Boyapati02}. Dada una especificación de las entradas válidas de un SUT, a menudo llamada \texttt{repOK}, la generación exhaustiva acotada de entradas consiste en crear todas las estructuras válidas que satisfacen \texttt{repOK} utilizando dominios de datos acotados. Varios análisis experimentales muestran que los enfoques exhaustivos acotados son efectivos para revelar fallos de software.

\cacho{DEBO INTRODUCIR BUIDLERS}

Además, la llamada \emph{hipótesis de alcance pequeño} --que establece que la mayoría de los defectos de software se pueden descubrir ejecutando la SUT en "entradas pequeñas"-- sugiere que los enfoques exhaustivos acotados brindan un alto grado de confianza sobre la ausencia de defectos en la SUT \cite{Andoni02}. La desventaja es que estos enfoques tienen que lidiar con la generación de una cantidad de estructuras que a menudo crece exponencialmente con respecto a los límites de generación (llamados a menudo \emph{alcances}), y con la exploración de un espacio de búsqueda combinatorio que incluye una gran cantidad de estructuras inválidas (es decir, que no satisfacen \texttt{repOK}) y estructuras isomórficas. Por lo tanto, la poda del espacio de búsqueda y la eliminación de estructuras isomórficas son clave para hacer que los enfoques exhaustivos acotados sean escalables en la práctica.

Enfoques previos de exhaustividad acotada requieren un \texttt{repOK} escrito en un lenguaje lo suficientemente expresivo como para describir con precisión las propiedades de las entradas \cite{Marinov01, Boyapati02}. Los objetivos más comunes de estos enfoques han sido representaciones de clases complejas, como colecciones asignadas en el montón con restricciones estructurales complejas (listas enlazadas, árboles, etc.). Se han utilizado varios lenguajes de especificación para describir el \texttt{repOK}, por ejemplo, la lógica relacional (en el denominado estilo declarativo) empleada por \textsf{TestEra} \cite{Marinov01}; y el código fuente en un lenguaje de programación imperativo (en el denominado estilo operacional) utilizado por \textsf{Korat} \cite{Boyapati02}. En cualquier caso, conseguir las especificaciones correctas, en cualquier lenguaje, consume tiempo y es propenso a errores. Las especificaciones sobredimensionadas pueden llevar a saltarse partes relevantes del espacio de estado de las entradas válidas durante el análisis; por otro lado, las especificaciones infradimensionadas pueden llevar a falsos fallos, es decir, a generar entradas que desencadenan fallos, pero que de hecho son inválidas y no representan errores reales (reproducibles). Además, las especificaciones rara vez están disponibles junto con el software, e incluso cuando lo están, los enfoques de análisis exhaustivo acotado específicos, como \textsf{Korat} y \textsf{TestEra}, requieren que se escriban de maneras bastante específicas para permitir que las herramientas correspondientes generen entradas de manera eficiente.


Estos enfoques  requieren que los
programadores identifiquen manualmente un subconjunto de los métodos de un
módulo con el fin de dirigir el análisis. En general, al analizar un módulo,
los programadores seleccionan un subconjunto de sus métodos que serán
considerados como constructores de objetos para definir lo que
se conoce como un controlador o "driver", que se utilizará para construir
objetos automáticamente para el análisis, combinándolos de manera no
determinista, aleatoria, etc. Esto requiere una inspección minuciosa del módulo
y su estructura, ya que la exhaustividad relativa del análisis (omitir métodos
importantes puede evitar sistemáticamente la generación de diferentes objetos) y
su eficiencia (las diferentes combinaciones acotadas de métodos crecen de manera
exponencial a medida que aumenta el número de métodos) se ven afectados por la
selección 