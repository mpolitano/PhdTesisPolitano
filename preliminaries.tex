\chapter[Preliminares]{Preliminares}
\label{cap:preliminares.BE}

\section{Testing}
El testing constituye una de las estrategias más directas y ampliamente utilizadas para verificar el comportamiento de un programa.
Esta técnica consiste en ejecutar el software bajo distintas condiciones específicas, observando si los resultados obtenidos se corresponden con los resultados esperados. 
Dado que no es factible analizar el comportamiento de un programa frente a todas las posibles entradas (debido a que este conjunto puede ser extremadamente grande o incluso infinito, como sucede en programas que procesan números enteros arbitrarios), 
se recurre a la selección de un subconjunto representativo de casos de prueba, comúnmente denominado \emph{suite de tests}.

El objetivo de esta suite es brindar un nivel de confianza suficiente sobre la corrección funcional del software, 
incluso en escenarios que no han sido ejercitados directamente. 
El testing es una etapa fundamental en los procesos modernos de desarrollo de software. 
Tradicionalmente, se realiza después de la fase de implementación, pero en metodologías de desarrollo ágiles está integrado de manera más continua, 
acompañando activamente el ciclo de desarrollo e incluso guiando decisiones de diseño e implementación.



\section{Korat: Generación exhaustiva acotada basada en especificaciones}
\label{sec:korat}


Korat es uno de los enfoques más conocidos y eficientes para la generación exhaustiva acotada
de entradas para test \cite{Boyapati02}.
Para funcionar, Korat requiere de una especificación formal dada en términos de
un método booleano, denominado \texttt{repOK}, que sirve para determinar si una estructura
es válida o no. Es decir, si satisface o no las restricciones que la estructura
debe cumplir, como por ejemplo, un invariante de representación de una
estructura de datos, una precondición de un método, etc. Korat también requiere 
de la definición del alcance de la generación, (en inglés, el \emph{scope}),
esto es, límites en el tamaño de los dominios de datos a ser utilizados
para la generación de estructuras.

Así, Korat genera de manera exhuastiva todas las estructuras acotadas que
satisfacen las condiciones de validez definidas por el programador en el
\texttt{repOK}. 
Korat explora de manera exhaustiva el espacio de todas las posibles instancias
acotadas de una clase (por ejemplo, listas con hasta $k$ nodos), 
retornando únicamente aquellas que satisfacen el invariante especificado. 

La eficiencia de Korat radica en su estrategia de exploración, 
que evita examinar múltiples estructuras que se sabe, por construcciones previas, que no conducen a estructuras válidas. 
Para lograr esto, Korat realiza una exploración sistemática del espacio de
posibles asignaciones de valores de atributos (por ejemplo, referencias de
nodos, enteros, etc.) utilizando una técnica basada en el seguimiento de los
atributos  leídos por el \texttt{repOK}.
Cada vez que una estructura es evaluada por el método \texttt{repOK}, Korat
registra qué atributos han sido accedidos (conocidos como \emph{field
accesses}). Esta información se utiliza para podar el espacio de búsqueda: si
una configuración parcial del heap no puede dar lugar a una estructura válida
(\texttt{repOK} da false), todas sus extensiones también serán descartadas.
De esta forma, el algoritmo de Korat combina una búsqueda basada en backtracking con poda
guiada por la ejecución del \texttt{repOK}, que le permite explorar 
el espacio de búsqueda acotado eficientemente, evitando explorar estructuras innecesarias. 

Korat ha demostrado ser eficaz y eficiente para la generación de entradas para
estructuras complejas con invariantes con propiedades ricas, como
listas doblemente enlazadas, árboles binarios, heaps binomiales, etc. \cite{Boyapati02}.
%, y ha sido utilizado como base para múltiples trabajos posteriores en verificación y generación de tests. Su enfoque representa un punto de referencia importante para técnicas que requieren generación de entradas válidas y exhaustivas a partir de especificaciones formales, y constituye una herramienta clásica dentro del campo del \emph{bounded exhaustive testing}.









%La \textit{generación exhaustiva de entradas} para probar APIs es una tarea crítica en la prueba de software, ya que permite identificar errores y garantizar que los programas funcionen correctamente bajo diversas condiciones. Sin embargo, el número potencialmente enorme de valores de entrada genera una explosión combinatoria, lo que hace inviable probar todas las posibles combinaciones.
%
%Para abordar este problema, se utiliza la \textit{generación exhaustiva acotada de entradas} (\textit{Bounded Exhaustive Testing, BE}), que consiste en generar todas las combinaciones posibles dentro de un rango predefinido. Este enfoque equilibra cobertura y factibilidad al reducir el espacio de prueba a un subconjunto manejable, sin dejar de incluir casos críticos que podrían pasar desapercibidos con métodos menos sistemáticos, como la \textit{generación aleatoria de pruebas}. Si bien la generación aleatoria es menos costosa computacionalmente, puede omitir casos límite relevantes, afectando la detección de errores.
%
%Korat es una herramienta que implementa la generación exhaustiva acotada, explorando todas las estructuras válidas dentro de ciertas restricciones. Su eficiencia se basa en la poda de combinaciones redundantes y en la eliminacion de estructuras isomorfas redundantes.
%
%El proceso de Korat consta de tres pasos clave:
%
%\begin{enumerate}
%    \item \textbf{Especificación de invariantes}: El usuario define las propiedades que deben cumplir las estructuras de datos, como que un árbol binario no debe tener ciclos y que cada nodo puede tener hasta dos hijos.
%    \item \textbf{Generación de candidatos}: Se generan todas las configuraciones posibles dentro de los límites especificados. Por ejemplo, si se establece un máximo de tres nodos para un árbol binario, se generarán todas las combinaciones con 1, 2 y 3 nodos.
%    \item \textbf{Filtrado y validación}: Se descartan las configuraciones que no cumplen con las restricciones definidas.
%\end{enumerate}
%
%\subsubsection{Ejemplo: Árboles Binarios}
%
%Si queremos probar una función que opera sobre árboles binarios, podemos definir:
%
%\begin{itemize}
%    \item \textbf{Límite}: Máximo 3 nodos.
%    \item \textbf{Invariantes}:
%    \begin{itemize}
%        \item No hay ciclos en el árbol.
%        \item Cada nodo tiene como máximo dos hijos.
%        \item Todos los nodos están conectados.
%    \end{itemize}
%\end{itemize}
%
%Korat generará todas las configuraciones válidas dentro de estos límites, como:
%
%\begin{itemize}
%    \item Un árbol con un solo nodo raíz.
%    \item Un árbol con un nodo raíz y un hijo izquierdo.
%    \item Un árbol con un nodo raíz, un hijo izquierdo y un hijo derecho.
%\end{itemize}
%
%Estos casos de prueba permiten verificar que la función maneja correctamente distintas estructuras de árboles binarios.
%
%\subsection{Ventajas de Korat}
%
%\begin{itemize}
%    \item \textbf{Cobertura completa}: Garantiza la exploración de todas las configuraciones dentro de los límites establecidos.
%    \item \textbf{Detección de casos límite}: Aumenta la probabilidad de encontrar errores en escenarios extremos.
%    \item \textbf{Eficiencia}: Evita la generación de estructuras inválidas o redundantes mediante poda y filtrado.
%\end{itemize}
%
%En esta tesis, Korat se utiliza como referencia para evaluar nuevas técnicas de generación de pruebas. Su enfoque sistemático y basado en especificaciones permite compararlo con otros métodos en términos de cobertura y calidad de los casos generados.
%
%
%
%
%
%La generación exhaustiva de entradas para realizar pruebas a las APIs de los programas es una tarea crítica en la prueba del software, ya que permite identificar errores y garantizar que los programas se comporten correctamente bajo una amplia gama de condiciones. Sin embargo, este proceso es inherentemente complejo debido al número potencialmente enorme de valores de entrada posibles, lo que genera una explosión combinatoria que hace inviable la prueba exhaustiva de todas las posibles entradas.
%
%Para abordar esta problemática, se recurre a la generación exhaustiva acotada de entradas (\emph{Bounded Exhaustive Testing, BE}), una técnica que consiste en generar todas las combinaciones posibles de entradas dentro de un rango o límite predefinido. Este enfoque permite reducir el espacio de entradas a un subconjunto manejable que aún cubre una diversidad significativa de casos, aumentando así la probabilidad de descubrir errores que podrían pasar desapercibidos con otros métodos de prueba.
%
%Por otro lado, una alternativa común a la generación exhaustiva acotada es la generación aleatoria de pruebas. Aunque este método es menos costoso computacionalmente y puede ser útil en ciertos contextos, presenta el inconveniente de que podría no cubrir casos críticos o bordes del espacio de entradas, lo que podría resultar en la omisión de errores significativos.
%
%En resumen, la generación exhaustiva acotada de entradas representa un compromiso entre la cobertura exhaustiva y la factibilidad práctica, ofreciendo una estrategia eficaz para la prueba de APIs, especialmente en sistemas donde la calidad y la seguridad son primordiales.
%
%Korat es una herramienta que implementa la técnica de generación exhaustiva acotada. Korat es una herramienta poderosa para la generación exhaustiva acotada de casos de prueba, permitiendo explorar todas las posibles estructuras válidas dentro de las restricciones establecidas. Su enfoque basado en filtrado, combinado con técnicas de poda y evitando las estructuras isomorfas, garantiza la eficiencia y efectividad en la generación de casos de prueba.
%
%La idea fundamental detrás de Korat es generar todas las configuraciones válidas de una estructura de datos dentro de un rango acotado (por ejemplo, un número máximo de nodos en un árbol o elementos en una lista). A diferencia de la generación aleatoria de pruebas, Korat garantiza que se exploren todas las combinaciones posibles dentro de los límites establecidos, lo que aumenta la probabilidad de detectar errores sutiles o casos límite.
%
%El proceso de Korat se basa en tres pasos clave:
%\begin{enumerate}
%\item \textbf{Especificación de invariantes}: El usuario define las propiedades que deben cumplir las estructuras de datos mediante predicados lógicos. Por ejemplo, en un árbol binario, se puede especificar que no debe contener ciclos y que cada nodo debe tener como máximo dos hijos
%
%\item \textbf{Generación de candidatos}: Korat genera todas las posibles configuraciones de la estructura de datos dentro de los límites especificados. Por ejemplo, si se define un límite de 3 nodos para un árbol binario, Korat generará todas las combinaciones posibles de árboles con 1, 2 o 3 nodos.
%
%\item \textbf{Filtrado y validación}: Cada configuración generada es validada contra los invariantes especificados. Solo las configuraciones que cumplen con las restricciones son retenidas como casos de prueba válidos.
%
%\end{enumerate}
%
%Para ilustrar el funcionamiento de Korat, consideremos el siguiente ejemplo concreto:
%
%\subsubsection{Ejemplo: Árboles Binarios}
%Supongamos que queremos probar una función que opera sobre árboles binarios. Con Korat, podemos definir los siguientes límites y restricciones:
%\begin{itemize}
%\item Límite: Árboles con un máximo de 3 nodos.
%\item Invariantes:
%\begin{itemize}
%\item No hay ciclos en el árbol.
%\item Cada nodo tiene como máximo dos hijos.
%\item Todos los nodos están conectados (no hay subárboles desconectados).
%\end{itemize}
%\end{itemize}
%
%Korat generará todas las posibles configuraciones de árboles binarios con 1, 2 y 3 nodos que cumplan con estas restricciones. Por ejemplo:
%\begin{itemize}
%\item Un árbol con un solo nodo raíz.
%\item Un árbol con un nodo raíz y un hijo izquierdo.
%\item Un árbol con un nodo raíz, un hijo izquierdo y un hijo derecho.
%\end{itemize}
%
%Estos casos de prueba permiten verificar que la función bajo prueba maneja correctamente diferentes configuraciones de árboles binarios.
%
%\cacho{Pongo ejemplos de codigo? de repok? de dibujitos?}
%
%La generación exhaustiva acotada implementada por Korat ofrece varias ventajas:
%\begin{itemize}
%\item \textbf{Cobertura completa}: Garantiza que todas las configuraciones válidas dentro de los límites establecidos sean exploradas.
%\item \textbf{Detección de casos límite}: Al generar todas las combinaciones posibles, aumenta la probabilidad de detectar errores en casos extremos o inusuales.
%\item \textbf{Eficiencia}: Las técnicas de poda y filtrado evitan la generación de configucciones redundantes o inválidas, optimizando el proceso.
%\end{itemize}
%
%En esta tesis, Korat se utiliza como una herramienta de referencia para evaluar la efectividad de nuevas técnicas de generación de pruebas. Su enfoque sistemático y basado en especificaciones lo convierte en un estándar ideal para comparar la cobertura y la calidad de los casos de prueba generados. Además, su capacidad para explorar exhaustivamente el espacio de entradas dentro de límites acotados proporciona una base sólida para identificar deficiencias en otros métodos de generación de pruebas.
%
%%En resumen, la generación exhaustiva acotada de entradas representa un compromiso entre la cobertura exhaustiva y la factibilidad práctica, ofreciendo una estrategia eficaz para la prueba de APIs, especialmente en sistemas donde la calidad y la seguridad son primordiales.
%
%\pp{Hacer una única sección con estas dos}
%
%% Los enfoques de generación de pruebas automatizadas tienen como objetivo ayudar a los desarrolladores en tareas cruciales de prueba de software [TODO ???], como la generación automática o facilitar la creación de conjuntos de pruebas [TODO: ????] y la detección y reporte automáticos de fallas [TODO: ????] . Muchos de estos enfoques implican componentes aleatorios que evitan una exploración sistemática del espacio de comportamientos, pero mejoran la eficiencia de la generación de pruebas [TODO: ????] . Si bien estos enfoques han sido muy útiles para encontrar una gran cantidad de errores en el software, podrían perder la exploración de ciertos comportamientos defectuosos del software debido a su naturaleza aleatoria. Los enfoques alternativos tienen como objetivo explorar sistemáticamente un número muy grande de ejecuciones del software bajo prueba (SUT), con el objetivo de proporcionar garantías más sólidas sobre la ausencia de errores[TODO: ????] . Uno de estos enfoques es la generación exhaustiva acotada (BE) [TODO: ????] , que consiste en generar todas las estructuras factibles que se pueden construir utilizando dominios de datos acotados. Los objetivos comunes de los enfoques BE han sido implementaciones de estructuras de datos complejas y dinámicas con ricos y estructurados enlaces (por ejemplo, listas enlazadas, árboles, etc.). Los enfoques BE de caja negra [TODO: ????]  son los más utilizados y eficientes para probar software. Requieren que el usuario proporcione una especificación formal de las restricciones que las estructuras deben satisfacer, con mayor frecuencia una invariante de representación de la estructura (repOK), y los límites de los dominios de datos [TODO: ????] , a menudo llamados \emph{scope}. De este modo, los enfoques BE de caja negra generan todas las estructuras dentro de los ámbitos proporcionados que satisfacen repOK.
%% Varios estudios muestran que los enfoques BE son efectivos para revelar fallas en el software [TODO ???]. Además, la llamada hipótesis del cota pequeña [TODO ?], que establece que la mayoría de las fallas de software se pueden revelar ejecutando el SUT en "entradas pequeñas", sugiere que, si se utilizan ámbitos lo suficientemente grandes, los enfoques BE deberían ser capaces de revelar la mayoría (si no todas) las fallas en el SUT. El desafío que enfrentan los enfoques BE es cómo explorar eficientemente un gran espacio de búsqueda, que en el peor de los casos crece exponencialmente con respecto a los ámbitos. El espacio de búsqueda a menudo incluye un gran número de estructuras no válidas (que no satisfacen repOK) y estructuras isomórficas [TODO ??]. Por lo tanto, podar partes del espacio de búsqueda que involucran estructuras inválidas y redundantes es clave para hacer que los enfoques BE se escalen en la práctica [TODO ??]. Escribir especificaciones formales apropiadas para la generación de BE es una tarea desafiante y que consume mucho tiempo. Las especificaciones deben capturar precisamente el conjunto de restricciones previstas en las estructuras. Las especificaciones sobrerestringidas hacen que falte la generación de una parte de las estructuras válidas, lo que puede hacer que la etapa de prueba subsiguiente pierda la exploración de los comportamientos defectuosos del SUT. Las especificaciones subrestringidas pueden llevar a la generación de estructuras inválidas (es decir, estructuras que no cumplen con las restricciones previstas), lo que puede producir falsos negativos durante la prueba del SUT. Además, a veces el usuario tiene que tener en cuenta la forma en que opera el enfoque de generación y escribir las especificaciones de una manera muy específica, de manera que el enfoque pueda lograr un buen rendimiento [TODO ???]. Finalmente, tales especificaciones formales precisas rara vez están disponibles en el software, lo que dificulta la usabilidad de los enfoques BE de caja negra.
%

\section{Randoop: Generación aleatoria de tests guiada por retroalimentación}
\label{sec:feedback-directed-test-gen}

% \begin{lstlisting}[caption={Método generar pruebas},basicstyle=\ttfamily\scriptsize]
%     public Set<Test> generarPruebas(Set<Metodo> mds, int tLimite, int nPruebas) {
%         Set<Test> tests = new HashSet<>();
%         long inicio = System.currentTimeMillis();
        
%         while (System.currentTimeMillis() - inicio < tLimite 
%                && tests.size() < nPruebas) {
            
%             Metodo metSel = selMetodoAleatorio(mds);
%             List<Parametro> params = new ArrayList<>();
            
%             for (Parametro param : metSel.getParams()) {
%                 Tipo tipo = param.getTipo();
%                 Object valor;
                
%                 if (tipo.esPrimitivo()) {
%                     valor = genValorPrimitivo(tipo);
%                 } else {
%                     valor = genSecuenciaTests(tests, tipo);
%                 }
%                 params.add(new ParamInstanciado(param, valor));
%             }
%             tests.add(new Test(metSel, params));
%         }
%         return tests;
%     }
%     \end{lstlisting}
    
El testing es una técnica fundamental para mejorar la confiabilidad del software
y detectar errores en el código \cite{Ammann16}. 
Sin embargo, escribir los tests de manera manual es una tarea trabajosa, y
requiere un esfuerzo importante por parte de los desarrolladores. Es por esto
que en los últimos años la comunidad de la ingeniería de software ha puesto especial énfasis en el
el desarrollo de técnicas automáticas que permitan automatizar la generación de
tests \cite{Boyapati02,Khurshid01,Fraser11,Visser05,Pasareanu:2010,Cadar08,Tillmann:2010,Ma15,Ponzio:2016,Rosner14}.
Uno de los enfoques más importantes para esta tarea es la generación aleatoria
de tests \cite{Chen19,Li18,Ramler12,Shamshiri15}. 
%que explora el espacio de entrada del programa mediante la ejecución de combinaciones diversas de valores y secuencias de invocaciones. 
Dentro de estos enfoques, Randoop se destaca como una herramienta ampliamente
utilizada, debido a su capacidad para generar tests que han mostrado ser útiles para revelar
fallas en distintos tipos de software muy utilizados \cite{Pacheco07,Pacheco08,Shamshiri15,just2014mutants}

Randoop utiliza la API del SUT (por las siglas de \emph{software under test}) para generar secuencias de tests, es decir,
secuencias de invocaciones a métodos de la API. Randoop propone la técnica
de generación aleatoria con retroalimentación basada en la ejecución, que
consiste en ejecutar las secuencias de test y observar los resultados para 
determinar si se debe continuar extendiendo o no las secuencias de test. 
El algoritmo principal de Randoop se describe en la Figura \ref{fig:randoop-algorithm}.

\begin{figure}[H]
    \centering
    \begin{algorithm}[H]
        \SetAlgoLined
        \KwIn{Conjunto de métodos $M_1,\ldots,M_n$, tiempo límite $S$, número deseado de tests $W$}
        \KwOut{Tests de regresión}
        
        $prev \leftarrow \emptyset$\;
        $tests \leftarrow \emptyset$\;
        
        \While{tiempo transcurrido $< S$ \textbf{y} $|tests| < W$}{
            Seleccionar aleatoriamente $M(p_1:T_1, \ldots, p_m:T_m) \in \{M_1,\ldots,M_n\}$\;
            \For{$p_i:T_i$ de $M$}{
                \If{$T_i$ es primitivo}{
                    $S_i \leftarrow$ valor primitivo para $T_i$ tomado
                    aleatoriamente de las semillas\;
                }\Else{
                    $S_i \leftarrow$ secuencia aleatoria $\in prev$ que crea objeto de tipo $T_i$\;
                }
            }
            $test \leftarrow S_1; \ldots; S_m; M(v_1,\ldots,v_m)$\;
            $res \leftarrow ejecutar($test$)$\;
            \If{res = falla} {
                \Return{$\{ test \}$}\;
            }   
            \If{res = inválido} {
                // No se guarda test para futuras extensiones
            }       
            \If{res = exito} {
                $prev \leftarrow prev \cup \{test\}$\;
            }        
            $tests \leftarrow tests \cup \{test\}$\;
        }
        \Return{$tests$}\;
    \end{algorithm}
    \caption{Algoritmo de Randoop}
    \label{fig:randoop-algorithm}
\end{figure}


\textsf{Randoop} toma como entradas un conjunto de rutinas (por ejemplo, la API
de un módulo), y criterios de terminación para la generación de tests, como el tiempo
máximo de generación \emph{S}, y/o la cantidad máxima de tests a generar \emph{W}.
Como salida, \textsf{Randoop} produce tests de regresión para el módulo, que
ejercitan los métodos dados.

\textsf{Randoop} representa los tests como secuencias de invocaciones a 
rutinas. Estas se denominan \emph{secuencias de
test}. \textsf{Randoop} comienza con unos pocos valores ``semilla''
predeterminados para los tipos primitivos de Java, que se utilizarán para
instanciar los parámetros de tipos primitivos de las rutinas durante la
generación. El usuario también puede proporcionar valores semilla adicionales
para los tipos primitivos. 

Inicialmente, se inicializan dos conjuntos de secuencias de test (líneas 1 y 2). 
\emph{prev} almacena las secuencias de test generadas en iteraciones previas cuya
ejecución es exitosa, es decir, las secuencias de test que el algoritmo intentará
extender con métodos adicionales. \emph{tests} se utiliza para guardar los tests
de regresión que produce el algoritmo como resultado.

\textsf{Randoop} construye secuencias de test de manera
iterativa, hasta que se alcance alguno de los criterios de terminación
provistos por el usuario, en su ciclo principal (líneas 3-18). 
Cada iteración consiste en seleccionar aleatoriamente una rutina \texttt{M},
para usarla en la creación de una nueva secuencia de test (línea 4). 
Para lograr esto, \textsf{Randoop} debe seleccionar secuencias \texttt{S$_1$,..,S$_k$}
que le permitan crear valores (del tipo correcto) para instanciar los parámetros 
\texttt{p$_1$,..,p$_m$} de \texttt{M} (lineas 5-25). 
Si el parámetro \texttt{p$_i$} es de tipo primitivo, el algoritmo simplemente
crea una secuencia de test que produce un valor primitivo, eligiendo
aleatoriamente un valor entre las semillas del tipo (líneas 6-8). 
Por ejemplo, para \texttt{p$_i$} de tipo entero, 
\textsf{Randoop} puede crear la secuencia \texttt{S$_i$} definida como 
\texttt{int vi = -1;}.
En caso de que \texttt{p$_i$} sea de tipo referencia, el algoritmo elige
aleatoriamente una secuencia \texttt{S$_i$} que sirve para crear un objeto del
tipo de \texttt{p$_i$}, tomando \texttt{S$_i$} del conjunto de secuencias generadas 
previamente (\texttt{prev}) (líneas 9-11).

De esta manera, la nueva secuencia de test, \texttt{test}, se crea componiendo
secuencialmente las secuencias \texttt{S$_1$,..,S$_m$} y \texttt{M},
reemplazando los parámetros formales de \texttt{M} por las variables
correspondientes en \texttt{S$_1$,..,S$_m$} (línea 13). 

Las líneas 14-23 del algoritmo implementan la retroalimentación guiada por la ejecución
de las secuencias de test. La idea principal es ejecutar \texttt{test} (línea
14), y observar el comportamiento de la ejecución. Si \texttt{test} revela una
falla el SUT, \textsf{Randoop} termina su ejecución y retorna al usuario el test que
revela la falla (líneas 15-17). Esto sucede, por ejemplo, cuando el test lanza una excepción 
que se corresponde con una falla (\texttt{NullPointerException}), cuando viola un contrato implícito 
de Java, o una especificación dada por el usuario \cite{Pacheco07}.

En cambio, si el test lanza otros tipos de excepciones que no se corresponden
con fallas en el SUT, \textsf{Randoop} simplemente descarta el test, y no lo guarda para
extenderlo en iteraciones futuras del algoritmo (líneas 18-20). Ejemplos de
estos tipos de excepciones son las que representan un uso inválido de la API,
como las excepciones correspondientes a la violación de una
precondición (\texttt{IllegalStateException}).

Por último, si el test termina exitosamente (líneas 21-23), se lo guarda en el
conjunto \texttt{prev} de secuencias que usarán en el futuro para ser extendidas
y así generar nuevos tests. 

Notar que tanto los tests que lanzan excepciones (que no representan fallas) como los 
exitosos se guardan en el conjunto de tests de regresión creados por el
algoritmo (\texttt{tests} en la línea 24). Cuando el ciclo principal termina,
\textsf{Randoop} retorna los tests de regresión generados.

Las evaluaciones experimentales han encontrado que la generación aleatoria de tests dirigida 
por retroalimentación funciona significativamente mejor que la generación
aleatoria tradicional \cite{Pacheco07,Pacheco08}.
La principal ventaja de \textsf{Randoop} es su capacidad para generar
automáticamente una gran cantidad de casos de prueba muy rápidamente, y así 
detectar fallas que pueden pasar desapercibidas durante el testing
manual \cite{Pacheco07,Pacheco08}.

\pp{Poner ejemplo de ejecución de Randoop ilustrando el algoritmo acá abajo.}


Para ilustrar el funcionamiento de Randoop, consideremos la clase
\texttt{java.util.LinkedList}. El generador parte de un conjunto pequeño de
valores primitivos (por ejemplo, 0, 1, 2, $-1$, $-2$) y de los
constructores públicos disponibles. En una primera ejecución, Randoop
selecciona aleatoriamente el constructor \texttt{LinkedList()} y
ejecuta la secuencia:
\\
\begin{lstlisting}[language=Java,basicstyle=\ttfamily\small,columns=fullflexible,keepspaces=true]
LinkedList<Integer> l = new LinkedList<>();
\end{lstlisting}

Como la ejecución no produce fallos, la secuencia y el objeto resultante
se incorporan al \emph{pool} para futuras extensiones.

En una iteración posterior, Randoop elige al azar un método, por ejemplo,
\texttt{add(Object)}. Para obtener una lista sobre la cual invocar el
método, reutiliza la secuencia previa que construye \texttt{l}. Para el
parámetro, toma un entero disponible en el \emph{pool} (por ejemplo, 1).
La secuencia extendida queda:
\\
\begin{lstlisting}[language=Java,basicstyle=\ttfamily\small,columns=fullflexible,keepspaces=true]
LinkedList<Integer> l = new LinkedList<>();
l.add(1);
\end{lstlisting}

La ejecución es exitosa y la nueva secuencia pasa a estar disponible para
nuevas extensiones.

En otra iteración, Randoop genera una secuencia que incluye
\texttt{l.get(2)} sobre una lista de tamaño 1. La invocación arroja una
excepción por índice fuera de rango. Debido a su estrategia de
\emph{feedback-directed random testing}, Randoop descarta esa secuencia
fallida y deja de ampliarla. Solo las secuencias que ejecutan sin fallos
se siguen extendiendo, guiando así la exploración de las secuencias de la
API~\cite{Pacheco07,Pacheco08}.

\cacho{Ver si agregar algo mas }
%Una de las técnicas que presentamos en esta tesis, \textsf{BEAPI}, se basa en \textsf{Randoop}, pero en lugar de la generación aleatoria, tiene como objetivo generar \emph{todas} las secuencias de pruebas factibles (acotadas), dentro de un alcance dado. La retroalimentación de la ejecución permite a \textsf{BEAPI} descartar pruebas ilegales durante el proceso de generación. Además, al estar basado en una generación de pruebas dirigida por retroalimentación, \textsf{BEAPI} genera una secuencia de prueba para cada estructura en el conjunto exhaustivo acotado que construye y solo guarda los conjuntos de secuencias de llamadas a métodos que generan objetos válidos.
%

%Uno de los enfoques que presentamos en esta tesis, BEAPI, toma como base la idea de Randoop pero introduce una diferencia clave: en lugar de generar pruebas de manera aleatoria, 
%BEAPI busca generar todas las secuencias de prueba factibles dentro de un alcance acotado. Es decir, en lugar de depender de la aleatoriedad, 
%BEAPI explora sistemáticamente el espacio de búsqueda, asegurando una mayor cobertura.
%Además, BEAPI aprovecha la retroalimentación de la ejecución para descartar pruebas ilegales de manera eficiente, 
%reduciendo el número de combinaciones a evaluar. También genera una única secuencia de prueba para cada estructura válida, 
%evitando la repetición innecesaria de casos similares.



% \section{Algoritmos Perezosos? (Greedy)}
% \label{sec:greedyPrev}
% El algoritmo Greedy es una estrategia de resolución de problemas que sigue un enfoque voraz, tomando decisiones locales óptimas en cada etapa con la esperanza de llegar a una solución global óptima. A diferencia de otros enfoques, el algoritmo Greedy no realiza una búsqueda exhaustiva en el espacio de soluciones, sino que se centra en elegir la mejor opción disponible en cada momento.

% El enfoque Greedy se basa en la idea de que, al tomar decisiones óptimas en cada etapa, se puede obtener una solución aproximadamente óptima para el problema en general. Sin embargo, debido a su naturaleza voraz, el algoritmo Greedy puede no garantizar una solución óptima en todos los casos. En algunos casos, el algoritmo puede llegar a un óptimo local, pero no a un óptimo global. Por lo tanto, es importante tener en cuenta las limitaciones y restricciones del problema al aplicar el algoritmo Greedy.

% \begin{algorithm}[H]
%   \SetAlgoLined
%   \SetKwInOut{Input}{Input}
%   \SetKwInOut{Output}{Output}
%   \SetKwFunction{Greedy}{Greedy}

%   \caption{Greedy Algorithm}

%   \Input{Set $S$}
%   \Output{Solution $R$}

%   \BlankLine
%   $R \gets \emptyset$ 
%   $U \gets S$ \tcp*{Set of available elements}

%   \BlankLine
%   \While{$U \neq \emptyset$}{
%     $x \gets$ element selected according to Greedy criteria
    
%     $R \gets R \cup \{x\}$ \tcp*{Add $x$ to the solution}
%     $U \gets U \setminus \{x\}$ \tcp*{Remove $x$ from available elements}
%   }

%   \BlankLine
%   \Return $R$ 

% \end{algorithm}

% El algoritmo comienza con un conjunto de elementos disponibles y un conjunto solución vacío. En cada iteración, se selecciona el elemento óptimo según la función de heurística para los estados que se haya implementado y se agrega a la solución. Luego, se elimina ese elemento de los disponibles y se repite el proceso hasta que no queden elementos disponibles.

% Es importante tener en cuenta que el algoritmo Greedy no garantiza encontrar la solución óptima en todos los casos, ya que puede quedarse atrapado en mínimos locales. Sin embargo, en muchos casos, el enfoque Greedy proporciona soluciones rápidas y razonables.

% En esta tesis se personalizó el algoritmo para detectar subconjuntos óptimos de métodos \emph{builders}. 
% Para mas informacion sobre este tipo de algoritmos, invitamos al lector referirse a \cite{Cormen2009}, \cite{kleinberg2006}



\section{Criterios de Cobertura}
\label{sec:coverage}
La evaluación de técnicas de análisis automático de software (incluyendo las
técnicas de generación automática de tests), como las presentadas en esta tesis, requieren de métricas que cuantifiquen su capacidad para ejercitar el código y exponer defectos. 
Los criterios de cobertura tradicionales proveen formas relativamente sencillas de evaluar 
la calidad de una suite de tests, debido a que típicamente hay una alta correlación entre
la satisfacción de los criterios y la capacidad de detección de defectos de la
suite \cite{Ammann16,just2014mutants}. 
En particular, Just et al.~\cite{just2014mutants} muestran que existe una fuerte
correlación entre la detección de mutantes y la detección de fallas reales, lo
que respalda el uso de la mutación como sustituto práctico para evaluar la
eficacia de un conjunto de tests.

En esta sección describimos tres criterios fundamentales adoptados en esta tesis: 
(i) cobertura de código, considerando tanto líneas como ramas \cite{Ammann16,myzili2012coverage}, 
(ii) análisis de mutación \cite{jia2011analysis,Ammann16,just2014mutants}, 
y \cacho{Esto no me cierra:} (iii) la identificación de métodos observadores, propuesta en esta tesis como un criterio adicional
específico para APIs de estructuras de datos. 
Las dos primeras técnicas son ampliamente utilizadas en la literatura y proporcionan 
métricas objetivas para medir la calidad de los tests, mientras que la tercera constituye
una contribución original de este trabajo.

\subsection{Cobertura de Código}

La cobertura de líneas mide el porcentaje de
líneas de código del SUT que han sido ejecutadas por los tests. 
Esta técnica evalúa la exhaustividad de los tests al determinar si cada línea de código ha sido ejecutada al menos una vez. 
Sin embargo, la cobertura de líneas no mide si se han ejecutado todas las ramas
posibles en el programa, lo que puede limitar su capacidad para detectar fallas
en ciertos escenarios.

La cobertura de ramas mide qué porcentaje de las
decisiones lógicas de un programa ha sido ejercitado por los tests. En otras
palabras, se refiere a la medida en que se han ejecutado las ramas de decisión
(if-else, switch-case, ciclos, etc.) en el código fuente durante la ejecución de
los tests. La cobertura de ramas es especialmente útil para identificar áreas del 
código que no han sido ejercitadas y que podrían contener errores lógicos o comportamientos no deseados.
Al lograr una alta cobertura de ramas, se aumenta la confianza en la calidad de
los tests implementados, ya que se ha examinado exhaustivamente la lógica del programa 
en diferentes condiciones de ejecución.

Cabe destacar que los criterios anteriores no imponen ninguna obligación sobre
las aserciones que se deben escribir en los tests. Debido a esto, puede que los
tests no revelen una falla si no tienen las aserciones apropiadas, incluso
cuando cubren el defecto con la entrada adecuada.  

\subsection{Análisis de Mutación}

El análisis de mutación (mutation testing) es una técnica para medir la
capacidad de un conjunto de tests para detectar cambios sintácticos
introducidos deliberadamente en el código fuente. Consiste en la creación de versiones 
alteradas del código original, denominadas mutantes, mediante la realización de
cambios sintáticos pequeños (ej. reemplazar $>$ por $>=$). Cada mutante representa una 
posible variación o error que podría haberse introducido en el código original.
Una vez generados, se ejecutan los tests sobre los mutantes. 
Si algún test de la suite falla al ejecutar el mutante se considera que ha
\'matado\' al mutante. Esto significa que los tests son capaces de detectar el error 
introducido por el mutante. Un mutante sobrevive si ningún test de la suite 
detecta el cambio. Esto implica que es posible mejorar la suite para aumentar su capacidad 
para encontrar errores, por ejemplo, agregando un nuevo test que mate el mutante.

El puntaje de mutación de una suite (mutation score) se define como
el cociente entre la cantidad de mutantes muertos y el total de mutantes
generados. Así, un puntaje de mutación alto da una mayor confianza de que la suite 
de tests tiene una buena capacidad de revelar defectos en el SUT. 
Por otro lado, al identificar los mutantes que no son detectados por los tests 
se pueden identificar deficiencias en la suite, y se pueden tomar medidas 
correctivas para mejorar su calidad.

El análisis de mutación es uno de los criterios más fuertes para evaluar la 
calidad de los tests, ya que los mutantes generados por las operadores de 
mutación más usados 
tienen una alta correlación con las fallas que cometen los desarrolladores 
(incluso, una mayor correlación que los criterios anteriores) \cite{just2014mutants}. Sin
embargo, su costo computacional es elevado (requiere generar un
número usualmente grande de mutantes, y ejecutar los tests para todos ellos). 
Suele ser el criterio más trabajoso para el desarrollador, ya que usualmente 
se requiere un número relativamente grande de tests para lograr un buen puntaje 
de mutación (suele ser significativamente mayor que la cantidad de tests
    requeridos para lograr buena cobertura de código) \cite{papadakis2019}.

Las técnicas mencionadas anteriormente se aplican en esta tesis para evaluar las 
nuevas técnicas propuestas, y poder realizar una comparación con herramientas
relacionadas del estado de arte. Además, se utilizan como base para la
definición de algunas de las técnicas presentadas. Por ejemplo, la cobertura de
código se usa como parte de la función objetivo para el cómputo de métodos
generadores de objetos usando Randoop \ref{sec:fitnessRandoop}.


\section{Java PathFinder (JPF)}
\label{sec:jpf}

\emph{Java PathFinder} (JPF) es una herramienta de verificación automática de programas Java, que implementa técnicas con
exploración explícita del espacio de estados. Entre sus aplicaciones está el \emph{bounded model checking} (BMC), que
consiste en explorar sistemáticamente todas las ejecuciones del programa bajo entradas de tamaño acotado en busca de fallas
\cite{Visser05,Pasareanu:2010}. Los límites para el tamaño de las entradas (por ej., número máximo de nodos o rangos de primitivos)
son provistos por la persona usuaria. Cuando se detecta una falla, JPF produce un contrajemplo reproducible que facilita el
\emph{debugging}.\footnote{\url{https://github.com/javapathfinder/jpf-core}}

Para realizar verificación acotada, JPF se basa en \emph{drivers} (también llamados controladores): combinaciones de métodos que permiten construir todas las
entradas acotadas para ejecutar el código bajo análisis. En tipos de datos complejos (por ej., estructuras dinámicas en el \emph{heap}
como listas doblemente enlazadas) la construcción suele requerir varias rutinas de la API del módulo (ejemplo, \texttt{add},
\texttt{remove}, etc.), por lo que el diseño del \emph{driver} depende de dichas rutinas.

En módulos con muchas operaciones, seleccionar rutinas para el \emph{driver} no es trivial y puede impactar fuertemente en el
análisis posterior. Se busca un conjunto tan pequeño como sea posible cuyas combinaciones permitan construir todas las
estructuras acotadas del módulo. Incluir rutinas superfluas incrementa exponencialmente las combinaciones y degrada la
eficiencia. Un caso típico de rutina superflua son los métodos observadores (no modifican el estado) \cite{Huang:2012}. 
A la vez, el subconjunto debe ser suficiente para generar todas las instancias dentro del alcance. 
Esta selección suele hacerse manualmente, exige revisar toda la API y comprender su semántica, y se vuelve tediosa cuando
hay redundancia o muchas operaciones irrelevantes.

Las propiedades pueden expresarse con \emph{assert}; si la condición resulta falsa en una ejecución, JPF reporta un
contrajemplo. Por ejemplo, para cualquier lista de entrada \texttt{t}, insertar al inicio un entero \texttt{v} (\texttt{addFirst(v)}, con \texttt{v} en
\([0,b]\)) que no pertenezca a la lista, y luego eliminar el primer elemento (\texttt{removeFirst()}), debe dejar el mismo tamaño.

\begin{algorithm}[H]
  \caption{Propiedad a chequear}
  \label{alg:propiedad-a-chequear}
  $oldSize \gets t.\texttt{size()}$\;
  $value \gets \texttt{Verify.getInt}(0, b)$\;
  \texttt{Verify.ignoreIf}( $t.\texttt{contains}(value)$ )\;
  $t.\texttt{addFirst}(value)$\;
  $t.\texttt{removeFirst}()$\;
  \texttt{assert } $oldSize$ \texttt{ == } $t.\texttt{size}()$
  \texttt{ : "different size";}\;
\end{algorithm}


Para introducir elecciones dentro de un mismo programa, JPF ofrece primitivas de no determinismo, como:
\begin{itemize}
\item \texttt{Verify.ignoreIf(condicion)}: Evita explorar ejecuciones cuyo estado no
cumplen con el predicado condicion. En el programa anterior, permite ignorar todas las ejecuciones en las que la lista contiene el valor \emph{value} a insertar.
Esto es similar a agregar una precondición a la propiedad a verificar.
\item \texttt{int i = Verify.getInt(min,max)}: Esta construcción de JPF explora todas las posibles ejecuciones del programa que resultan de asignar 
a \emph{i} cualquier valor entre min y max. Esto significa que JPF ejecutará el código luego
de esta instrucción con \emph{i=min}, con \emph{i=min+1, ..., i=max}. Esto introduce no
determinismo, ya que en principio no hay garantías del orden en que se
asignarán valores a \emph{i} (aunque JPF tiene opciones para elejir un orden de
ejecución particular). 
\end{itemize}

Para analizar la propiedad del algortimo \ref{alg:propiedad-a-chequear} , JPF necesita mecanismos para generar
las listas del parámetro \texttt{t}. Los enteros se obtienen con
\texttt{Verify.getInt}, pero las estructuras requieren un
\emph{driver}. El objetivo es construir todas las listas de tamaño
máximo \(b\), con elementos en \([0,b]\) (verificación exhaustiva
acotada). El \emph{driver} selecciona una longitud
\(maxLength \in [0,b]\). Como cada método considerado agrega a lo sumo
un elemento, ejecutar a lo sumo \(b\) métodos produce listas de
tamaño \(\le b\). En cada iteración se elige no determinísticamente
una operación de la API y sus argumentos.

Si la persona usuaria no conoce los métodos generadores (y no desea seleccionarlos manualmente), la alternativa más segura es
usar todos los métodos del módulo, como se muestra en el algortimo \ref{lst:driverNCL}. En el
cuerpo del ciclo, a cada operación se le asigna un identificador y se elige no determinísticamente un valor en \([0, m)\) para
seleccionar la operación a ejecutar; por ejemplo, si
\texttt{methodN=2}, se ejecuta \texttt{clear()}. El número de ejecuciones crece exponencialmente con \(m\) (cantidad de
métodos): tras \(k\) pasos hay \(m^{k}\) secuencias potenciales.
\\
\begin{lstlisting}[language=Java,caption={Controlador con todos los métodos},label={lst:driverNCL},captionpos=b] 
private static NCL generateStructure(int scope) {
  int maxLength = Verify.getInt(0, scope);
  NCL t = new NCL();
  for (int i = 1; i <= maxLength; i++) {
    int n_methods = Verify.random(n_methods)
    switch (n_methods) {
      case 0:
        t.addFirst(Verify.getInt(0,scope),Verify.getInt(0,scope));
        break;
      case 1:
        t.removeFirst(Verify.getInt(0,scope));
        break;
      case 2:
        t.clear();
        break;
      case 3:
        t.containsValue(Verify.getInt(0,scope));
        break;
      // ...
      case 33:
        t.size(l);
        break;
      default:
        /* no-op */
    }
  }
  return t;
}
\end{lstlisting}


En esta tesis proponemos una técnica automática que, dada la API de un módulo, identifica un subconjunto suficiente y no superfluo de
métodos generadores (ver Capitulo \ref{cap:builders}). Esta técnica actúa como paso previo a la construcción del controlador
para BMC. Al exponer sólo los métodos generadores necesarios, reduce el factor de ramificación del controlador, disminuye el
espacio de búsqueda y mejora la eficiencia de la exploración, sin perder la capacidad de generar todas las instancias acotadas dentro
del \emph{scope}.