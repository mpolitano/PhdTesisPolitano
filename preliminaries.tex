\chapter[Preliminares]{Preliminares}
\label{cap:preliminares.BE}

\section{Testing}
El testing constituye una de las estrategias más directas y ampliamente utilizadas para verificar el comportamiento de un programa.
Esta técnica consiste en ejecutar el software bajo distintas condiciones específicas, observando si los resultados obtenidos se corresponden con los resultados esperados. 
Dado que no es factible analizar el comportamiento de un programa frente a todas las posibles entradas (debido a que este conjunto puede ser extremadamente grande o incluso infinito, como sucede en programas que procesan números enteros arbitrarios), 
se recurre a la selección de un subconjunto representativo de casos de prueba, comúnmente denominado \emph{suite de tests}.

El objetivo de esta suite es brindar un nivel de confianza suficiente sobre la corrección funcional del software, 
incluso en escenarios que no han sido ejercitados directamente. 
El testing es una etapa fundamental en los procesos modernos de desarrollo de software. 
Tradicionalmente, se realiza después de la fase de implementación, pero en metodologías de desarrollo ágiles está integrado de manera más continua, 
acompañando activamente el ciclo de desarrollo e incluso guiando decisiones de diseño e implementación.



\section{Korat: Generación exhaustiva acotada basada en especificaciones}
\label{sec:korat}


Korat es uno de los enfoques más conocidos y eficientes para la generación exhaustiva acotada
de entradas para test \cite{Boyapati02}.
Para funcionar, Korat requiere de una especificación formal dada en términos de
un método booleano, denominado \texttt{repOK}, que sirve para determinar si una estructura
es válida o no. Es decir, si satisface o no las restricciones que la estructura
debe cumplir, como por ejemplo, un invariante de representación de una
estructura de datos, una precondición de un método, etc. Korat también requiere 
de la definición del alcance de la generación, (en inglés, el \emph{scope}),
esto es, límites en el tamaño de los dominios de datos a ser utilizados
para la generación de estructuras.

Así, Korat genera de manera exhuastiva todas las estructuras acotadas que
satisfacen las condiciones de validez definidas por el programador en el
\texttt{repOK}. 
Korat explora de manera exhaustiva el espacio de todas las posibles instancias
acotadas de una clase (por ejemplo, listas con hasta $k$ nodos), 
retornando únicamente aquellas que satisfacen el invariante especificado. 

La eficiencia de Korat radica en su estrategia de exploración, 
que evita examinar múltiples estructuras que se sabe, por construcciones previas, que no conducen a estructuras válidas. 
Para lograr esto, Korat realiza una exploración sistemática del espacio de
posibles asignaciones de valores de atributos (por ejemplo, referencias de
nodos, enteros, etc.) utilizando una técnica basada en el seguimiento de los
atributos  leídos por el \texttt{repOK}.
Cada vez que una estructura es evaluada por el método \texttt{repOK}, Korat
registra qué atributos han sido accedidos (conocidos como \emph{field
accesses}). Esta información se utiliza para podar el espacio de búsqueda: si
una configuración parcial del heap no puede dar lugar a una estructura válida
(\texttt{repOK} da false), todas sus extensiones también serán descartadas.
De esta forma, el algoritmo de Korat combina una búsqueda basada en backtracking con poda
guiada por la ejecución del \texttt{repOK}, que le permite explorar 
el espacio de búsqueda acotado eficientemente, evitando explorar estructuras innecesarias. 

Korat ha demostrado ser eficaz y eficiente para la generación de entradas para
estructuras complejas con invariantes con propiedades ricas, como
listas doblemente enlazadas, árboles binarios, heaps binomiales, etc. \cite{Boyapati02}.
%, y ha sido utilizado como base para múltiples trabajos posteriores en verificación y generación de tests. Su enfoque representa un punto de referencia importante para técnicas que requieren generación de entradas válidas y exhaustivas a partir de especificaciones formales, y constituye una herramienta clásica dentro del campo del \emph{bounded exhaustive testing}.









%La \textit{generación exhaustiva de entradas} para probar APIs es una tarea crítica en la prueba de software, ya que permite identificar errores y garantizar que los programas funcionen correctamente bajo diversas condiciones. Sin embargo, el número potencialmente enorme de valores de entrada genera una explosión combinatoria, lo que hace inviable probar todas las posibles combinaciones.
%
%Para abordar este problema, se utiliza la \textit{generación exhaustiva acotada de entradas} (\textit{Bounded Exhaustive Testing, BE}), que consiste en generar todas las combinaciones posibles dentro de un rango predefinido. Este enfoque equilibra cobertura y factibilidad al reducir el espacio de prueba a un subconjunto manejable, sin dejar de incluir casos críticos que podrían pasar desapercibidos con métodos menos sistemáticos, como la \textit{generación aleatoria de pruebas}. Si bien la generación aleatoria es menos costosa computacionalmente, puede omitir casos límite relevantes, afectando la detección de errores.
%
%Korat es una herramienta que implementa la generación exhaustiva acotada, explorando todas las estructuras válidas dentro de ciertas restricciones. Su eficiencia se basa en la poda de combinaciones redundantes y en la eliminacion de estructuras isomorfas redundantes.
%
%El proceso de Korat consta de tres pasos clave:
%
%\begin{enumerate}
%    \item \textbf{Especificación de invariantes}: El usuario define las propiedades que deben cumplir las estructuras de datos, como que un árbol binario no debe tener ciclos y que cada nodo puede tener hasta dos hijos.
%    \item \textbf{Generación de candidatos}: Se generan todas las configuraciones posibles dentro de los límites especificados. Por ejemplo, si se establece un máximo de tres nodos para un árbol binario, se generarán todas las combinaciones con 1, 2 y 3 nodos.
%    \item \textbf{Filtrado y validación}: Se descartan las configuraciones que no cumplen con las restricciones definidas.
%\end{enumerate}
%
%\subsubsection{Ejemplo: Árboles Binarios}
%
%Si queremos probar una función que opera sobre árboles binarios, podemos definir:
%
%\begin{itemize}
%    \item \textbf{Límite}: Máximo 3 nodos.
%    \item \textbf{Invariantes}:
%    \begin{itemize}
%        \item No hay ciclos en el árbol.
%        \item Cada nodo tiene como máximo dos hijos.
%        \item Todos los nodos están conectados.
%    \end{itemize}
%\end{itemize}
%
%Korat generará todas las configuraciones válidas dentro de estos límites, como:
%
%\begin{itemize}
%    \item Un árbol con un solo nodo raíz.
%    \item Un árbol con un nodo raíz y un hijo izquierdo.
%    \item Un árbol con un nodo raíz, un hijo izquierdo y un hijo derecho.
%\end{itemize}
%
%Estos casos de prueba permiten verificar que la función maneja correctamente distintas estructuras de árboles binarios.
%
%\subsection{Ventajas de Korat}
%
%\begin{itemize}
%    \item \textbf{Cobertura completa}: Garantiza la exploración de todas las configuraciones dentro de los límites establecidos.
%    \item \textbf{Detección de casos límite}: Aumenta la probabilidad de encontrar errores en escenarios extremos.
%    \item \textbf{Eficiencia}: Evita la generación de estructuras inválidas o redundantes mediante poda y filtrado.
%\end{itemize}
%
%En esta tesis, Korat se utiliza como referencia para evaluar nuevas técnicas de generación de pruebas. Su enfoque sistemático y basado en especificaciones permite compararlo con otros métodos en términos de cobertura y calidad de los casos generados.
%
%
%
%
%
%La generación exhaustiva de entradas para realizar pruebas a las APIs de los programas es una tarea crítica en la prueba del software, ya que permite identificar errores y garantizar que los programas se comporten correctamente bajo una amplia gama de condiciones. Sin embargo, este proceso es inherentemente complejo debido al número potencialmente enorme de valores de entrada posibles, lo que genera una explosión combinatoria que hace inviable la prueba exhaustiva de todas las posibles entradas.
%
%Para abordar esta problemática, se recurre a la generación exhaustiva acotada de entradas (\emph{Bounded Exhaustive Testing, BE}), una técnica que consiste en generar todas las combinaciones posibles de entradas dentro de un rango o límite predefinido. Este enfoque permite reducir el espacio de entradas a un subconjunto manejable que aún cubre una diversidad significativa de casos, aumentando así la probabilidad de descubrir errores que podrían pasar desapercibidos con otros métodos de prueba.
%
%Por otro lado, una alternativa común a la generación exhaustiva acotada es la generación aleatoria de pruebas. Aunque este método es menos costoso computacionalmente y puede ser útil en ciertos contextos, presenta el inconveniente de que podría no cubrir casos críticos o bordes del espacio de entradas, lo que podría resultar en la omisión de errores significativos.
%
%En resumen, la generación exhaustiva acotada de entradas representa un compromiso entre la cobertura exhaustiva y la factibilidad práctica, ofreciendo una estrategia eficaz para la prueba de APIs, especialmente en sistemas donde la calidad y la seguridad son primordiales.
%
%Korat es una herramienta que implementa la técnica de generación exhaustiva acotada. Korat es una herramienta poderosa para la generación exhaustiva acotada de casos de prueba, permitiendo explorar todas las posibles estructuras válidas dentro de las restricciones establecidas. Su enfoque basado en filtrado, combinado con técnicas de poda y evitando las estructuras isomorfas, garantiza la eficiencia y efectividad en la generación de casos de prueba.
%
%La idea fundamental detrás de Korat es generar todas las configuraciones válidas de una estructura de datos dentro de un rango acotado (por ejemplo, un número máximo de nodos en un árbol o elementos en una lista). A diferencia de la generación aleatoria de pruebas, Korat garantiza que se exploren todas las combinaciones posibles dentro de los límites establecidos, lo que aumenta la probabilidad de detectar errores sutiles o casos límite.
%
%El proceso de Korat se basa en tres pasos clave:
%\begin{enumerate}
%\item \textbf{Especificación de invariantes}: El usuario define las propiedades que deben cumplir las estructuras de datos mediante predicados lógicos. Por ejemplo, en un árbol binario, se puede especificar que no debe contener ciclos y que cada nodo debe tener como máximo dos hijos
%
%\item \textbf{Generación de candidatos}: Korat genera todas las posibles configuraciones de la estructura de datos dentro de los límites especificados. Por ejemplo, si se define un límite de 3 nodos para un árbol binario, Korat generará todas las combinaciones posibles de árboles con 1, 2 o 3 nodos.
%
%\item \textbf{Filtrado y validación}: Cada configuración generada es validada contra los invariantes especificados. Solo las configuraciones que cumplen con las restricciones son retenidas como casos de prueba válidos.
%
%\end{enumerate}
%
%Para ilustrar el funcionamiento de Korat, consideremos el siguiente ejemplo concreto:
%
%\subsubsection{Ejemplo: Árboles Binarios}
%Supongamos que queremos probar una función que opera sobre árboles binarios. Con Korat, podemos definir los siguientes límites y restricciones:
%\begin{itemize}
%\item Límite: Árboles con un máximo de 3 nodos.
%\item Invariantes:
%\begin{itemize}
%\item No hay ciclos en el árbol.
%\item Cada nodo tiene como máximo dos hijos.
%\item Todos los nodos están conectados (no hay subárboles desconectados).
%\end{itemize}
%\end{itemize}
%
%Korat generará todas las posibles configuraciones de árboles binarios con 1, 2 y 3 nodos que cumplan con estas restricciones. Por ejemplo:
%\begin{itemize}
%\item Un árbol con un solo nodo raíz.
%\item Un árbol con un nodo raíz y un hijo izquierdo.
%\item Un árbol con un nodo raíz, un hijo izquierdo y un hijo derecho.
%\end{itemize}
%
%Estos casos de prueba permiten verificar que la función bajo prueba maneja correctamente diferentes configuraciones de árboles binarios.
%
%\cacho{Pongo ejemplos de codigo? de repok? de dibujitos?}
%
%La generación exhaustiva acotada implementada por Korat ofrece varias ventajas:
%\begin{itemize}
%\item \textbf{Cobertura completa}: Garantiza que todas las configuraciones válidas dentro de los límites establecidos sean exploradas.
%\item \textbf{Detección de casos límite}: Al generar todas las combinaciones posibles, aumenta la probabilidad de detectar errores en casos extremos o inusuales.
%\item \textbf{Eficiencia}: Las técnicas de poda y filtrado evitan la generación de configucciones redundantes o inválidas, optimizando el proceso.
%\end{itemize}
%
%En esta tesis, Korat se utiliza como una herramienta de referencia para evaluar la efectividad de nuevas técnicas de generación de pruebas. Su enfoque sistemático y basado en especificaciones lo convierte en un estándar ideal para comparar la cobertura y la calidad de los casos de prueba generados. Además, su capacidad para explorar exhaustivamente el espacio de entradas dentro de límites acotados proporciona una base sólida para identificar deficiencias en otros métodos de generación de pruebas.
%
%%En resumen, la generación exhaustiva acotada de entradas representa un compromiso entre la cobertura exhaustiva y la factibilidad práctica, ofreciendo una estrategia eficaz para la prueba de APIs, especialmente en sistemas donde la calidad y la seguridad son primordiales.
%
%\pp{Hacer una única sección con estas dos}
%
%% Los enfoques de generación de pruebas automatizadas tienen como objetivo ayudar a los desarrolladores en tareas cruciales de prueba de software [TODO ???], como la generación automática o facilitar la creación de conjuntos de pruebas [TODO: ????] y la detección y reporte automáticos de fallas [TODO: ????] . Muchos de estos enfoques implican componentes aleatorios que evitan una exploración sistemática del espacio de comportamientos, pero mejoran la eficiencia de la generación de pruebas [TODO: ????] . Si bien estos enfoques han sido muy útiles para encontrar una gran cantidad de errores en el software, podrían perder la exploración de ciertos comportamientos defectuosos del software debido a su naturaleza aleatoria. Los enfoques alternativos tienen como objetivo explorar sistemáticamente un número muy grande de ejecuciones del software bajo prueba (SUT), con el objetivo de proporcionar garantías más sólidas sobre la ausencia de errores[TODO: ????] . Uno de estos enfoques es la generación exhaustiva acotada (BE) [TODO: ????] , que consiste en generar todas las estructuras factibles que se pueden construir utilizando dominios de datos acotados. Los objetivos comunes de los enfoques BE han sido implementaciones de estructuras de datos complejas y dinámicas con ricos y estructurados enlaces (por ejemplo, listas enlazadas, árboles, etc.). Los enfoques BE de caja negra [TODO: ????]  son los más utilizados y eficientes para probar software. Requieren que el usuario proporcione una especificación formal de las restricciones que las estructuras deben satisfacer, con mayor frecuencia una invariante de representación de la estructura (repOK), y los límites de los dominios de datos [TODO: ????] , a menudo llamados \emph{scope}. De este modo, los enfoques BE de caja negra generan todas las estructuras dentro de los ámbitos proporcionados que satisfacen repOK.
%% Varios estudios muestran que los enfoques BE son efectivos para revelar fallas en el software [TODO ???]. Además, la llamada hipótesis del cota pequeña [TODO ?], que establece que la mayoría de las fallas de software se pueden revelar ejecutando el SUT en "entradas pequeñas", sugiere que, si se utilizan ámbitos lo suficientemente grandes, los enfoques BE deberían ser capaces de revelar la mayoría (si no todas) las fallas en el SUT. El desafío que enfrentan los enfoques BE es cómo explorar eficientemente un gran espacio de búsqueda, que en el peor de los casos crece exponencialmente con respecto a los ámbitos. El espacio de búsqueda a menudo incluye un gran número de estructuras no válidas (que no satisfacen repOK) y estructuras isomórficas [TODO ??]. Por lo tanto, podar partes del espacio de búsqueda que involucran estructuras inválidas y redundantes es clave para hacer que los enfoques BE se escalen en la práctica [TODO ??]. Escribir especificaciones formales apropiadas para la generación de BE es una tarea desafiante y que consume mucho tiempo. Las especificaciones deben capturar precisamente el conjunto de restricciones previstas en las estructuras. Las especificaciones sobrerestringidas hacen que falte la generación de una parte de las estructuras válidas, lo que puede hacer que la etapa de prueba subsiguiente pierda la exploración de los comportamientos defectuosos del SUT. Las especificaciones subrestringidas pueden llevar a la generación de estructuras inválidas (es decir, estructuras que no cumplen con las restricciones previstas), lo que puede producir falsos negativos durante la prueba del SUT. Además, a veces el usuario tiene que tener en cuenta la forma en que opera el enfoque de generación y escribir las especificaciones de una manera muy específica, de manera que el enfoque pueda lograr un buen rendimiento [TODO ???]. Finalmente, tales especificaciones formales precisas rara vez están disponibles en el software, lo que dificulta la usabilidad de los enfoques BE de caja negra.
%

\section{Randoop: Generación aleatoria de tests guiada por retroalimentación}
\label{sec:feedback-directed-test-gen}

% \begin{lstlisting}[caption={Método generar pruebas},basicstyle=\ttfamily\scriptsize]
%     public Set<Test> generarPruebas(Set<Metodo> mds, int tLimite, int nPruebas) {
%         Set<Test> tests = new HashSet<>();
%         long inicio = System.currentTimeMillis();
        
%         while (System.currentTimeMillis() - inicio < tLimite 
%                && tests.size() < nPruebas) {
            
%             Metodo metSel = selMetodoAleatorio(mds);
%             List<Parametro> params = new ArrayList<>();
            
%             for (Parametro param : metSel.getParams()) {
%                 Tipo tipo = param.getTipo();
%                 Object valor;
                
%                 if (tipo.esPrimitivo()) {
%                     valor = genValorPrimitivo(tipo);
%                 } else {
%                     valor = genSecuenciaTests(tests, tipo);
%                 }
%                 params.add(new ParamInstanciado(param, valor));
%             }
%             tests.add(new Test(metSel, params));
%         }
%         return tests;
%     }
%     \end{lstlisting}
    
El testing es una técnica fundamental para mejorar la confiabilidad del software
y detectar errores en el código \cite{Ammann16}. 
Sin embargo, escribir los tests de manera manual es una tarea trabajosa, y
requiere un esfuerzo importante por parte de los desarrolladores. Es por esto
que en los últimos años la comunidad de la ingeniería de software ha puesto especial énfasis en el
el desarrollo de técnicas automáticas que permitan automatizar la generación de
tests \cite{Boyapati02,Khurshid01,Fraser11,Visser05,Pasareanu:2010,Cadar08,Tillmann:2010,Ma15,Ponzio:2016,Rosner14}.
Uno de los enfoques más importantes para esta tarea es la generación aleatoria
de tests \cite{Chen19,Li18,Ramler12,Shamshiri15}. 
%que explora el espacio de entrada del programa mediante la ejecución de combinaciones diversas de valores y secuencias de invocaciones. 
Dentro de estos enfoques, Randoop se destaca como una herramienta ampliamente
utilizada, debido a su capacidad para generar tests que han mostrado ser útiles para revelar
fallas en distintos tipos de software muy utilizados \cite{Pacheco07,Pacheco08,Shamshiri15,just2014mutants}

Randoop utiliza la API del SUT (por las siglas de \emph{software under test}) para generar secuencias de tests, es decir,
secuencias de invocaciones a métodos de la API. Randoop propone la técnica
de generación aleatoria con retroalimentación basada en la ejecución, que
consiste en ejecutar las secuencias de test y observar los resultados para 
determinar si se debe continuar extendiendo o no las secuencias de test. 
El algoritmo principal de Randoop se describe en la Figura \ref{fig:randoop-algorithm}.

\begin{algorithm}[htbp]
    \SetAlgoLined
    \KwIn{Conjunto de métodos $M_1,\ldots,M_n$, tiempo límite $S$, número deseado de tests $W$}
    \KwOut{Tests de regresión}
    
    $prev \leftarrow \emptyset$\;
    $tests \leftarrow \emptyset$\;
    
    \While{tiempo transcurrido $< S$ \textbf{y} $|tests| < W$}{
        Seleccionar aleatoriamente $M(p_1:T_1, \ldots, p_m:T_m) \in \{M_1,\ldots,M_n\}$\;
        \For{$p_i:T_i$ de $M$}{
            \If{$T_i$ es primitivo}{
                $S_i \leftarrow$ valor primitivo para $T_i$ tomado
                aleatoriamente de las semillas\;
            }\Else{
                $S_i \leftarrow$ secuencia aleatoria $\in prev$ que crea objeto de tipo $T_i$\;
            }
        }
        $test \leftarrow S_1; \ldots; S_m; M(v_1,\ldots,v_m)$\;
        $res \leftarrow ejecutar($test$)$\;
        \If{res = falla} {
            \Return{$\{ test \}$}\;
        }   
        \If{res = inválido} {
            // No se guarda test para futuras extensiones
        }       
        \If{res = exito} {
            $prev \leftarrow prev \cup \{test\}$\;
        }        
        $tests \leftarrow tests \cup \{test\}$\;
    }
    \Return{$tests$}\;
    \caption{Pseudocódigo del Algoritmo de Randoop}
    \label{fig:randoop-algorithm}
\end{algorithm}



\textsf{Randoop} toma como entradas un conjunto de rutinas (por ejemplo, la API
de un módulo), y criterios de terminación para la generación de tests, como el tiempo
máximo de generación \emph{S}, y/o la cantidad máxima de tests a generar \emph{W}.
Como salida, \textsf{Randoop} produce tests de regresión para el módulo, que
ejercitan los métodos dados.

\textsf{Randoop} representa los tests como secuencias de invocaciones a 
rutinas. Estas se denominan \emph{secuencias de
test}. \textsf{Randoop} comienza con unos pocos valores ``semilla''
predeterminados para los tipos primitivos de Java, que se utilizarán para
instanciar los parámetros de tipos primitivos de las rutinas durante la
generación. El usuario también puede proporcionar valores semilla adicionales
para los tipos primitivos. 

Inicialmente, se inicializan dos conjuntos de secuencias de test (líneas 1 y 2). 
\emph{prev} almacena las secuencias de test generadas en iteraciones previas cuya
ejecución es exitosa, es decir, las secuencias de test que el algoritmo intentará
extender con métodos adicionales. \emph{tests} se utiliza para guardar los tests
de regresión que produce el algoritmo como resultado.

\textsf{Randoop} construye secuencias de test de manera
iterativa, hasta que se alcance alguno de los criterios de terminación
provistos por el usuario, en su ciclo principal (líneas 3-18). 
Cada iteración consiste en seleccionar aleatoriamente una rutina \texttt{M},
para usarla en la creación de una nueva secuencia de test (línea 4). 
Para lograr esto, \textsf{Randoop} debe seleccionar secuencias \texttt{S$_1$,..,S$_k$}
que le permitan crear valores (del tipo correcto) para instanciar los parámetros 
\texttt{p$_1$,..,p$_m$} de \texttt{M} (lineas 5-25). 
Si el parámetro \texttt{p$_i$} es de tipo primitivo, el algoritmo simplemente
crea una secuencia de test que produce un valor primitivo, eligiendo
aleatoriamente un valor entre las semillas del tipo (líneas 6-8). 
Por ejemplo, para \texttt{p$_i$} de tipo entero, 
\textsf{Randoop} puede crear la secuencia \texttt{S$_i$} definida como 
\texttt{int vi = -1;}.
En caso de que \texttt{p$_i$} sea de tipo referencia, el algoritmo elige
aleatoriamente una secuencia \texttt{S$_i$} que sirve para crear un objeto del
tipo de \texttt{p$_i$}, tomando \texttt{S$_i$} del conjunto de secuencias generadas 
previamente (\texttt{prev}) (líneas 9-11).

De esta manera, la nueva secuencia de test, \texttt{test}, se crea componiendo
secuencialmente las secuencias \texttt{S$_1$,..,S$_m$} y \texttt{M},
reemplazando los parámetros formales de \texttt{M} por las variables
correspondientes en \texttt{S$_1$,..,S$_m$} (línea 13). 

Las líneas 14-23 del algoritmo implementan la retroalimentación guiada por la ejecución
de las secuencias de test. La idea principal es ejecutar \texttt{test} (línea
14), y observar el comportamiento de la ejecución. Si \texttt{test} revela una
falla el SUT, \textsf{Randoop} termina su ejecución y retorna al usuario el test que
revela la falla (líneas 15-17). Esto sucede, por ejemplo, cuando el test lanza una excepción 
que se corresponde con una falla (\texttt{NullPointerException}), cuando viola un contrato implícito 
de Java, o una especificación dada por el usuario \cite{Pacheco07}.

En cambio, si el test lanza otros tipos de excepciones que no se corresponden
con fallas en el SUT, \textsf{Randoop} simplemente descarta el test, y no lo guarda para
extenderlo en iteraciones futuras del algoritmo (líneas 18-20). Ejemplos de
estos tipos de excepciones son las que representan un uso inválido de la API,
como las excepciones correspondientes a la violación de una
precondición (\texttt{IllegalStateException}).

Por último, si el test termina exitosamente (líneas 21-23), se lo guarda en el
conjunto \texttt{prev} de secuencias que usarán en el futuro para ser extendidas
y así generar nuevos tests. 

Notar que tanto los tests que lanzan excepciones (que no representan fallas) como los 
exitosos se guardan en el conjunto de tests de regresión creados por el
algoritmo (\texttt{tests} en la línea 24). Cuando el ciclo principal termina,
\textsf{Randoop} retorna los tests de regresión generados.

%Las evaluaciones experimentales han encontrado que la generación aleatoria de tests dirigida 
%por retroalimentación funciona significativamente mejor que la generación
%aleatoria tradicional \cite{Pacheco07,Pacheco08}.
%La principal ventaja de \textsf{Randoop} es su capacidad para generar
%automáticamente una gran cantidad de casos de prueba muy rápidamente, y así 
%detectar fallas que pueden pasar desapercibidas durante el testing
%manual \cite{Pacheco07,Pacheco08}.

Para ilustrar el funcionamiento de Randoop, consideremos la clase
\texttt{java.util.LinkedList}. 
El generador comienza con un conjunto inicial de ``semillas'', es decir, valores
primitivos (por ejemplo, -1, 0, 1 y 100). 
Supongamos que en la primera iteración, \textsf{Randoop}
selecciona aleatoriamente el constructor \texttt{LinkedList()} (linea 4, del algoritmo \ref{fig:randoop-algorithm}). Como no tiene parametros 
para instanciar, el siguiente paso es ejecutar la secuencia de test (línea 14):
\\
\begin{lstlisting}[language=Java,basicstyle=\ttfamily\small,columns=fullflexible,keepspaces=true]
LinkedList<Integer> l = new LinkedList<>();
\end{lstlisting}

Como la ejecución es exitosa, el test resultante
se agrega a \texttt{prev} para que esté disponible para futuras extensiones
(líneas 21-23).

En la iteración siguiente, \textsf{Randoop} elige al azar un método, por ejemplo,
\texttt{add(List, Integer)} (línea 4; notar que el primer parámetro es el objeto
sobre el que se aplica el método). Para obtener una lista sobre la cual invocar el
método, \textsf{Randoop} reutiliza la única secuencia de test disponible en \texttt{prev} (línea
10) que genera una lista (la secuencia de test generada en la iteración anterior). 
Para el parámetro de tipo primitivo, \textsf{Randoop} toma un entero disponible
en el conjunto inicial de semillas (en la línea 7; por ejemplo, 1).
La secuencia completa \texttt{test} (línea 13) es la siguiente:

\begin{lstlisting}[language=Java,basicstyle=\ttfamily\small,columns=fullflexible,keepspaces=true]
LinkedList<Integer> l = new LinkedList<>();
l.add(1);
\end{lstlisting}

La ejecución es exitosa (línea 14) y la nueva secuencia de test se agrega a
\texttt{prev}.

Asumamos que, en una iteración posterior, \textsf{Randoop} genera la siguiente
secuencia de test:

\begin{lstlisting}[language=Java,basicstyle=\ttfamily\small,columns=fullflexible,keepspaces=true]
LinkedList<Integer> l = new LinkedList<>();
l.add(1);
l.get(2);
\end{lstlisting}

La ejecución de esta secuencia (línea 14) da como resultado una excepción porque
se intenta acceder a un índice fuera del rango de la lista. En este caso,
\textsf{Randoop} no almacena el test para ser extendido en el futuro (línea 19).





\section{Criterios de Cobertura}
\label{sec:coverage}
La evaluación de técnicas de análisis automático de software (incluyendo las
técnicas de generación automática de tests), como las presentadas en esta tesis, requieren de métricas que cuantifiquen su capacidad para ejercitar el código y exponer defectos. 
Los criterios de cobertura tradicionales proveen formas relativamente sencillas de evaluar 
la calidad de una suite de tests, debido a que típicamente hay una alta correlación entre
la satisfacción de los criterios y la capacidad de detección de defectos de la
suite \cite{Ammann16,just2014mutants}. 
En particular, Just et al. \cite{just2014mutants} muestran que existe una fuerte
correlación entre la detección de mutantes y la detección de fallas reales, lo
que respalda el uso de la mutación como sustituto práctico para evaluar la
eficacia de un conjunto de tests.

En las secciones siguientes describimos brevemente dos criterios utilizados en esta tesis: 
(i) cobertura de código, considerando tanto líneas como ramas \cite{Ammann16,myzili2012coverage}, 
(ii) análisis de mutación \cite{jia2011analysis,Ammann16,just2014mutants}. 

\subsection{Cobertura de Código}

La cobertura de líneas mide el porcentaje de
líneas de código del SUT que han sido ejecutadas por los tests. 
Esta técnica evalúa la exhaustividad de los tests al determinar si cada línea de código ha sido ejecutada al menos una vez. 
Sin embargo, la cobertura de líneas no mide si se han ejecutado todas las ramas
posibles en el programa, lo que puede limitar su capacidad para detectar fallas
en ciertos escenarios.

La cobertura de ramas mide qué porcentaje de las
decisiones lógicas de un programa ha sido ejercitado por los tests. En otras
palabras, se refiere a la medida en que se han ejecutado las ramas de decisión
(if-else, switch-case, ciclos, etc.) en el código fuente durante la ejecución de
los tests. La cobertura de ramas es especialmente útil para identificar áreas del 
código que no han sido ejercitadas y que podrían contener errores lógicos o comportamientos no deseados.
Al lograr una alta cobertura de ramas, se aumenta la confianza en la calidad de
los tests implementados, ya que se ha examinado exhaustivamente la lógica del programa 
en diferentes condiciones de ejecución.

Cabe destacar que los criterios anteriores no imponen ninguna obligación sobre
las aserciones que se deben escribir en los tests. Debido a esto, puede que los
tests no revelen una falla si no tienen las aserciones apropiadas, incluso
cuando cubren el defecto con la entrada adecuada.  

\subsection{Análisis de Mutación}

El análisis de mutación (mutation testing) es una técnica para medir la
capacidad de un conjunto de tests para detectar cambios sintácticos
introducidos deliberadamente en el código fuente. Consiste en la creación de versiones 
alteradas del código original, denominadas mutantes, mediante la realización de
cambios sintáticos pequeños (ej. reemplazar $>$ por $>=$). Cada mutante representa una 
posible variación o error que podría haberse introducido en el código original.
Una vez generados, se ejecutan los tests sobre los mutantes. 
Si algún test de la suite falla al ejecutar el mutante se considera que ha
\'matado\' al mutante. Esto significa que los tests son capaces de detectar el error 
introducido por el mutante. Un mutante sobrevive si ningún test de la suite 
detecta el cambio. Esto implica que es posible mejorar la suite para aumentar su capacidad 
para encontrar errores, por ejemplo, agregando un nuevo test que mate el mutante.

El puntaje de mutación de una suite (mutation score) se define como
el cociente entre la cantidad de mutantes muertos y el total de mutantes
generados. Así, un puntaje de mutación alto da una mayor confianza de que la suite 
de tests tiene una buena capacidad de revelar defectos en el SUT. 
Por otro lado, al identificar los mutantes que no son detectados por los tests 
se pueden identificar deficiencias en la suite, y se pueden tomar medidas 
correctivas para mejorar su calidad.

El análisis de mutación es uno de los criterios más fuertes para evaluar la 
calidad de los tests, ya que los mutantes generados por las operadores de 
mutación más usados 
tienen una alta correlación con las fallas que cometen los desarrolladores 
(incluso, una mayor correlación que los criterios anteriores) \cite{just2014mutants}. Sin
embargo, su costo computacional es elevado (requiere generar un
número usualmente grande de mutantes, y ejecutar los tests para todos ellos). 
Suele ser el criterio más trabajoso para el desarrollador, ya que usualmente 
se requiere un número relativamente grande de tests para lograr un buen puntaje 
de mutación (suele ser significativamente mayor que la cantidad de tests
    requeridos para lograr buena cobertura de código) \cite{papadakis2019}.

Las técnicas mencionadas anteriormente se aplican en esta tesis para evaluar las 
nuevas técnicas propuestas, y poder realizar una comparación con herramientas
relacionadas del estado de arte. Además, se utilizan como base para la
definición de algunas de las técnicas presentadas. Por ejemplo, la cobertura de
código se usa como parte de la función objetivo para el cómputo de métodos
generadores de objetos usando Randoop \ref{sec:fitnessRandoop}.


\section{Java PathFinder (JPF)}
\label{sec:jpf}

\emph{Java PathFinder} (JPF) es una herramienta para la verificación de
programas Java. Entre sus aplicaciones está el \emph{bounded model checking} (BMC), que
consiste en explorar sistemáticamente todas las ejecuciones del programa con
entradas de tamaño acotado, y un número acotado de iteraciones de los ciclos, en busca de fallas
\cite{Visser05,Pasareanu:2010}. Los límites para el tamaño de las entradas
son provistos por el usuario. 
%Estos incluyen, el número máximo de objetos para las 
%estructuras, rangos de valores para los
%tipos primitivos, y el número máximo de iteraciones para los ciclos.
Cuando se detecta una falla, JPF produce un contrajemplo reproducible que facilita el
\emph{debugging} \cacho{\cite{Visser05,Pasareanu:2010}} \footnote{\url{https://github.com/javapathfinder/jpf-core}}
\\
\begin{lstlisting}[language=Java,caption={Propiedad a verificar},label={lst:propiedad},captionpos=b]
int oldSize = t.size();
int value = Verify.getInt(0, b);
Verify.ignoreIf(t.contains(value));
t.addFirst(value);
t.removeFirst();
assert oldSize == t.size() : "different size";
\end{lstlisting}

La Figura \ref{lst:propiedad} muestra un ejemplo de propiedad a
verificar (de manera acotada) usando JPF. La propiedad indica que, para cualquier lista 
de entrada \texttt{t}, insertar al inicio un entero \texttt{value}
(\texttt{addFirst(value)}, con \texttt{value} en \texttt{[0,b]}) que no pertenece a la lista,
y luego eliminar el primer elemento de la lista (\texttt{removeFirst()}), debe
dejar una lista con el mismo tamaño que la inicial.
La propiedad se expresa con un \emph{assert} de JPF: si la condición resulta falsa en una ejecución, JPF reporta un
contrajemplo. En el ejemplo, la propiedad indica que la longitud de la lista
inicial (\texttt{oldSize}) debe ser igual a la longitud de la lista al final de la
ejecución (\texttt{t.size()}). 

Notar que el Algoritmo \ref{lst:propiedad} usa algunas primitivas
propias de JPF que introducen no determinismo en la exploración del programa. 
En particular, \texttt{Verify.ignoreIf(condicion)} evita explorar ejecuciones
que no cumplen con el predicado \texttt{condicion}. En el algoritmo, esta
sentencia permite ignorar todas las ejecuciones en las que la lista contiene el valor \emph{value} a insertar. Esto es similar a agregar una precondición a la propiedad a verificar.
Por otra parte, con la sentencia \texttt{int i = Verify.getInt(min,max)} JPF explora todas las
posibles ejecuciones del programa que resultan de asignar a \texttt{i} cualquier
valor entre \texttt{min} y \texttt{max}. Esto significa que JPF ejecutará el código luego
de esta instrucción con \emph{i=min}, con \emph{i=min+1, ..., i=max}. 
%Esto introduce no determinismo, ya que en principio no hay garantías del orden en que se
%asignarán valores a \emph{i}. 
%(aunque JPF tiene opciones para elejir un orden de ejecución particular).

Para analizar el algortimo \ref{lst:propiedad}, JPF necesita mecanismos para generar
las listas para instanciar el parámetro \texttt{t}. 
Los tipos primitivos son fáciles de generar en JPF (por ejemplo, los enteros se
obtienen con \texttt{Verify.getInt}), pero las estructuras dinámicas complejas
requiren de un mecanismo diferente. Para hacer verificación exhaustiva acotada
de la propiedad anterior, el usuario debe proveer un programa, comúnmente
llamado \emph{driver}, que construya todas las listas de tamaño máximo \(scope\), 
con elementos en \([0,scope]\). Las entradas generadas por el
\emph{driver} son usadas por JPF para la verificación de la propiedad.

Un driver básico para la propiedad de la Figura \ref{lst:propiedad} se
muestra en la Figura \ref{lst:driverAPI_all}. 
El driver selecciona primero la máxima cantidad de veces que se
ejecutarán métodos de la API (\(maxLength \in [0,scope]\)). Como cada método considerado a lo sumo
agrega un elemento a la lista, ejecutar a lo sumo \(scope\) métodos produce listas de
tamaño hasta \(scope\). Luego, el driver procede a la ejecución de \texttt{maxLength} 
métodos de la API (línea 4). A cada operación se le asigna un
identificador único, y se elige no determinísticamente un identificador para
seleccionar la operación a ejecutar (línea 5); por ejemplo, si
se elige el valor 2, se ejecuta 
\texttt{list.addLast(value)} (líneas 15 y 16). 

En la siguiente iteración del ciclo (línea 4), JPF volverá a elegir no
determinísticamente un nuevo método entre los disponibles (por ejemplo,
el identificador 7, correspondiente a \texttt{removeFirst()}), y así continuará
ejecutando métodos de la API para construir la estructura actual.
Cada combinación posible de decisiones (tanto el
método elegido como los valores generados para los parámetros) corresponde a una
estructura distinta dentro del espacio de búsqueda. \emph{JPF} las explora de forma 
exhaustiva para explorar todas las estructuras de tamaño hasta \texttt{scope}.
%Finalmente, el método (\texttt{generateStructure}) retorna una lista \texttt{LinkedList} que representa uno de
%esos estados posibles, sobre la cual se evaluará la propiedad del Algoritmo
%\ref{lst:propiedad}.

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}[language=Java,caption={Driver usando todos los métodos
de la API de \texttt{LinkedList}},label={lst:driverAPI_all},captionpos=b]
private static LinkedList generateStructure(int scope) {
    int maxLength = Verify.getInt(0, scope);
    LinkedList list = new LinkedList();
    for (int i = 0; i < maxLength; i++) {
        switch (Verify.getInt(n_methods - 1)) {
            case 0:
                int value = Verify.getInt(0, scope);
                list.add(value);
                break;
            case 1:
                int value = Verify.getInt(0, scope);
                list.addFirst(value);
                break;
            case 2:
                int value = Verify.getInt(0, scope);
                list.addLast(value);
                break;
            case 3:
                int value = Verify.getInt(0, scope);
                list.offer(value);
                break;
            case 4:
                int value = Verify.getInt(0, scope);
                list.offerFirst(value);
                break;
            case 5:
                int value = Verify.getInt(0, scope);
                list.offerLast(value);
                break;
            case 6:
                list.remove();
                break;
            case 7:
                list.removeFirst();
                break;
            case 8:
                list.removeLast();
                break;
            case 9:
                list.poll();
                break;
            case 10:
                list.pollFirst();
                break;
            case 11:
                list.pollLast();
                break;
            case 12:
                int value = Verify.getInt(0, scope);
                list.contains(value);
                break;
            case 13:
                list.peek();
                break;
            case 14:
                list.clear();
                break;
            /* (*@m\'etodos omitidos@*) */
            case 66:
                list.empty();
                break;
        }
    }
    return list;
}
\end{lstlisting}
\end{minipage}

Este driver simple utiliza todos los métodos de la API para la generación de
estructuras. Notar que el número de caminos a explorar por el driver crece exponencialmente con la cantidad de métodos disponibles. Sin embargo, muchas de estos métodos no son necesarios si
lo que se busca es generar estructuras de manera exhaustiva acotada. 
En módulos con muchas operaciones, seleccionar rutinas para el \emph{driver} no es trivial y puede impactar fuertemente en el
análisis posterior. Idealmente, se busca un conjunto tan pequeño como sea
posible de métodos, cuyas combinaciones permitan construir todas las
estructuras acotadas para el módulo. Incluir rutinas superfluas incrementa exponencialmente las combinaciones y degrada la eficiencia. 
La selección de rutinas suele hacerse manualmente, lo que exige revisar minuciosamente toda la API y comprender su semántica, y se vuelve tediosa cuando hay redundancia o muchas operaciones irrelevantes.

En esta tesis proponemos técnicas automáticas que, dada la API de un módulo,
identifican un subconjunto minimal de métodos generadores de objetos (ver
Capitulo \ref{cap:builders}). Como se muestra en la Sección \ref{sec:experiments-jpf-driver}, 
estas técnicas pueden ayudar a la definición de drivers más eficientes. 

