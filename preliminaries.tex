\chapter[Preliminares]{Preliminares}
\label{cap:preliminares.BE}
\section{Generacion exhaustiva acotada  de entradas}
\label{sec:BE}

\cacho{Explicar sobre BE}
% La generación automatizada de entradas de prueba para las APIs de los programas es una tarea crítica en la prueba de software, ya que puede ayudar a identificar errores y garantizar que los programas se comporten correctamente bajo una amplia gama de entradas. Sin embargo, la generación de entradas para las APIs puede ser desafiante, ya que el número de posibles valores de entrada a menudo es muy grande. La prueba exhaustiva de todas las posibles entradas es típicamente inviable debido a la explosión combinatoria de los valores de entrada, mientras que la prueba aleatoria puede pasar por alto casos importantes. En este artículo, se propone un nuevo enfoque para generar valores de entrada exhaustivos y acotados para las APIs de los programas. Nuestro enfoque combina la ejecución simbólica con la resolución de restricciones para generar un conjunto representativo de valores de entrada que se pueden utilizar para probar APIs con una alta cobertura, sin la necesidad de probar cada posible valor de entrada. Evaluamos nuestro enfoque en un conjunto de APIs del mundo real y mostramos que es más efectivo que los enfoques existentes en términos de cobertura y eficiencia.

% Los enfoques de generación de pruebas automatizadas tienen como objetivo ayudar a los desarrolladores en tareas cruciales de prueba de software [TODO ???], como la generación automática o facilitar la creación de conjuntos de pruebas [TODO: ????] y la detección y reporte automáticos de fallas [TODO: ????] . Muchos de estos enfoques implican componentes aleatorios que evitan una exploración sistemática del espacio de comportamientos, pero mejoran la eficiencia de la generación de pruebas [TODO: ????] . Si bien estos enfoques han sido muy útiles para encontrar una gran cantidad de errores en el software, podrían perder la exploración de ciertos comportamientos defectuosos del software debido a su naturaleza aleatoria. Los enfoques alternativos tienen como objetivo explorar sistemáticamente un número muy grande de ejecuciones del software bajo prueba (SUT), con el objetivo de proporcionar garantías más sólidas sobre la ausencia de errores[TODO: ????] . Uno de estos enfoques es la generación exhaustiva acotada (BE) [TODO: ????] , que consiste en generar todas las estructuras factibles que se pueden construir utilizando dominios de datos acotados. Los objetivos comunes de los enfoques BE han sido implementaciones de estructuras de datos complejas y dinámicas con ricos y estructurados enlaces (por ejemplo, listas enlazadas, árboles, etc.). Los enfoques BE de caja negra [TODO: ????]  son los más utilizados y eficientes para probar software. Requieren que el usuario proporcione una especificación formal de las restricciones que las estructuras deben satisfacer, con mayor frecuencia una invariante de representación de la estructura (repOK), y los límites de los dominios de datos [TODO: ????] , a menudo llamados \emph{scope}. De este modo, los enfoques BE de caja negra generan todas las estructuras dentro de los ámbitos proporcionados que satisfacen repOK.
% Varios estudios muestran que los enfoques BE son efectivos para revelar fallas en el software [TODO ???]. Además, la llamada hipótesis del cota pequeña [TODO ?], que establece que la mayoría de las fallas de software se pueden revelar ejecutando el SUT en "entradas pequeñas", sugiere que, si se utilizan ámbitos lo suficientemente grandes, los enfoques BE deberían ser capaces de revelar la mayoría (si no todas) las fallas en el SUT. El desafío que enfrentan los enfoques BE es cómo explorar eficientemente un gran espacio de búsqueda, que en el peor de los casos crece exponencialmente con respecto a los ámbitos. El espacio de búsqueda a menudo incluye un gran número de estructuras no válidas (que no satisfacen repOK) y estructuras isomórficas [TODO ??]. Por lo tanto, podar partes del espacio de búsqueda que involucran estructuras inválidas y redundantes es clave para hacer que los enfoques BE se escalen en la práctica [TODO ??]. Escribir especificaciones formales apropiadas para la generación de BE es una tarea desafiante y que consume mucho tiempo. Las especificaciones deben capturar precisamente el conjunto de restricciones previstas en las estructuras. Las especificaciones sobrerestringidas hacen que falte la generación de una parte de las estructuras válidas, lo que puede hacer que la etapa de prueba subsiguiente pierda la exploración de los comportamientos defectuosos del SUT. Las especificaciones subrestringidas pueden llevar a la generación de estructuras inválidas (es decir, estructuras que no cumplen con las restricciones previstas), lo que puede producir falsos negativos durante la prueba del SUT. Además, a veces el usuario tiene que tener en cuenta la forma en que opera el enfoque de generación y escribir las especificaciones de una manera muy específica, de manera que el enfoque pueda lograr un buen rendimiento [TODO ???]. Finalmente, tales especificaciones formales precisas rara vez están disponibles en el software, lo que dificulta la usabilidad de los enfoques BE de caja negra.

\section{Feedback-directed test generation}\label{sec:feedback-directed-test-gen}
% Randoop es una herramienta de generación automática de pruebas que utiliza la técnica de generación aleatoria para explorar el espacio de entrada de un programa y generar casos de prueba automáticamente \cite{Pacheco:07}.

% La técnica de generación aleatoria empleada por Randoop consiste en generar de forma automática entradas aleatorias para el programa bajo prueba. Utiliza la reflexión en Java para analizar la estructura del programa y generar una serie de llamadas a métodos con valores de entrada aleatorios. Estas llamadas se combinan de manera inteligente para formar secuencias de instrucciones que representan escenarios de prueba.

% Randoop utiliza una estrategia de búsqueda guiada para guiar la generación aleatoria de pruebas. El objetivo de esta estrategia es maximizar la cobertura del programa bajo prueba. Para lograrlo, Randoop utiliza técnicas de generación de casos de prueba basadas en la cobertura de sentencias y la cobertura de ramas del programa \cite{Pacheco:07}.



% Randoop ha sido ampliamente utilizado en la industria y en la investigación académica para evaluar la calidad de programas, encontrar errores y mejorar la confiabilidad del software. Ha demostrado ser efectivo en la generación de casos de prueba y en la detección de errores en una variedad de dominios y aplicaciones \cite{Pacheco08, Pacheco07}.

% En resumen, Randoop es una herramienta de generación automática de pruebas basada en la técnica de generación aleatoria. Proporciona una forma eficiente y efectiva de generar casos de prueba que cubren diferentes partes de un programa y ayuda en la detección de errores y la mejora de la calidad del software.

La generación de pruebas dirigida por retroalimentación se introdujo por primera vez en el enfoque \textsf{Randoop}, basado en la generación aleatoria de pruebas \cite{Pacheco07}. \textsf{Randoop} requiere un conjunto de rutinas de una API y un budget para la generación de pruebas 
% (tiempo o número de pruebas a generar). 
\textsf{Randoop} representa las pruebas como secuencias de invocaciones a las rutinas de la API. Por lo tanto, a menudo se llaman \emph{secuencias de prueba}. Comienza con unos pocos valores semilla predeterminados para los tipos primitivos que se utilizarán para instanciar los parámetros de las rutinas de tipos primitivos durante la generación (el usuario también puede proporcionar valores semilla adicionales). \textsf{Randoop} realiza un proceso iterativo. Cada paso consiste en seleccionar aleatoriamente una única rutina \texttt{r(p$_1$,..,p$_k$)} para generar una nueva secuencia de prueba. Para esta rutina, \textsf{Randoop} selecciona aleatoriamente las secuencias \texttt{s$_1$,..,s$_k$} de un conjunto de secuencias de prueba previamente generadas, que se pueden usar para crear valores de los tipos apropiados para instanciar los parámetros \texttt{p$_1$,..,p$_k$} de \texttt{r}, respectivamente. Una nueva prueba \texttt{T} se crea componiendo secuencialmente \texttt{s$_1$,..,s$_k$} y \texttt{r} (y reemplazando los parámetros formales de \texttt{r} por las variables correspondientes en \texttt{s$_1$,..,s$_k$}). \texttt{T} podría ser una prueba ilegal debido al uso no válido de la API y/o fallas en el código en prueba. También podría ser redundante en el sentido de que no produce ninguna estructura para ejercitar el código de manera diferente que las pruebas generadas anteriormente.
La idea principal de la generación de pruebas dirigida por retroalimentación es ejecutar \texttt{T} y observar su comportamiento en tiempo de ejecución. Si \texttt{T} es una prueba legal, es decir, su ejecución termina con éxito,
y \texttt{T} no es redundante, entonces, \texttt{T} se agrega al conjunto de pruebas generadas previamente. Esto hace que \texttt{T} sea un candidato para su posible extensión para generar nuevas pruebas cuando se seleccione un nuevo método en una iteración futura del algoritmo. De lo contrario, si \texttt{T} es una prueba ilegal, por ejemplo, porque genera una excepción o viola un contrato, o si es redundante (consulte la sección~\ref{sec:state-matching})), entonces \texttt{T} no se considera para su posible extensión. \textsf{Randoop} continúa este proceso iterativo hasta que agota su presupuesto. Las evaluaciones experimentales han encontrado que la generación de pruebas dirigida por retroalimentación funciona significativamente mejor que la generación aleatoria simple de pruebas \cite{Pacheco07,Pacheco08}.
La principal ventaja de \textsf{Randoop} es su capacidad para generar automáticamente una gran cantidad de casos de prueba que cubren diferentes partes del programa bajo prueba. Esto permite detectar errores y comportamientos inesperados que pueden surgir en situaciones de entrada no contempladas durante el desarrollo manual de pruebas.
Una de las técnicas que presentamos en esta tesis, \textsf{BEAPI}, se basa en \textsf{Randoop}, pero en lugar de la generación aleatoria, tiene como objetivo generar \emph{todas} las secuencias de pruebas factibles (acotadas), dentro de un alcance dado. La retroalimentación de la ejecución permite a \textsf{BEAPI} descartar pruebas ilegales durante el proceso de generación. Además, al estar basado en una generación de pruebas dirigida por retroalimentación, \textsf{BEAPI} genera una secuencia de prueba para cada estructura en el conjunto exhaustivo acotado que construye y solo guarda los conjuntos de secuencias de llamadas a métodos que generan objetos válidos.

% Cabe destacar que esta modificación se realizó basándonos en la arquitectura y diseño modular de Randoop, lo que permitió una fácil extensión de sus funcionalidades sin afectar su funcionalidad principal.

Además, en esta tesis se realizó una modificación de Randoop que consistió en incorporar una funcionalidad que permitiera al usuario especificar un porcentaje de prioridad para un subconjunto de métodos en la generación de pruebas. Al proporcionar un porcentaje de prioridad para un subconjunto de métodos, Randoop tendrá mayor probabilidad de generar casos de prueba que cubran esos métodos específicos de manera más exhaustiva. Y le hemos agregado la posibilidad de serializar los objetos (con secuencia de llamadas a métodos de los test podemos generar objetos) Esto nos permitió utilizarlo como una función de valoración explicada en \ref{sec:randoopObjects}.


\section{Algoritmos Genéticos}
\label{sec:geneticoPrev}
Los algoritmos genéticos (AG) \cite{goldberg1989genetic} son una técnica de búsqueda y optimización que se inspira en la evolución biológica. Se utilizan para resolver problemas de búsqueda, especialmente problemas de optimización, imitando el proceso de evolución natural. A través de un proceso evolutivo basado en elecciones aleatorias guiadas, los algoritmos genéticos exploran un espacio de soluciones en busca de la mejor solución posible.
Para abordar un problema utilizando un algoritmo genético, es necesario contar con los siguientes componentes:

\begin{itemize}
    \item  \textbf{Codificacionl}: Cada solución candidata en el espacio de búsqueda debe poder representarse como un individuo o \emph{cromosoma} en la población del algoritmo genético. La codificación consiste en una función biyectiva que mapea soluciones del problema al conjunto de todos los posibles cromosomas. Comúnmente, los cromosomas están compuestos por genes que representan características del individuo, por ejemplo  $c\_s = [g1, g2, ..., gn]$ donde cada gen representa una característica del cromosoma.


    \item \textbf{Población inicial}: La población inicial del algoritmo genético está formada por un conjunto de cromosomas que codifican soluciones candidatas al problema. Los genes de estos cromosomas son seleccionados aleatoriamente. El tamaño de la población inicial se define a priori y se mantiene constante durante las iteraciones del algoritmo.

    \item \textbf{Función de Fitness}: La función de aptitud (también conocida como función de fitness) es una función que mide la calidad de un cromosoma o solución candidata. Evalúa cuán bien resuelve el problema la solución representada por el cromosoma. Durante la evolución del algoritmo, el objetivo es optimizar esta función, es decir, encontrar el individuo de la población con el mayor (o menor) valor de aptitud según el objetivo del problema.

\item \textbf{Operadores genéticos}: Los operadores genéticos son las herramientas mediante las cuales se generan nuevas soluciones a partir de soluciones existentes. Los principales operadores son:
    \begin{itemize}
    \item \textbf{Selección}: Selecciona los cromosomas más aptos para reproducirse. Existen diferentes estrategias de selección, como la selección por torneo.

    \item \textbf{Cruce (\emph{Cross-over} en inglés)}: Combina los genes de dos cromosomas para producir uno o más descendientes. El cruce se realiza en puntos específicos de los cromosomas y puede ser de un solo punto, de múltiples puntos o uniforme.

    \item \textbf{Mutación}: Introduce cambios aleatorios en un cromosoma para explorar nuevas regiones del espacio de soluciones. La mutación permite evitar la convergencia prematura y mantener la diversidad genética en la población.
    \end{itemize}

\item \textbf{Par\'ametros}: El algoritmo genético recibe una serie de parámetros que deben ajustarse para su ejecución. Algunos de los parámetros comunes incluyen el tamaño máximo de la población, el número de iteraciones, las tasas de mutación y cruce, y los criterios de convergencia.
\end{itemize}

A continuación, se describen las etapas principales del algoritmo genético y para explicar un algoritmo genético estándar :

\begin{algorithm}[H]

\SetAlgoLined
\KwResult{Best solution}
Inicializar población inicial $P$ de cromosomas aleatorios\;

Evaluar la aptitud de cada cromosoma en $P$\;

\While{Criterio de terminación no se cumple}{ 
    Seleccionar cromosomas padres de $P$ para la reproducción\;
    Aplicar operador de cruce para generar descendencia\;
    Aplicar operador de mutación a la descendencia\;
    Evaluar la aptitud de los nuevos cromosomas\;
    % Reemplazar cromosomas menos aptos en $P$ por la descendencia\;
}
\caption{Algoritmo Genético}
\end{algorithm}

\begin{itemize}

\item \textbf{Inicialización}: En esta etapa, se crea la población inicial de cromosomas aleatorios. Los cromosomas se generan codificando soluciones candidatas al problema.

\item \textbf{Evaluación}: En esta etapa, se evalúa la aptitud de cada cromosoma en la población utilizando la función de aptitud. La aptitud se utiliza para guiar la búsqueda y seleccionar los cromosomas más aptos para reproducirse.

\item \textbf{Selección}: En esta etapa, se seleccionan los cromosomas más aptos para reproducirse y formar la próxima generación de la población. Los métodos de selección pueden variar, pero generalmente se utiliza la selección por torneo o la selección proporcional al valor de aptitud.

\item \textbf{Cruce}: En esta etapa, se aplican operadores de cruce a los cromosomas seleccionados. El cruce combina los genes de dos cromosomas para generar uno o más descendientes. El tipo de cruce depende del problema y se selecciona según su eficacia para explorar el espacio de soluciones.

\item \textbf{Mutación}: En esta etapa, se aplican operadores de mutación a los cromosomas seleccionados. La mutación introduce cambios aleatorios en un cromosoma para explorar nuevas regiones del espacio de soluciones. La tasa de mutación controla la probabilidad de que ocurra una mutación en un gen dado.

\item \textbf{Reemplazo}: En esta etapa, se reemplazan los cromosomas menos aptos en la población por los descendientes generados mediante el cruce y la mutación. Esto permite que los cromosomas más aptos sobrevivan y transmitan sus características a las siguientes generaciones.

\item \textbf{Convergencia}: El algoritmo genético se repite durante un número determinado de iteraciones o hasta que se cumpla un criterio de convergencia. Este criterio puede ser un número máximo de generaciones, una aptitud objetivo alcanzada o la estabilización de la aptitud promedio de la población.
\end{itemize}

En resumen, los algoritmos genéticos son una herramienta poderosa y versátil para abordar problemas de optimización y búsqueda en una amplia gama de campos. Su capacidad para explorar ampliamente el espacio de soluciones y su capacidad para manejar problemas complejos los convierten en una opción atractiva para resolver desafíos en diversos dominios.

En esta tesis, nos enfocamos en el uso de AGs para buscar subconjunto de métodos de la API que sean builders. Esto lo hablaremos en detalle en el Capítulo \ref{cap:builders}. Para más información sobre Algoritmo Genéticos, puede referirse a \cite{dejong2006evolutionary} 


\section{Algoritmos Perezosos? (Greedy)}
\label{sec:greedyPrev}
El algoritmo Greedy es una estrategia de resolución de problemas que sigue un enfoque voraz, tomando decisiones locales óptimas en cada etapa con la esperanza de llegar a una solución global óptima. A diferencia de otros enfoques, el algoritmo Greedy no realiza una búsqueda exhaustiva en el espacio de soluciones, sino que se centra en elegir la mejor opción disponible en cada momento.

El enfoque Greedy se basa en la idea de que, al tomar decisiones óptimas en cada etapa, se puede obtener una solución aproximadamente óptima para el problema en general. Sin embargo, debido a su naturaleza voraz, el algoritmo Greedy puede no garantizar una solución óptima en todos los casos. En algunos casos, el algoritmo puede llegar a un óptimo local, pero no a un óptimo global. Por lo tanto, es importante tener en cuenta las limitaciones y restricciones del problema al aplicar el algoritmo Greedy.

\begin{algorithm}[H]
  \SetAlgoLined
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwFunction{Greedy}{Greedy}

  \caption{Greedy Algorithm}

  \Input{Set $S$}
  \Output{Solution $R$}

  \BlankLine
  $R \gets \emptyset$ 
  $U \gets S$ \tcp*{Set of available elements}

  \BlankLine
  \While{$U \neq \emptyset$}{
    $x \gets$ element selected according to Greedy criteria
    
    $R \gets R \cup \{x\}$ \tcp*{Add $x$ to the solution}
    $U \gets U \setminus \{x\}$ \tcp*{Remove $x$ from available elements}
  }

  \BlankLine
  \Return $R$ 

\end{algorithm}

El algoritmo comienza con un conjunto de elementos disponibles y un conjunto solución vacío. En cada iteración, se selecciona el elemento óptimo según la función de heurística para los estados que se haya implementado y se agrega a la solución. Luego, se elimina ese elemento de los disponibles y se repite el proceso hasta que no queden elementos disponibles.

Es importante tener en cuenta que el algoritmo Greedy no garantiza encontrar la solución óptima en todos los casos, ya que puede quedarse atrapado en mínimos locales. Sin embargo, en muchos casos, el enfoque Greedy proporciona soluciones rápidas y razonables.

En esta tesis se personalizó el algoritmo para detectar subconjuntos óptimos de métodos \emph{builders}. 
Para mas informacion sobre este tipo de algoritmos, invitamos al lector referirse a \cite{Cormen2009}, \cite{kleinberg2006}

\section{Coverage?}

